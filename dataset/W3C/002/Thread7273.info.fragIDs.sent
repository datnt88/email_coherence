Here is a proposed draft charter for this working group, which will be discussed at the Cambridge meeting. 
Especially if you are not attending, I welcome your feedback. 
Pardon me if I've missed something but there seems to be no mention whatsoever of security/authentication/permissions in this draft. 
BTW, which Cambridge? 
Cheers, Ben. 
A.L. Digital Ltd, URL: http://www.algroup.co.uk London, England. 
Apache Group member (http://www.apache.org) 
Here is a proposed draft charter for this working group, which will be discussed at the Cambridge meeting. 
Especially if you are not attending, I welcome your feedback. 
- Jim 
WWW Distributed Authoring and Versioning (webdav) Charter Draft, v0.1, September 15, 1996 Chair * Jim Whitehead, ejw@ics.uci.edu 
Mailing List Information * General Discussion: w3c-dist-auth@w3.org 
* To Subscribe: w3c-dist-auth-request@w3.org o Send message with subject "subscribe" * Archived: http://www.w3.org/pub/WWW/Archives/Public/w3c-dist-auth/ Description and Purpose of Working Group The HTTP protocol contains functionality which enables the editing of web content at a remote location, without direct access to the storage media via an operating system. 
This capability is exploited by several HTML distributed authoring tools, and by a growing number of mainstream applications (e.g. word processors) which allow users to write (publish) their work to an HTTP server. 
Experience from the HTML authoring tools to date has shown they are unable to meet their user's needs without adding extensions to the HTTP protocol. 
Their extensions, developed in isolation, are not interoperable. 
The broad goal of the working group is to enable distributed web authoring tools to be broadly interoperable, while supporting user needs. 
It is assumed that user needs encompass the abilities currently found in distributed authoring tools, which include versioning, listing and creating directories, locking, and typed relationships. 
Other reasonable distributed authoring functionality includes metadata capability, the ability to copy and move web content from a remote location, and access to the unprocessed source representation of content. 
More concretely, the activity of this working group will be to develop distributed authoring usage scenarios and requirements documents to determine reasonable user needs. 
Wherever possible, these needs will be kept simple, easy to implement, and general in their range of applicability. 
Specifications for how these requirements can be met will then be generated. 
These specifications will take the form of extensions to HTTP, and new media types. 
Deliverables and Milestones Done Establish mailing list and archives. 
Sep 96 Draft working group charter. 
Sep 96 Submit distributed authoring requirements as Internet Draft and W3C Working Draft. 
Sep 96 Submit WWW versioning requirements as Internet Draft and W3C Working Draft. 
Oct 96 Submit distributed authoring and versioning scenarios document as Internet Draft and W3C Working Draft. 
Nov 96 Submit container media type specification as Internet Draft Nov 96 Submit initial distributed authoring and versioning specification as Internet Draft and W3C Working Draft Jan 97 Complete revisions to container media type specification Internet Draft. 
Move to W3C Proposed Recommendation. 
Jan 97 Complete final revisions to distributed authoring requirements document. 
Submit as Informational RFC. 
Feb 97 Complete final revisions to WWW versioning requirements document. 
Submit as informational RFC. 
Feb 97 Complete revisions to distributed authoring and versioning Internet Draft specification. 
Move to W3C Proposed Recommendation. 
Jun 97 Complete revisions to container media type specification based on implementation experience. 
Submit as standards track RFC. 
Jun 97 Complete revisions to distributed authoring and versioning specificaiton based on implementation experience. 
Submit as standards track RFC. 
Aug 97 Group terminates. 
Jim, a few comments just to show that I am back and working now: 
I seem to remember this discussion appeared already in either one of the working group, and was discussed by David Durand and me while drafting the versioning requirements. 
Is my interpretation of the last sentence correct, in that the lack of "direct access to the storage media" is *required*? 
I mean, do we exclude support for non-HTTP access to the stored media (e.g. direct file access, FTP, or even redundant copies (published and local ones), or do we simply include both direct and HTTP access? 
If so, wouldn't the sentence improve if it stated: "...with or without direct access to the storage media"? 
Should we include a discussion on synchronous vs. asynchronous collaboration? 
(e.g. is notification out of this group?) Ciao Fabio 
Good points. 
Security is an item we are going to leave up to other groups to provide for us. 
However, our draft charter should make this clear. 
We have been operating under the assumption that MD5 authentication would be sufficient for our needs -- if something better than MD5 comes along, we would hope we could use it. 
Again, the draft should state this. 
Aside from locking, our work is *not* going to address access control or permissions. 
This is a huge issue, and I feel that we would never finish if we had to produce a consensus access control draft. 
This is an important issue, and one which will hopefully be addressed by *another* working group. 
But, the draft should make mention of this. 
- Jim 
Fair enough. 
But there is an aspect of permissioning that probably should be addressed by this WG, namely, the ownership/permissions of the file (or equivalent entity) on the server. 
Not what they should be, of course, but how one sets them. 
Cheers, Ben. 
A.L. Digital Ltd, URL: http://www.algroup.co.uk London, England. 
Apache Group member (http://www.apache.org) 
Down that path lay madness. 
Yaron (We Need a Non-Versioning client and Security Sub-Group) Goland From: Ben Laurie[SMTP:ben@gonzo.ben.algroup.co.uk] Subject: Re: Draft WG charter 
Fair enough. 
But there is an aspect of permissioning that probably should be addressed by this WG, namely, the ownership/permissions of the file (or equivalent entity) on the server. 
Not what they should be, of course, but how one sets them. 
Cheers, Ben. 
A.L. Digital Ltd, URL: http://www.algroup.co.uk London, England. 
Apache Group member (http://www.apache.org) 
As long as you're restating the assumptions, I'll add my bit. 
MD5 is not likely to survive much longer and therefore should be considered inappropriate. 
Claims of being close to breaking it are beginning to circulate, including predictions of that event happening yet this year. 
As for a suitable replacement, SHA (aka, SHA-1) seems to be the likely candidate. 
There is also a hash out of Europe that seems to have the right attributes (but alas, I can't remember the name). 
AO Alan O. FreierCorporate Cynic freier@netscape.com 
(415) 937-3638 (work) 
Personally, I think that the charter should be broad enough that we might consider specific proposals for authorization models and access permissions, even if we don't want to deep end on the topic. 
No Internet standard can progress without at least touching on the topic of security issues, and I don't think we can just ignore the issue, without being clear about how such things will work in practice. 
Clearly, in order to meet the general needs, we can't rely on a specific model ("ownership" and "file permissions"), but the protocol might allow some registry of authentication models, and tunnel access policy issues. 
After all, an access policy for a particular uploaded item isn't so different from other kinds of random metadata (PICS rating, MARC record, etc.) that one might want to send. 
Larry 
Alan is certainly right about what is going on around MD5 in the industry and in research. 
While Ron Rivest's (the R of RSA) reply to me earlier this week was for our purposes in HTTP Digest authentication plain MD5 was probably just fine, it is also clear that some people will not be comfortable with its use, as it has recently shown certain classes of vulnerabilities. 
Each time some vulnerability comes up, we don't want to have to always deal with understanding its implications to HTTP work, but should leverage other people's crypto work as much as possible. 
In the area of what HTTP should do semantically, we really don't want/need to take on all cryptographic problems too. 
We need to get the HTTP documents to correctly interact with all the IP security work going on in the IETF, so that this problem doesn't come back to haunt HTTP work forever. 
IPSEC is specifing a hash function for authentication purposes; the way out of the morass is to organize things to reference (as soon as possible; it may not currently trivial to do this instant on process grounds for things like Digest, as the IPSEC documents themselves are being revised and may not be far enough along for us to reference them to meet IETF process standards for proposed standard that Digest is at) the IPSEC work on authentication functions, rather than get into it ourselves. 
My understanding from a hallway conversation yesterday with Matt Thomas of Digital (involved in the IPV6 work) is that IPSEC is going with MD5-HMAC right now (whatever exactly that is; it is a variation on the original MD5 algorithm), and I asked Matt to get me information on who is shepherding these IPSEC documents through the IETF process so I could understand what was happening there to deal with IETF process issues (we have much the same problem right now with Digest authentication, where we specify which algorithm and are not in the midst of the people who are expert in this area), to address Phil Karlton of Netscape's concerns about Digest. 
I'll be trying to sort this out some over the next couple days, if I can. - Jim 
Half addressing security is, in my opinion, even worse then not addressing it at all. 
The reason being that a half addressing leaves certain expectations that may or may not be accurate, that may or may not work, and that may or may not ever be realized. 
The logic is similar to why it is better to use no virus checker than a bad virus checker. 
I have said before that we should have a dedicated security sub-group on a separate schedule from the main group. 
I am willing to be a member. 
Is anyone else interested? 
Yaron From: Larry Masinter[SMTP:masinter@parc.xerox.com] 
Subject: Re: Draft WG charter Personally, I think that the charter should be broad enough that we might consider specific proposals for authorization models and access permissions, even if we don't want to deep end on the topic. 
No Internet standard can progress without at least touching on the topic of security issues, and I don't think we can just ignore the issue, without being clear about how such things will work in practice. 
Clearly, in order to meet the general needs, we can't rely on a specific model ("ownership" and "file permissions"), but the protocol might allow some registry of authentication models, and tunnel access policy issues. 
After all, an access policy for a particular uploaded item isn't so different from other kinds of random metadata (PICS rating, MARC record, etc.) that one might want to send. 
Larry 
I agree with Alan; the biggest issue here as little to do with MD5 itself, which Ron Rivest thought it was ok for the purpose it is being used for in Digest authentication. 
But dealing with the political fallout as such attacks happen again and again is diverting from HTTP itself; we don't have the expertise here, and had better leverage the rest of the community that has to fight that battle (and can fight it better than we can, with real expertise). 
So having someone else run interference on the issues is the way for HTTP to be able to evolve without getting sidetracked again and again into the firedrill of the day and people who don't want things deployed for whatever reason. 
(and not just commercial reasons; the web has spilled into the point of international politics y of all sorts). 
- Jim 
