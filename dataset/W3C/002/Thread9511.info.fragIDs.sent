DanC: 
I suppose, in addition to the tests art came up with, there's an example in the RDF spec: 
rdf:Description xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/metadata/dublin_core#" 
xmlns="http://www.w3.org/TR/REC-mathml" rdf:about="http://mycorp.com/papers/NobelPaper1" Ramifications of to World Peace -- http://www.w3.org/TR/1999/REC-rdf-syntax-19990222/#examples 
Jeremy, as owner of #rdfms-literal-is-xml-structure, I'd like you to show what the n-triples form of that document should be. 
I would not be opposed to deleting parseType="Literal" The only use case I have been told about is for cheap and cheerful tools which involving typing RDF in directly where people want to put some HTML in a value. 
In my previous ramblings on the topic, which I still owe the WG a second attempt at, I have suggested that: 1) any reasonable attempt at representing an XML Literal should be permissable. 
2) we should recommend an XML Canonicalisation according to the fragment section of that spec. 
Taking your challenge and following 2, I attach an n-triples file. 
The literal, (in pieces that need to be concatenated is) "\n Ramifications of\n apply xmlns=\"http://www" ".w3.org/TR/REC-mathml\" xmlns:dc=\"http://purl.org/metadata/d" "ublin_core#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-sy" "ntax-ns#\" \n power /power \n apply \n " 
plus /plus \n ci a /ci \n ci b /ci " 
"\n /apply \n cn 2 /cn \n /apply \n " 
to World Peace\n " 
Notes: Alla c14n all namespaces are made explicit on the outermost element(s) in the fragment. 
In this case there is one. 
The namespaces are listed in lexicographic order of the namespace prefix. 
Empty xml elements such as power/ are canonicalised to power /power . 
The bit I don't like is including the irrelevant namespaces rdf and dc as well as the relevant default namespace. 
Unfortunately the XML guys have made it impossible to distinguish the relevant namespaces from the irrelevant. 
Moreover it's not possible to undeclare namespaces (other than the default one); hence it is always the case that XML Literals under my proposal will have the rdf namespace being explicit in them (yuk!). 
I am increasingly convinced that infoset is an irrelevance to RDF/XML and we should only consider the XPath nodeset. 
I would much prefer to drop parseType="Literal" than have a homebrew solution that did not strike a chord with some XML standard. 
Jeremy 
Dan Connolly: 
No, I think the tests are fine; the spec is just sloppy. 
You'll have to do better than this. 
XML well formedness is one of the few areas surrounding literals where the M&amp;S is neither sloppy nor ambiguous. 
The refactoring syntax draft also insists upon well 
formedness; it's not sloppy on this point either. 
Please don't assume that the tests and specifications can stand in isolation. 
As things are I can code two different behaviours against the body of work. 
That wastes everyone's time, hurts interop, slows adoption; it's hardly smart. 
Think the spec is wrong? 
Then propose to kill the well formedness constraint in view of implementation feedback. 
The best place to exact that change is in the refactoring syntax draft, you'll find text to that effect below. 
Think the tests are wrong? 
Then propose to change the tests to reflect the M&amp;S and the refactoring syntax draft. 
You'll find text to that effect below. 
regards, Bill 
Proposal: remove the well formedness constraint from to allow certain rdf tests to stand. 
Please be aware that this change allows XML literal fragments to be non-well formed. 
Old text: Section 3.1 "6.34 literal any well-formed XML " new text: "6.34 literal any XML" 
Old text: section 4.20 "4.20 Production literal (was 6.34 literal) Any non-empty well-formed XML." New text: "4.20 Production literal (was 6.34 literal) Any non-empty XML." 
Proposal: Change the rdf literal tests and errors to be consistent with both the M&amp;S and the refactoring syntax draft. 
Add a surrounding element pair em /em to each free text literal element content. 
Add another error file without a surrounding element pair and indicate that this should not generate a triple. 
Dan Connolly: 
Hmm... I read it one way, you read it another, and both of us can support our positions from the text. 
In my book, that's sloppy and ambiguous. 
You inferred that the RDF spec was using "well-formed XML" in the sense of 2.1 Well-Formed XML Documents. 
I infer that it's using "well-formed XML" in the sense of 4.3.2 
Well-Formed Parsed Entities: 
An internal general parsed entity is well-formed if its replacement text matches the production labeled content. 
[43] content ::= CharData? 
((element | Reference | CDSect 
PI | Comment) CharData?)* 
-- http://www.w3.org/TR/2000/REC-xml-20001006#wf-entities -- http://www.w3.org/TR/2000/REC-xml-20001006#NT-content 
That would be bad. 
But fortunately, as far as I can tell, noone has invested in the interpretation that parseType="Literal" constrains the value to have a single root. 
quite... thanks for hunting down the relevant details, but I suggest a slightly different fix; I don't think we're removing any constraints; just clarifying... 
Clarify the well-formedness constraint to refer to well-formed XML content (as opposed to well-formed XML documents, which must, for example, have a single root). 
new text: "6.34 literal any well-formed XML content, in the sense of the content production in the XML grammar." 
new text: "4.20 Production literal (was 6.34 literal) Any non-empty XML content." 
Dave, do you agree this is a simple editorial fix? 
If so, please make it (or something like it). 
Or do you think it's a substantive issue that the WG should consider? 
Dan Connolly, W3C http://www.w3.org/People/Connolly/ 
Right, that could well be the intention of the spec. 
And that would be nice because as you say below we're clarifying not changing. 
Unfortunately 'well formed XML' sounds to me closer to 'Well Formed XML Document' than 'Well-Formed Parsed Entities', but I choose to ignore that in favour of a sensible reading. 
go. Unless. 
and I'm backing things up, binning parseType is still option in this iteration :) regards, Bill 
Ron: 
Canonicalizing the literal just makes things hard for the DPH, which will in turn limit the use of RDF. 
DPH ? 
Perl Hacker ? 
Jeremy 
Ron: 
Canonicalizing the literal just makes things hard for the DPH, which will in turn limit the use of RDF. 
Desperate Perl Hacker. 
Origin of term seems to be Jon Bosak in the original XML group, exhorting others to keep things simple so that the DPH could write simple code to operate on XML as strings and get reasonable results. 
One example of this is that end tags must contain the element type, not just / . 
Longer, but less need use a stack to keep track of scope. 
Didn't really agree with it at the time, but I do now. 
Ron 
Canonicalizing the literal just makes things hard for the DPH, which will in turn limit the use of RDF. 
Wow. In the year 2001, fundamental design decisions in programing languages are critically influenced by the need to protect low-level hackers from the burden of implementing a simple stack. 
IBM 704 assembler beats LISP after 45 years and about ten (twelve?) orders of magnitude increase in processing efficiency. 
To hell with the DPH. 
If he can't parse a nested bracket structure, then he doesn't deserve the outrageous salary he is probably earning; tell him to take up gardening instead. 
Pat 
IHMC(850)434 8903 home 40 South Alcaniz St.(850)202 4416 office phayes@ai.uwf.edu 
Well, you had me laughing out loud, ... but I'll still wade in to defend the DPH. 
Considering whether we are creating unnecessary burdens is an important test of any proposals. 
We can gain useful insight by understanding how the DPH does useful stuff despite not having various mathematically appealing properties embodied in their code. 
I think the example which was *on topic* at the beginning of this thread was parseType="Literal". 
For me, a suggestion I put on the table is that we use XML Canonicalization. 
This is moderately difficult to implement, and currently the DPH doesn't do it (nor the sophisticated programmer for that matter). 
What are the attractions, well, actually there is one, and it is theoretical: it becomes possible to provide a clean definition of equality. 
This allows some of the things that this WG has found important to happen. 
+ We can define test cases. 
(They depend on equality). 
+ We can have a well-founded abstract syntax, the graph, with well-defined literals. 
(Although Pat keeps asserting that any literals will do, it is made a lot harder if, as with M&amp;S parseType="Literals" we can't say that A=A and B=B). 
+ We can build a model theory on top of the abstract syntax. 
Meanwhile, without a well-defined representation of a parseType="Literal" value, and without well-defined equality, the DPH has done useful things, like shunt metadata around, help make the web work in one way or another. 
Things that are valuable rather than merely important. 
I am currently experimenting with squaring this circle with a bit of philosophy. 
The purpose of our rearticulation is not so much to change RDF but to allow people (DPHs included) a better understanding of what they are already doing. 
So let's suppose we decide with my suggestion of XML Canonicalization for this part of the pie. 
The DPH who needs to move metadata around will still pick up the literal string and pass it from an input stream to an output stream unchanged; but now they can be enlightened and understand that this string is one of the many acceptable representations for the XML Canonicalized version. 
This helps clarify the issues to do with equality, if this interests the DPH. 
It also helps identify what the DPH may need to do - expansion of XML character and entity references, a bit of worry about namespaces. 
Often in the restricted environments that the DPH works in they know ahead of time the namespaces in scope on the input, and can ensure that the output environment for the literal also has these namespaces. 
Maybe the DPH will decide to use Ron's approach and explicitly pass namespace information in parallel to the actual text. 
The receiving end can, if it so chooses, now recreate the XML Canonicalization, but since that two was written by a DPH, it probably won't. 
So, we *can* have our cake and (the DPH can) eat it. 
We provide a good theoretical framework, but remind application developers (and metadata infrastructure developers) that they only need to bite off as much of it as suits their problem space. 
The symbolic manipulation done in the application is valid in as much as it corresponds to an equivalent manipulation of its theoretical counterpart. 
In a restricted domain not moving into the more abstract level may be quite a bit easier. 
I am pretty sure that the same sort of argument can be made about all the graph and sub-graph isomorphism stuff, and the rdf-entail and the rdfs-entail. 
These are issues of theoretical importance; a lack of understanding of them may in the past have put a break on RDF escaping from the metadata arena; but if metadata in restricted schema is what an application is about then that complexity is an irrelevance. 
(But not dangerous). 
Jeremy 
