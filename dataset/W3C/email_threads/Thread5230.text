John's definitions are slightly different than those used in North America:
Sorry, in subtitling the start of presentation of a subtitle is referred to
as its on-air (or in-cue), the time at which the subtitle is removed from
display is the off-air (or out-cue).
Here, we use in-time and out-time (or erase time), although the effect is the same.
On-air and off-air are probably more
correctly used when talking about Open subtitling (where the subtitle is
burnt in to the video image prior to transmission) -
At some point, the working group must adopt a standard definition of "caption" vs
"subtitle" to prevent international confusion. What John is calling subtitles is what
we call captions: the textual representation of speech and non-speech information
(such as sound effects) in the same language as the audio. Captions are for deaf and
hard-of-hearing people, and can be closed (viewable with a decoder only) or open
(visible to everyone, no decoder necessary).
In NA, subtitles are a textual translation of the audio into a different language.
Subtitles are for hearing people; as such, they don't always contain the information
required by deaf or hard-of-hearing viewers, such as sound-effect cues.
Geoff Freed
WGBH/NCAM
SMPTE's definitions leave room for ambiguity. Captions are always in the
same language as the program audio, for example, and they aren't limited to just
motion pictures. I propose the following definition for captions:
"Textual representation of dialog, narration and other audio events, in the same
language as the original presentation."
And for subtitles:
"Textual representation of dialog or narration in a language different from the
original presentation."
We should also provide examples in the final recommendation, something we
don't necessarily need to deal with right now.
Geoff/NCAM
From: Johnb@screen.subtitling.com [mailto:Johnb@screen.subtitling.com]
Sent: Monday, February 03, 2003 10:34 AM
Subject: RE: TT and subtitling
I'm not sure we need get to concerned about defining captioning
vs subtitling, since TT should be agnostic to the 'higher'
meaning of the text being transmitted :-) I would suggest that
the terms subtitle and caption do not appear in the TT standard
- since both carry a number of connotations. (In the UK a
caption is the label to a picture).
Captioning is NOT always in the language of the program audio - for example
in the UK it is perfectly feasible on DTT (digital terrestrial TV) to have
English subtitles AND English captions (as separate user selections) for a
Welsh language (audio) program. To adopt the above definition would mean
that any 'foreign language' program that is **not** dubbed could only be
termed 'subtitled' - regardless of the inclusion of audio events and
narration (which are indicative of captioning cf subtitling).
Talk about head-spinning...
It is becoming apparent that we should consider a broader definition of subtitle vs
caption. That is, not differentiating subtitles from captions based on language, but
based on content:
-- captions contain additional information (sound effect cues, identifiers)
-- subtitles contain no additional information
In other words, the language of the original soundtrack *could*
become irrelevant.
Arguments?
Geoff/NCAM
Captioning is NOT always in the language of the program audio - for example
in the UK it is perfectly feasible on DTT (digital terrestrial TV) to have
English subtitles AND English captions (as separate user selections) for a
Welsh language (audio) program. To adopt the above definition would mean
that any 'foreign language' program that is **not** dubbed could only be
termed 'subtitled' - regardless of the inclusion of audio events and
narration (which are indicative of captioning cf subtitling).
Well, we do know that we will have independent variation in natural language
and on the above axis. But we have markup structures and terms for natural
language.
I don't believe that we have got to the bottom of this, yet, though.
You do have your hands on a key aspect of differentiation.
But even this has two factors.
One is coverage: does the text track cover what is said in the sound track,
or does it cover more by way of sounds or action. [And terms/language to
describe
the answer to "if more, then what?"]
But aside from texture, there is the granularity of comparison in
determining the goodness of fit. Some captions will abridge the dialog.
The same information in different words. That is to say, they will describe
what is said in the sound track in other words, even 'though in the same
natural language. These are useful in educational and learning-difficulty
applications.
So the dimensions of the problem at least subdivide into
- relationship between the natural languages of the two tracks
.. this can be based on comparing values of a unary 'naturalLanguage'
property of the tracks
- relationship between the coverage of one track relative to the kinds of
sounds in the
other track.
- other distinctions such as the reading level of the diction used in the
variant
as distinguished from the related variant track.
Candidate primitive terms in a Dublin Core sense in this application are
- natural language (done)
- language level [TBD -- education community in the lead -- ISO/IEC JTC1
SC36 LCFA]
- kinds of sounds (speech, [other categories to be named --
effects? sonicons? wallpaper? action? -- Dublin Core -like process of
intercommunity harmonization of concepts]
- rough order of coverage [fragmentary, substantial, partial]
And all of these things are qualified by scoping them to media objects we
can point at.
Captions and subtitles are both supplemental resources that find their
principal use
in conjunction with other tracks.
Al
for more on the variety of use cases:
No, we can't command changes to usage canonized in existing accredited
standards.
But the precision of the language used in their definitions is inadequate
to capture
distinctions that are important in assitive applications and adaptation
choices.
So we need to create a mapping [with noted ambiguities] between their
definitions
and the axes of distinction that matter in our applications. Then they
might join
us in DCMI to define a migration path to more universal language.
However these distinctions are IMHO far removed from the requirements of a
TT standard - which should be to define an agnostic mechanism for the timed
delivery of text. Using XML, tags to provide distinction between the text
categories (for want of a better term) should be optional, but undefined by
the standard. The TT standard should IMHO only **define** tags that are
necessary for the temporal control of the display of text.
I'm not so sure we can get away with this. There are examples today of multi-level
line-21 captioning (e.g., verbatim vs edited to a specific reading level), with no way
to easily indicate what's in the data streams. We could perhaps solve that with
metadata that defines at least two types of data...
verbatim:true/false
level: x, xx, xxx, etc., where x=editing level, reading speed, whatever
...indicating to the user that two or three or four streams of data exist. Of course, this
opens up the problem of defining levels. I'm not sure that's appropriate for this
group. But we could at least leave space for the options.
Geoff/NCAM
geoff freed wrote...
Here's my understanding:
Subtitles
- Intended for all viewers who speak a given language*
- Displayed by default for those viewers
- Includes dialog only
Captioning
- Intended for hearing-impaired viewers
- Displayed on request** by those viewers
- Includes both dialog and audio events
(generally visually differentiated by style, color, etc.)
*For example, English translations of French dialogue for English-
speaking viewers, which are unnecessary for French-speaking viewers.
**Why isn't there a "I am hearing impaired" system preference?
This needs to be defined as part of the standard since content may include
both subtitles and captioning (although they will generally be exclusive).
-- Charles Wiltgen
Similarly I am hoping that the style of the
displayed text is defined by an optional mechanism (e.g. style sheets) and
that the end presentation of the text is primarily the responsibility of the
**viewer** implementation (and could be much different to the authors
conception).
I think putting the burden of text-display characteristics on the viewer is an unfair
one. I am not against viewers overriding author choices, perhaps by using style
sheets to control the style characteristics of the text, but I think it's incumbent on the
author to provide captions or subtitles that convey information in a logical manner.
("Logical manner", of course, will differ from author to author and agency to
agency, but that's another story....) If viewers want to change the appearance of the
captions (just as they can change the appearance of a Web page today), fine.
Otherwise authors might as well just provide a plain transcript and nothing more.
I am hoping that the TT standard is **unlike** SMIL,
RealPlayer, Quicktime. These existing standards IMHO already provide
competent solutions where the **authors** intended presenation of the
material is preserved totally through the transmission chain to the display
surface.
I, too, am hoping for a format unlike RealText, QText and SAMI. Yes, they provide
competent solutions for the display of text, but they're incompatible with each other.
It's a real pain creating three different caption/subtitle files for a single presentation.
Geoff Freed
WGBH/NCAM
Johnb@screen.subtitling.com wrote...
In Digital broadcasting multiple subtitles are transmitted in parallel for
multiple languages.
Yes. For example, English-speaking viewers would receive subtitles for
English-speaking viewers, while French-speaking viewers would receive
subtitles for French-speaking viewers.
An important difference between subtitles and captions -- one of several
reasons why we must differentiate between them -- is that subtitles aren't
necessary for content already in the viewer's native language. Captions
are.
IMHO the distinction is simpler:
The distinction is that you classify captioning as a type of subtitle
because you own "subtitling.com"? :O)
Seriously, they're for different audiences (subtitles are dialog intended
for all speakers of a given language, captions are for the hearing-impaired
and contain more than just dialog) and have different mechanics (subtitles
should be displayed for all viewers who speak a given language, while
captions are specifically for the hearing-impaired), and TT must
differentiate between them unless accessibility is not a goal.
Again, I see no need for markup differentiating the type of text - why is
this felt necessary?
Between my last two posts on the topic this should be clear, but I welcome
specific questions.
-- Charles Wiltgen
geoff freed wrote...
incompatible
Do one of those come close than the others to being what you want TT to be?
-- Charles Wiltgen
None are complete solutions as currently structured, but between the three, i'd
choose RealText for its XMLish structure and its separation of streams (e.g., for
multi-language subtitling).
Geoff Freed
WGBH/NCAM
