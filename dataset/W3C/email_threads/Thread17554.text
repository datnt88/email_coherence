Hi,
How about a scenario like this? A blind student has to register for
a class via the web. The registration web page has multiple forms.
In addition, two different submit buttons are provided towards the beginning
of each form for different actions. Also, each form has a link to a help
web page for that particular form.
What features would be helpful for the blind student to choose the correct
form, fill it out and then submit it?
Which features should be in the browser and which supported by third party
accessibility software?
Scott
I'd like to offer the senario in more detail. In my experience, if you
are tabbing through a form and the input requires more than one form, you
should be able to go smoothly from one form to annother which is now not
often the case. The biggest problem with the gui as I see it where forms
are concerned is finding out exactly what to click on to submit them. to
answere the question, I use my screenreader to look at the lay out of the
page and this can change for the screenreader depending on what is
hilighted to determine where I need to go and what I need to do to get the
form datta entered.
some of what I'm attempting to construct here though changes from page to
page and different gui browsers but it is essentially up to the user of
the screenreader to get as much data as possible by exploration. this may
be mittigated by the adoption of guidelines which support keyboard
ability to move from field to field and from form to form.
in our current draft, this may already be incorporated depending on what
terms we use to describe the elements for which keyboard support is
requested.
for instance, is it possible that headers separate forms? is it possible
that a formfield can be enterpretted as a link? Lynx in its current
flavors solves this problem quite nicely by allowing formfields to be
numbered.
My last tip here again is that a good search fascility can help with this.
I often search for the form after having made myself aware of it through
use of my screenreader. by doing this with a good search tool, we can be
placed exactly where we need to be in each instance.
this is a silly thing I se all the time, one would think that the submit
buttons would be at the bottom of the form. I'd like the browser to
clearly tell me that the button is a submit button. or a clear or reset
button. this is often but not always the case.
I'd like to offer the senario in more detail. In my experience, if you
are tabbing through a form and the input requires more than one form, you
should be able to go smoothly from one form to annother which is now not
often the case. The biggest problem with the gui as I see it where forms
are concerned is finding out exactly what to click on to submit them. to
answere the question, I use my screenreader to look at the lay out of the
page and this can change for the screenreader depending on what is
hilighted to determine where I need to go and what I need to do to get the
form datta entered.
some of what I'm attempting to construct here though changes from page to
page and different gui browsers but it is essentially up to the user of
the screenreader to get as much data as possible by exploration. this may
be mittigated by the adoption of guidelines which support keyboard
ability to move from field to field and from form to form.
in our current draft, this may already be incorporated depending on what
terms we use to describe the elements for which keyboard support is
requested.
for instance, is it possible that headers separate forms? is it possible
that a formfield can be enterpretted as a link? Lynx in its current
flavors solves this problem quite nicely by allowing formfields to be
numbered.
My last tip here again is that a good search fascility can help with this.
I often search for the form after having made myself aware of it through
use of my screenreader. by doing this with a good search tool, we can be
placed exactly where we need to be in each instance.
Hands-On-Technolog(eye)s
touching the internet
voice: 1-(301) 949-7599
poehlman@clark.net
ftp://ftp.clark.net/pub/poehlman
Hi,
Just a couple of thoughts about deciding if a feature should be in a
browser or in third party accessibility software.
If a feature meets any of the following criteria, the feature should probably
be in the browser:
a. the feature falls into universal design because it can benefit both
disabled and non-disabled users
b. the feature can be benefit more than one disability, e.g. a feature
which helps both blind and quadriplegics
c. the feature is of such basic or significant benefit to a particular
disability group that the disability group would benefit from the
feature being centralized in the browser rather than re-created
in various third party accessibility software packages
The above 'c' criteria is included for situations where it makes
sense for the browser developer to do some work once rather than
perhaps screen reader companies using their limited resources to duplicate
each other's work. The disabled users also benefit in that it will
be easier for them to switch between screen readers without having
to learn all sorts of new browser commands associated with each screen reader.
(Screen reader developers can of course still add their own browser-specific
features.)
What do people think?
Scott
your statement about screenreader developpers duplicating each others work
may make the last point moot because if the browser provides the propper
information to the third party device, the only thing the third party
device needs to do is be sure to take advantage of it. perhaps we need to
develop annother third party device to go between but that may be a topic
for another time and annother list.
I'd say the strongest case can be made for features that can benefit all.
I'd also say that many features benefitting one using a screenreader can
probably benefit all even if that eans that the feature need be adapted to
fit annother catagory.
Hands-On-Technolog(eye)s
touching the internet
voice: 1-(301) 949-7599
poehlman@clark.net
ftp://ftp.clark.net/pub/poehlman
Hi,
I disagree with your point for a couple of reasons. First, how
much work will the developer have to go through to write and debug
the code to use the information provided by the browser? This
may or not may be trivial. My other concern is what are the advantages
to the blind user to have the feature provided by the screen access
technology versus the browser? I might be wrong about this, but I don't
believe that the blind browser user will want the browser functionality changed
out from under them each time they switch screen reader. Do you think
that blind users want this?
Scott
I'm not making myself clear. If on a technical level, there is a
universal standard set in place for certain types of behavior of browsers,
then the screenreader developpers can use that model to extract the
information needed. Windows.95 for instance can be readily used by people
with screenreaders in its basic form because of this focus. This was my
point scot. As I see it, we are reducing the need for code writing by the
screenreader developpers here and asking the browser developpers to
standardize on a set perhaps to be developped in the future.
annother point to keep in mind here is that if you put the onus on the
screenreader developper, unless you give them a fair amount of lead time,
the screen reader user will always lag behind everyone else when it comes
to upgrading and may even need to switch screenreaders in order to save
their job just because of the browser. I think the name screenreader is a
missnomer here the correct name is or should be speaking or braille
computer interface. The screen reader should be asked to present the
information in a way that the user can use it, but it is up to the
software developper to make it possible for the screenreader to do that to
a point at least. Perhaps what we need is a library that each browser
company can use to make it possible for screenreaders to see what is going
on and then to determine how to present that to the user.
Hands-On-Technolog(eye)s
touching the internet
voice: 1-(301) 949-7599
poehlman@clark.net
ftp://ftp.clark.net/pub/poehlman
Hi, Dave
I'm not quite sure of your approach here. Could you maybe give some examples
of what browser-related functions should be in screen readers
and not in browsers themselves? This would help give a better sense of what
information the guidelines need to specify that browsers should make
available to screen readers.
I tend to lean towards putting more functionality in the browser and less
in the screen reader as a way to minimize the lag between browser
enhancements and screen reader releases.
One area which I think is screen reader based is that the screen reader
should be able to speak intermixed text and button labels without
skipping. The browser should provide information to the screen reader
in such a way that it can do that.
I think that navigation is a shared responsibility. The browser should be
able to change the focus via keyboard action and the screen reader
should be able to speak the new area being focused on. (I'm not sure how
braille output should be handled.)
Scott
Hi,
Here's a pass at analyzing this scenario.
Scenario: A blind student has to register for a class via the web.
The registration web page has multiple forms. In addition, two different
submit buttons are provided towards the beginning of each form for
different actions. Also, each form has a link to a help web page for
that particular form.
There are actually a couple versions of this scenario. The simpler version
is if the student has used the web page before. Suppose he needs
to fill out the middle form on the web page. The student could search
through the web page looking for the form which could be rather
inefficient. The student's chore could be made much easier
if the browser provided a command or menu item which moved
the web page to the beginning of the middle form.
In the second version of the scenario, the blind student hasn't read
the web page before. When a sighted person pulls up a new web, he/she can
scan through the web page to get a sense of its structure. The blind
student can benefit from a browser command or menu item which pops up a
summary of the web page which includes such things as number of forms,
number of links, etc. The blind student can then find out that there are
three forms on the page. The blind student now has to read the
web page to find out which form he/she needs to fill out. One problem
that can crop up is that the web page may be set up in such a way that
that the visual cues for separating the forms are missed. The blind
student could benefit from the browser's including some annotation at the
beginning and end of each form including the number of the form.
After reading through the web page, the blind student decides that the
middle form needs to be filled out. This is the same problem as the first
version of the scenario and the blind student in this case could benefit
from the same solution.
Before the blind student starts filling out the form, he/she might want to know
more about the form. The student could benefit from a command or menu item
which describes the form. The description could tell how many fields
there are, any links in the form, how many text fields and how many
submit buttons. The student could then find out that this form has two submit
buttons to choose from instead of just one.
The student can fill out the fields in the form by using something like
the tab key to move to successive fields and buttons. The form
may not be clear about how labels and buttons are associated. In HTML
4.0, there is a label tag which associates labels and buttons. The blind
student could benefit from a command or menu item which describes the button
including information about label, current setting, etc. If the button
is a radio button in a group, the describe action for the button
could also tell which button is currently selected.
The blind student needs to know when the end of the form has been reached.
The tab action could stop at the annotation the browser has provided at that
the end of the form. The student now has to activate the right submit button.
The student could go back through the fields looking for the submit
button. However, if each button had an id, for example 2.3 which would mean
the third field/button on second form, the student could use a
command or menu item to tell the browser to navigate to that button or
to activate that button.
What do people think of this scenario analysis?
Scott
