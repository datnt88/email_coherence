Hello Joe,
Nikkud. I know all about them and they are rarely used in adult Hebrew.
Your proposal to force authors everywhere to use kiddie Hebrew
ain't gonna
cut it, Reuven.
I opened randomly Tom Clancy "Debt of Honor", do you know this book? It's
from 1995 and certainly not for children.
I opened it randomly at page 209 and found:
3 Russian words written with Hebrew letters with partial Nikud for better
reading.
1 word with partial Nikud so people will not read it wrong.
I opened another book and on the title the name of the author is written
with partial Nikud. Again for people to read it correctly.
I opened three other pages in the two books and could not find any Nikud.
What I am saying is that Nikud is not childish. You are right, people will
not read a book with all Nikud, but they will accept a book with small
amount of Nikud which will help them read the word correctly especially with
strange names.
Fix your adaptive technology. Don't try to tell people how to write.
The reason that you people have so good text to speech synthesizer in
English is because there is a large market for it in telephony, games and so
on. Text to phonetic in English is quite simple, but nobody thought about
blind people when created very good voices for English phonetic to speech.
Money makes the world go round.
Israel is small, Hebrew language has a limitation both in text to phonetic
and the regular money solving problems with the phonetic to speech. So,
nobody invests in text to speech in Hebrew. This is the best or almost the
best that can be done with the current efforts. We will be able to work much
harder and get a percent more and so on but we will never reach the 100%.
To the best of my knowledge, the problems in Arabic are the same. Maybe
someone here on the list which worked with Arabic text to speech can speak
about his experience.
Thank you,
Reuven Nisser
Ofek Liyladenu
Perhaps Joe knows all about japanese, too, and will tell us. In case he's
busy, or not omniscient, I can pass on what was explained by several people
at the face to face meeting that took place in Japan last year - essentially,
that there are similar problems. You could always look over the minutes to
find out who was there and get a summary version of what they said.
Additional detail may have come from Keio-based members of the W3C Team, and
some is from from Masafumi Nakane, a friend and former colleague (he and I
are part of the very small group of "former WAI staff") in japan who is
blind.
to go into a little more detail:
Japanese has 3 alphabets. Two are called "kana" - roughly, characters. They
look different, sound the same, and have a fixed number of letters with
strict phonetic rules. One, hiragana, is used for japanese words in "kiddie
script", for little grammatical things like prepositions, and wherever there
isn't a kanji, or you decided not to use a kanji. The other, katakana, is
used to write words that are imported into the language. Like Lisa was
talking about before, for hebrew, but perhaps more reliably, it is easy to
identify in japanese the words that are imported, because they spend a long
time being written in katakana...
But the "grown-ups" use kanji - characters that can be ambiguous in both
sound and meaning, and whose pronunciation is more or less impossible to
determine from their form. A university graduate is expected to know
some thousands of these. In adult books there is a mix of perhaps 50-70%
kanji and the rest kana - less kanji for kids books.
Braille, in japan, is written using an alphabet that corresponds to hiragana.
So creating any braille content actually requires being able to address the
issue of getting a "kiddie version" of it.
It's possible to create new kanji in Japan, like it is possible to create new
words in english. Except that there is no sure guide to pronunciation of them
from the component parts. (A former colleague at W3C has a unique kanji in
his name, created in this way).
Given all of this, the W3C, primarily at the instigation of East Asian
members (chinese has a some similar characteristics, with apparently
important differences) developed the ruby specification, a module for HTML
whose specific purpose was to allow explanatory content to be placed
alongside "primary content". Common use cases include business cards,
newspaper articles, and textbooks.
For a large number of common kanji, like in hebrew, there is enough to build
effective lookup tables (the glossary approach) so they can be pronounced
correctly by a text to speech engine. But for a large number of other common
kanji, and more particularly for less common ones, this isn't feasible.
Something that makes it possible to provide clear interpretation is therefore
important. One technique is to use clear characters, as used to write simple
documents pitched at a broad audience. It is preferable in a way that they
need not be always visible - think of the differences between closed and open
captioning on television.
I do not want to make any claims now about a priority of such a requirement -
I think that it is premature to assess priority without having looked at the
techniques available, the people who benefit, the type of benefit, the
alternatives, and then worked out what a rational scheme might be based on.
In the continuum between "authors should provide pre-recorded versions of
their documents, complete with powerful interactive VoiceXML navigation, in
several accents" and "wait for speech technology to be perfect", or between
"authors should provide captions, sign language interepretation, subtitles
and credits" and "make better speech recognition stuff so the user can watch
their own techology generate the version they want", I think we need to look
for some pragmatic solutions.
I am not a great fan of many technoogies around now - I think they could
easily be improved a lot. Others, despite being really hard to work with, are
impressive because of the technical complexity of what they do, or because of
the ingenuity required to develop some kind of workable system at all. But I
believe, as I did in 2000, that finding some base line that can be updated,
and that takes into account what is available in the real world, is
important.
Without some kind of agreed baseline, it seems to me premature to rule out
techniques for solving existing problems, whether those problems are caused
by the fact that people don't know what technology is available, can't afford
it, can't be bothered installing it, or cannot use it except if they have 9
different hardware and software set-ups to read a common website. Let alone
where the technology (speech recognition good enough to take to the movies
and have on-the-fly captions generated) does not exist yet.
Naturally, I have some ideas about this - I tend to favour (as Joe seems
to) standards-conformant implementations before looking at ways to cope with
obsoleted technology which does not conform to existing standards where other
systems do. I tend to favour forward-looking solutions over ones that break
future compatibility for the sake of backwards compatibility. But I don't
have firm rules on this yet, and I note that there is not consensus 3 years
after I last raised it. It isn't an easy topic.
By comparison, adding important accents might be fairly straightforward. It's
clearly the practice in arabic that some of these marks are added (it has
essentially the same approach as hebrew).
cheers
Chaals
Nikkud. I know all about them and they are rarely used in adult Hebrew.
Your proposal to force authors everywhere to use kiddie Hebrew
ain't gonna
cut it, Reuven.
Fix your adaptive technology. Don't try to tell people how to write.
Hello Charles
build
common
therefore
simple
they
open
One question though regarding the attached paragraph. When you look at a
single Japanese word is there always a one and only one way to pronounce it?
If so, then the problem in Japanese is "only" a lookup table for each word
and the phonetic representation.
In Hebrew and in Arabic, if you look at a single word, there are in average
2.3 ways to pronounce it. There are even words with 13 ways to pronounce.
Each pronunciation has a different meaning. To eliminate several
possibilities you need to analyze the sentence grammatically. To eliminate
more you need to get to text semantics.
For example, S-F-R could be SEFER (book) or SAPAR (barber).
Regards,
Reuven Nisser
Ofek Liyladenu
No, although in practice there are a restricted number of possiblities. One
difficulty is that japanese doesn't use word breaks, so you don't get to look
at a single word very often.
True, but the lookup table for "kiddy japanese" is extremely large. If
Moore's law continues to apply we could expect it to work in computers at
some point, but like doing grammar analysis by brute force, it isn't
currently feasible as I understand it.
It would be nice to have some people more versed in japanese than I am in
this discussion. But the culture of this list can be intimidatory by american
standards. From other perspectives it is considered bullying and abusive.
This explains some of the reluctance of people to participate even when they
have important contributions to make. There are other things like limited
time, a generic fear of being ridiculed or ignored for incorrect language
which is exacerbated by the fact that it happens uncheced here, or not
actually being able to keep up with the pace of the discussion, which have an
impact too.
Cheers
Chaals
Hello,
In Germany the parliament member Hubert H?ppe has a site and claims that
this is WCAG-AA-compliant.
Ironically under the WCAG-AA-logo is stated that the site is accessible
for people with visual impairment.(http://www.huberthueppe.de )
Roberto:
The problem is that there are not a lot of localization.
In the document (i've done the italian version so i know) is clear that
it isn't a certification and the only responsable is the person that put
in the web site.
If the logo is a trade-mark (but i don't think so), W3C can legally act
versus wrong use of it.
Hello,
In Germany the parliament member Hubert H?ppe has a site and claims that
this is WCAG-AA-compliant.
Ironically under the WCAG-AA-logo is stated that the site is accessible
for people with visual impairment.(http://www.huberthueppe.de )
Realizing that using WCAG-logos is also always more a commercial reason
for impressing clients or competitors, I think it is better that in the
page with the download conformance logos
something like:
showing the conformancelogos on a page means that the page has been made
as accessible as possible for all visitors, corresponding to the
claimed conformance-level.
And that claiming accessible for one or more specified groups of
visitors violates the meaning and prohibits the use of these
conformance-logos.
Why is the text "Responsibility for accuracy of claims" in the bottom of
this page? Only few peole will scroll the page more than seeing the
conformance-logos and read it. Is not it better to move this text just
above the text "how to use the logos"?
Perhaps WCAG can ask the parliament member to remove the
conformance-logo from mentioned page?
Is any authority existing that can remove logos from pages when the
logos are very clearly misused ( e.g. no valid code and claiming level
aa or aaa) and people are not prepared to remove the logo? I mean
things that can be tested by every online accessibility (like Bobby or
WAVE) or (x)html-validation tool?.
Cheers
Ineke van der Maat
Hallo Yvette,
Thanks for your mail.
If I have a page that conforms to WCAG level AA, I can both place a
WCAG-AA-logo and state that the site is accessible for people with
visual
impairments if I want to, can't I?
WCAG-AA, though the WCAG-AA-logo is in the site..
My concern is that accessibility logos will get an emty meaning (and
perhaps accessibility) when showed on pages that does not pass automatic
tests like Bobby or WAVE.
And writing a statement under a logo as: accessible for people with
visual impairments gives a certain explanation of the logo to people who
don't understand what the logos really mean. And that is still always
more than 85% of the visitors.
I even have seen a site of a web design company that claim their CMS
produces accessible site and you can chooce a site with A, AA or AAA
logo. Nowhere in the site is stated what this really means.
The company site is not valid and accessible at all, but who cares for
that? The WCAG? Even member-sites are not valid (X)html and at least
WCAG-AA conform.
Greetings
Ineke van der Maat
Hello Eric,
Thanks for your mail.
Using the A, AA or AAA logo means more than just being accessible to
people with visual disabilities. It is also more accessible to
everybody
else and to people with other disabilities.
Of course I know what the logos really mean. But not most persons
outside the accessibilityscene and these are still always more than in
it.
Writing such a text below the logo opens a door for much other
(commercial) slogans. I even can write below it "accessible for people
who can use the mouce with their left hand" or 'accessible for people
who can use a keyboard" I think that this, just like misguiding
advertisement must be forbidden.
I never talk about accessibility is a business case, but always about
accessibility must be as usual as bread. Simply because everybody has
the right to visit a site to get the information/products she/he wants.
The Canadian magazine Adbusters has a very nice action: "know the
media, change the media, be the media." This is also very valid for the
internet and an accessible site makes it certainly more true.
Greetings
Ineke
I guess we all know that Bobby evaluation ain't infallable. But the Hueppe
site definitely ain't WCAG compliant (at any level).
There indeed is the risk that conformance logos are abused and get diluted
by non-compliant sites. By the way, I think there'll be of course some rotten
apples, but most site using conformance logos either seem to conform or
obviously take pains to conform to WCAG guidelines yet.
Best regards,
Jens.
Jens Meiert
Interface Architect
