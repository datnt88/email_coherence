[... suggestion for XML catalogs ...]
I support the _idea_ of this proposal, because it gives an impetus to
creating a managed namespace. Sometimes such namespaces can be cheap
to create and it simply needs some-body to make a proposal which is
sufficiently convincing, and suffiently simple to implement that everyone
sees the value and adopts it. (IMO MIME has some of these features though
it also has design flaws.)
At present the most obvious namespace management available to everyone
is DNS. (For example, in 'Java in a Nutshell', p 19, O'Reilly show how
it can be used to provide a unique namespace for any Java package, e.g:
COM.ora.writers.david.widgets.Barchart;
(The first two components are the domain name in reverse order).
I am not familiar with the URN process in detail - am I right in assuming
that it based on DNS?
Let's suppose that "-//FOOCORP::FOOAUTH//DOCUMENT sometitle
ver1.01//EN" fails to find resolution at the local level. Postulate
the existence of a server (probably mirrored, but let's stay above
that level of detail for the nonce) funded by every organization that
wishes to use this mechanism. Let's call this server xmlid.net. That
server does not have a listing for every FPI; all it has is one (and
only one) entry for every publisher that has joined the cooperative.
Jon, could you expand on this word, please? If it means 'Those large
corporations whose business is publishing information and who are prepared
to pay for a maintained site (xmlid.net) to be set up'. If this is the
case then it will lead either to a fragmentation of the community, or to
a proliferation of 'xmlid.net's (e.g. 'xmlid.net.ac.uk', 'xmlid.bio.net')
So on that server there is a single lookup table cached in RAM, one
line of which consists of FOOCORP::FOOAUTH on one side and
foodocs.foo.com on the other.
This server is going to have to be funded somehow, with a registration process
and removal of dead entries. Will it, in itself, be able to scale to
respond to demand or will there be a DNS-like system of servers?
Add to the abilities assumed for the XML client under the XML catalog
proposal the following: it can query xmlid.net with the string
FOOCORP::FOOAUTH and get back foodocs.foo.com; it can then query
foodocs.foo.com for its corporate catalog; and it can add that
corporate catalog to its own for long enough to resolve the query (or
fail, but that's entirely FooCorp's responsibility).
This isn't enough to build a resolution mechanism, but it's enough to
think that building one might be possible. Is there anything
basically wrong with the idea?
It seems to involve a mapping of organisations onto domain names. For
example SUN:: would map onto sun.com (right?). Is SUN:: the only
component of SUN or are there also SUNSOFT, SUN_MICROSYSTEMS, etc.
It seems to me that it is necessary to have a feel for the stability
of organisation names before you can get an idea of the work involved.
If domain names are a useful approach, what about the use of
something like:
This says, in effect, if your site (or server) has implemented XML then
this is reserved request for the XML catalog that relates to XML
information on that site/server.
It's unlikely to clash with existing namespace (apart from people who
used XML for something else :-). Webmasters could easily implement it,
and it should be fairly straightforward to update the local catalog.
P.
Peter Murray-Rust, (domestic net connection)
Virtual School of Molecular Sciences, Nottingham University, UK
As I understand it, there is no URN process:
Last, this document intentionally does not address the problem of
name resolution, other than to recommend that for each naming
authority a name translation mechanism exist. Naming authorities
assign names, while resolvers or location services of some sort
assist or provide URN to URL mapping. There may be one or many such
services for the resources named by a particular naming authority.
It may also be the case that there are generic ones providing service
for many resources of differing naming authorities. Some may be
authoritative and others not. Some may be highly reliable or highly
available or highly responsive to updates or highly focussed by other
criteria such as subject matter. Of course, it is also possible that
some naming authorities will also act as resolvers for the resources
they have named. This document supports and encourages third party
and distributed services in this area, and therefore intentionally
makes no statements about requirements of URNs or naming authorities
on resolvers."
Paul Prescod
[Peter Murray-Rust:]
Yes. See
draft-ietf-urn-naptr-01.txt
draft-ietf-urn-http-conv-00.txt
I don't understand the URN proposal completely, but it seems to be
attempting vastly more than what we need.
Let's suppose that "-//FOOCORP::FOOAUTH//DOCUMENT sometitle
ver1.01//EN" fails to find resolution at the local level. Postulate
the existence of a server (probably mirrored, but let's stay above
that level of detail for the nonce) funded by every organization that
wishes to use this mechanism. Let's call this server xmlid.net. That
server does not have a listing for every FPI; all it has is one (and
only one) entry for every publisher that has joined the cooperative.
I mean what you think, but I don't agree that fragmentation follows.
Let's postulate the existence of some organization whose function is
to provide such a service and make just enough to pay for itself and
the salaries of the people it employs. Take the net operating cost
every year, divide by the number of "publishers", and that's how much
you charge each publisher. The service provided is pretty simple:
maintain one line in a lookup table and respond to HTTP queries giving
the left hand side by returning the right hand side. This should cost
no more to provide than the typical DNS entry. (And we might take
advantage of the fact that this is not DNS by putting in place review
and arbitration procedures that take advantage of what has been
learned from the DNS registration experience.)
I am quite unqualified to make a detailed proposal on how to set this
up, but I believe that something along this line could effectively
solve the FPI resolution problem. I know that at Sun we are setting
up a collaborative authoring system that automatically assigns FPIs to
every publication and resolves those FPIs in our distributed
publishing system through distributed partial socats which all fall
through, in the worst case, to a single socat that we maintain at
docs.sun.com (not yet publicly visible, but soon to appear). So for
our purposes, which I believe are commensurate with the needs of the
great majority of publishers, a system that redirected someone trying
to resolve an FPI beginning "-//SUN::SUNSOFT//" to docs.sun.com would
work just fine.
Jon
