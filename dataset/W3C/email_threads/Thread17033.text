I've had a comment regarding the way Page Valet reports WCAG
accessibility warnings. My correspondent[1] thinks it should
mention any WCAG points that are untested, as this is how some
other accessibility tools work and it makes Valet seems less complete[2].
As it stands, Page Valet will generate warnings when it detects an
error (or potential error). When it applies a test that is passed
it says nothing. When it doesn't apply a test, it says nothing.
Now the suggestion is that is should - conceptually - test every point
in the WCAG. In cases like #14.1/etc that self-evidently can't be
tested by any tool, it should issue a nag message - whatever page
is being tested.
Now, I have several reasons not to apply this kind of completeness.
But maybe I'm missing the wider view. Comments, please, on:
* Nag messages are a turnoff. If more than a couple of messages
are repeated in every evaluation, users will rapidly learn to
ignore them.
* If we say that Valet should exhaustively list every point in WCAG,
are we not saying that WCAG itself is the best test tool - and the
only one that is never wrong?
* Valet applies tests to every element and attribute, and displays
messages in place in the source code. This is designed to make it
more useful to its users:
"there is an error right here"
as opposed to
"there is an error somewhere"
Listing tests per-document is an entirely different approach.
* Because Valet applies per-element tests, there are tests that
are both applied and not applied. For example, #4.1/#4.3 (the lang
attribute) is tested for the html element[3], but not for other
elements. Yet to be exhaustive, we should test *every* element,
lest it contain a passage in another language. For the tool to
be manageable at all, it needs to make compromises.
* Bottom line: too many nag warnings will dilute the overall message
of the tests - like useful content getting buried in waffle or
(in our times) spam.
Now, one possible solution here is to retain the present scheme
(modulo updates) for the human-readable HTML reports, but to include
the additional nag messages in the machine-readable EARL reports
so they get into databases populated by Valet (such as W3C's
Annotea).
[1] She reads this list, so she'll doubtless reply if I'm
misrepresenting her.
[2] Section508 testing does take this more legalistic nagging approach.
That works because 508 is much briefer, and expressed in terms that
are easier to incorporate into an automatic tool than WCAG.
[3] The lang attribute for html shouldn't be necessary at all in the
presence of an HTTP Content-Language header. But testing for it
seems to be a requirement for any WCAG testing tool.
Nick Kew
Site Valet - the mark of Quality on the Web.
I just posted a comment to an identical message crossposted to the
comp.infosystems.www.authoring.tools and c.i.w.a.html groups on Usenet. I
wonder what would be the most constructive approach to achieve useful
discussion. Maybe continue on Usenet? I'm afraid interested people might
miss some relevant points made on another forum, if the discussion is
carried out on two independent fora.
Jukka Korpela
TIEKE Tietoyhteiskunnan kehitt?miskeskus ry
Finnish Information Society Development Centre
Salomonkatu 17 A, 10th floor, FIN - 00100 HELSINKI, FINLAND
Content-Language specifies multiple langauges and is for content
negotiation. The lang attribute specifies exactly one language and,
in part, controls rendering.
Erm - no.
Accept-Language in the HTTP Request specifies multiple langauges for
content negotiation. Content-Language in the HTTP Response identifies
the actual language of the document returned.
Nick Kew
Site Valet - the mark of Quality on the Web.
I think it is best to give info on the "untested" points - probably
not as a "nag" as you put it, but as a short summary of the other
issues people need to be aware of. It wouldn't have to be part of
every set of test results.
People using your tool may not be aware of the "untestable" WCAG
items, and if using your tool is the ONLY thing they do to "cover"
accessibility, they may never find out, unless the tool alerts them
to the issues.
Cheers
Rebecca Cox
Erm No!!
From RFC 2616:
The Content-Language entity-header field describes the natural
language(s) of the intended audience for the enclosed entity. Note
that this might not be equivalent to all the languages used within
the entity-body.
Content-Language = "Content-Language" ":" 1#language-tag
Note the 1# and the (s). Some more:
Language tags are defined in section 3.10. The primary purpose of
Content-Language is to allow a user to identify and differentiate
entities according to the user's own preferred language. Thus, if the
I.E. it is to help resource selection, not to control rendering.
body content is intended only for a Danish-literate audience, the
appropriate field is
Content-Language: da
Multiple languages MAY be listed for content that is intended for
multiple audiences. For example, a rendition of the "Treaty of
Waitangi," presented simultaneously in the original Maori and English
versions, would call for
Content-Language: mi, en
Yes, the reference to an *Entity Header* is exactly that: it describes
an entity. However, that is a very general case. My reference was
to its use as a *Response Header*, which is more specific.
That would be appropriate to a multipart entity, perhaps comprising
multiple copies of a document in different languages. It's dealing
with bundled collections, and perhaps with HTTP PUT transactions.
It is not dealing with single HTML or XML documents, which is all
either a web browser or Page Valet normally deals with.
In an entity that is a single HTML page, it serves exactly the same
purpose as the lang attribute to html .
Nick Kew
Site Valet - the mark of Quality on the Web.
The English/Maori example seems very much to me to refer to a single
page, but, for a concrete example, try:
http://www.ocrat.com/biling/pridprej/chap0101.html (note that this
Whilst this particular example has a bias towards English users,
if you look at it without the automation features it could be used
in the learning of either of the languages.
Basically, the ability to use the HTTP Content-Language is a last resort
default, not, I believe, a suggestion that that is the preferred method.
If it were the preferred method, then including it with meta would have
to be the de facto preferred method, given the difficult people seem to
have with specifying charset with real headers. As such, it would seem
to me a much more ugly solution (in my view, meta was largely added for
bad reasons, and, in some cases has actually caused the atrophy of much
more hyperlink like alternatives).
Yeah, I think in a user interface it is helpful to be clear about what hasn't
been tested - especially in something that is basically involved in testing.
(By the way, there are strategies for automating things like simple language
testing and repair - at least to the point of having an interactive
machine-supported process. Wanna challenge? ;-)
cheers
Chaals
I think it is best to give info on the "untested" points - probably
not as a "nag" as you put it, but as a short summary of the other
issues people need to be aware of. It wouldn't have to be part of
every set of test results.
People using your tool may not be aware of the "untestable" WCAG
items, and if using your tool is the ONLY thing they do to "cover"
accessibility, they may never find out, unless the tool alerts them
to the issues.
Cheers
Rebecca Cox
Location: 21 Mitchell street FOOTSCRAY Vic 3011, Australia
(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)
