Hi,
Screen readers like JAWS with multilingual synthesizers like Eloquence are
beginning to be able to swich language on the fly. In JAWS it has worked
since before version 4, or it mayh have been added in version 4, and with
the release of JFW 5 in september JAWS kan now identify the language if it
is marked up. The question is not tto markup every word that may originate
from other languages e.g. English but to markup a block of text written in
a another language, and then hope that the screen reader has an installed
synthesizer that can speak this language, and you never know on the
devvelopper site of the webpage but that is life!
Also remember that for braille devices the same applies for reading
contracted braille.
Claus Th?gersen
jens.meiert@erde3.com
y.p.hoitink@heritas.nl
w3c-wai-gl@w3.org
[...] Specifically, we were talking about the need to identify the
language,
including language changes, since not doing so could lead to serious
accessibility problems.
Well, can language really cause accessibility problems (more important:
when
does it not)? First of all, each language vocabulary differs from another,
second, even every person uses another vocabulary than the other. But to
diagnose accessibility problems, you need a clear definition of each
language
vocabulary by defining a standard set of words and terms each native
speaker
-must- control (can anybody really say what all fellow countrymen
understand?).
Assuming that there is such a virtual standard set for each language, you
at
first had to decrease the maximum (native) vocabulary about maybe 98%
whereby having set a minimum age for this set to about 10 years. You also
pass on
every non-native term to ensure that you can offer that accessibility you
want. -- What I exaggeratedly show here is that you IMO try to find a way
to an
ill-defined goal.
Due to this ill-defined goal, there is no chance for either recommending
or
banning or judging anything, neither for you nor the WAI WG. Me, I
perceive
the WAI as an initiative suggesting how you've got fewest problems in
reaching
your audience, although I understand your feel of maybe powerlessness when
noticing a language soup everywhere, but this is normal and (again)
self-regulating, and it also supports everyone's ability to -increase- his
vocabulary
(what a beautiful impact).
[...] Making a page such as the LogicaCMG one
accessible would require, in my opinion, that each English phrases is
identified as such.
Why? Making clear that 'email' is English, or 'Nachricht' ist German? Does
it make sense? -- How? Visually highlighting it to irritate users once
more
when visiting an almost colored site? Semantically pronouncing it to
complicate
author's work and to allow the desired effect deflagrate?
My task as I saw it was to come up with examples where language changes
would lead to accessibility problems. [...]
Did you really prove that there are accessibility problems or did you
merely
prove that international companies use a mix of languages? -- I think that
there are rather -guessed- problems than real problems, or did you test
these
interfaces? Ain't most users also affected by the mix in e.g. advertising,
when most of all larger companies use English slogans, everywhere you
look? Do
you want to intervene only related to the Web, or do you want to start a
campaign to free the world from all these guessed problems?
-- Well, maybe I'm wrong, but there are so many issues I see in this case
that they are hard to ignore. Finally, I recommend to pass on every
influence
related to language use except when you use e.g. hyperlinks to sources in
another language or include cites on your site written in another language
(and
there already are solutions for these de facto accessibility -- or
usability
-- problems).
Best regards,
Jens.
Jens Meiert
Interface Architect
Hi Claus,
In the examples I gave in my article
(http://www.heritas.nl/wcag/language.html) which examples do you think would
need to be marked up? How can we give clear guidelines so a developer knows
which foreign words have to be marked as such?
My personal estimate is that the Shell website would be OK as it is (page
marked up as Dutch even though there are some English words) where the
LogicaCMG website would need a lot of markup to identify English texts.
Marking up foreign sentences would fall into the 'must do' category for me,
whereas marking up occasional foreign words would be a 'should do' or even
just 'could do' depending on how easy it is to recognize the word when
pronounced in the main language of the text. "Sitemap", even when pronounced
in Dutch, can be easily recognized. "Email" on the other hand, becomes a
different word with a different meaning when pronounced in Dutch (thanks to
Ineke for the example).
There will always be cases where there just isn't a solution within the
current HTML specs, even if you want to go out of your way to mark up every
foreign word. Cadeaushoppen is an example of this: the word 'cadeau' is a
Dutch gallicism, 'shoppen' is a Dutch anglicism but the combination will
probably never be in the official Dutch word list. It would be wonderful if
the HTML standard could incorporate a mechanism to phonetically describe how
to pronounce such words, but that's just blue sky thinking. Working within
the current standards, we can only attach one language to each word.
Also, could you please clarify what you mean by contracted braille? I am not
familiar with this term but would deduce that it involves language-specific
abbreviations to speed up braille reading, is that a correct assumption?
Yvette Hoitink
CEO Heritas, Enschede, The Netherlands
E-mail: y.p.hoitink@heritas.nl
Very interesting message about multilingual texts, Yvette! Thanks.
You asked about the term "contracted braille." Your assumption is correct-- it involves dot-configurations that represent multiple letters or even entire words. In English, for example, the word "for" is represented by a Braille cell containing all six dots. The word "the" is represented by dots 2,3, 4, and 6. (The cell is arranged in two columns of three cells each; numbering goes vertically, so column 1 contains dots 1-3 and column 2 has 4-6.)
John
"Good design is accessible design."
Please note our new name and URL!
John Slatin, Ph.D.
Director, Accessibility Institute
University of Texas at Austin
FAC 248C
1 University Station G9600
Austin, TX 78712
ph 512-495-4288, f 512-495-4524
email jslatin@mail.utexas.edu
web http://www.utexas.edu/research/accessibility/
Hi Claus,
In the examples I gave in my article
(http://www.heritas.nl/wcag/language.html) which examples do you think would need to be marked up? How can we give clear guidelines so a developer knows which foreign words have to be marked as such?
My personal estimate is that the Shell website would be OK as it is (page marked up as Dutch even though there are some English words) where the LogicaCMG website would need a lot of markup to identify English texts. Marking up foreign sentences would fall into the 'must do' category for me, whereas marking up occasional foreign words would be a 'should do' or even just 'could do' depending on how easy it is to recognize the word when pronounced in the main language of the text. "Sitemap", even when pronounced in Dutch, can be easily recognized. "Email" on the other hand, becomes a different word with a different meaning when pronounced in Dutch (thanks to Ineke for the example).
There will always be cases where there just isn't a solution within the current HTML specs, even if you want to go out of your way to mark up every foreign word. Cadeaushoppen is an example of this: the word 'cadeau' is a Dutch gallicism, 'shoppen' is a Dutch anglicism but the combination will probably never be in the official Dutch word list. It would be wonderful if the HTML standard could incorporate a mechanism to phonetically describe how to pronounce such words, but that's just blue sky thinking. Working within the current standards, we can only attach one language to each word.
Also, could you please clarify what you mean by contracted braille? I am not familiar with this term but would deduce that it involves language-specific abbreviations to speed up braille reading, is that a correct assumption?
Yvette Hoitink
CEO Heritas, Enschede, The Netherlands
E-mail: y.p.hoitink@heritas.nl
I don't want to be perceived as destructive, but there are at least two
other aspects (although very specific) which make any semantic emphasis of
language changes difficult and/or not practical:
Case 1 is the use of content management systems which enable technically not
inevitably experienced editors to create and publish texts -- it will get
difficult or even impossible a) to create simple and usable mechanisms to
emphasize other language words and b) to maybe coach and above all motivate all
editors to use these mechanisms.
Case 2 are old or 'dead' languages -- is e.g. the entire Latin vocabulary
treated as part of each language? Is it treated separately (and has to be
marked up as ISO 639-1 conform 'la')? Are there problems with user-agents reading
Latin text? It might be very difficult to remove the at least rhetorically
important Latin vocabulary from more or less sophisticated texts.
I really like the enthusiasm in this discussion, as I appreciate all
altruistic intentions on this list, but I never felt that sceptical facing this
challenge. If it is recommended (not mandatory) to emphasize terms in another
language, I can live with it -- otherwise I fear the day when having to write
p xml:lang="en" span xml:lang="fr" R?sum? /span :
My span xml:lang="la" conclusio /span implies a reasonable use
of language to make sure all people over the world are satisfied with
what I'm saying. Maybe someone has problems with my firstname,
since xml:lang="de" Jens /span might be difficult to spell in some
languages; even xml:lang="de" VW /span now has problems to
define a correct language to its brand. But since em they /em
prohibited spelling misttakes, all the rest seems fine. /p
All the best,
Jens.
Jens Meiert
Interface Architect
On Thu, 4 Dec 2003 14:15:57 +0100,
In general, I agree with this. I think this is true especially for
Western languages.
In East Asian languages, and when they are represented using Unicode,
it is extremely important to identify the natural language in order
for the speech/Braille output technologies to correctly render the
content, since there are characters that are used, for example, both
in Japanese and in Chinese, but of course pronounced differently.
Now, when phrases originally came from Chinese are used in Japanese
text, and if it is marked up as Chinese, then, probably majority of
people would not understand it just by listening to it since Japanese
know such phrases with Japanese way of reading them. This is also
true for Chinese proper nouns. When they are read in Japanese, they
are pronounced differently from how they are pronounced in Chinese, in
most cases. But if it is something like textbook of Chinese language
written for Japanese speakers, then it is probably essential to
specify the language.
So, I believe specifying the natural language of block of foreign
text, like paragraph, is must, while foreign text of length shorter
than that, like sentences/phrases/words/characters, is should.
Cheers,
Max
