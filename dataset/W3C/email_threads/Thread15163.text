Hi,
As an introduction to our discussion of what the Technology-specific
Checklists layer of WCAG 2.0 might look like, Paul, Wendy and I have
been working on a few sample pages and collecting issues and ideas for
the group to review as we begin the process of making decisions about
how the checklist should take shape. The checklists, which are described
in the second section of "How to read this document" in the latest
draft, are intended to "provide information on what is required when
using different technologies in order to meet the WCAG 2.0 Working Draft
access guidelines."
Much of the information included below is a compilation of ideas and
discussions that began in small group work at the July face to face in
Linz. In case anyone is interested in reviewing the discussion that took
place there, I've added links to the original draft pages that were
presented at the end of the face to face to the minutes, which are
available at
Many thanks to Paul, Bengt, Avi, Christian and Wendy for help in
brainstorming and working through these ideas.
Issues and questions:
*In addition to understanding how to succeed in meeting the
guidelines, how can this checklist also describe how and where
techniques or technologies might fail? For example, should the document
make it clear that, for a technology that by definition can not address
a specific checkpoint, make a statement asserting that meeting a
checkpoint in a given technology is not possible? Some suggestions for
addressing this issue include:
1.only generate techniques documents for technologies that meet
WCAG 2.0 at the minimum level
2.include a "not possible" category that describes how some
techniques or technologies may fail and suggest alternatives
3.create an other technology that allows for newer technologies
and techniques to be used in meeting a checkpoint. That way, the message
isn't that authors shouldn't use a technology. Instead, it simply means
that we don't have techniques yet and provides an opportunity for author
to explain how the checkpoint was addressed.
*How much ongoing work will the group be able to do on this layer
(and the techniques documents) after WCAG 2.0 becomes a recommendation?
*If the checklists include all of the checkpoints (21 in latest
draft), success criteria (80 in latest draft) and techniques (there will
likely be multiple techniques for each success criteria) in one place,
the document is likely to become quite long. How can we best optimize
the checklists so that they are optimally usable and minimally
overwhelming?
*At this point, it's not clear exactly how the techniques relate
to whether or not an author has passed or failed a given success
criteria. For example, where 5 techniques exist to address a single
checkpoint, it's not clear how the techniques would be prioritized. Is
it possible that in some cases one technique will be
preferred/recommended over another given the current state of user agent
support? Will it be possible to insert something that, for example, says
you will have passed a success criterion if you have applied x number of
techniques below?
*For level 2 assurance type success criteria (e.g. the content
has been reviewed and .), should a unique set of techniques be included
for each? Would all of the review requirements of this type be addressed
with the same set of techniques or would these recurring techniques be
described elsewhere? Also, does it make sense to include a space for a
reviewer/author to document what they've done or observed related to the
review process?
*Checkpoint 3.3 was included in the sample checklist drafts so
that we could take a look at how a checkpoint that includes additional
ideas might look. Does it make sense to include the ideas here or is it
likely that each idea will need its own list of techniques?
*The drafts currently don't link into the techniques documents
because there's nothing to link to at this point in time. When we do add
links, do we want the entire rule element that will be pulled from the
techniques to become a link or should we consider including a techniques
numbering system and provide shorter links at the front end as we have
with checkpoints and guidelines?
Draft pages:
*An example of a basic checklist layout is available at
there are a number of areas where information is missing, not yet linked
in, or not yet available, it illustrates how we might handle different
types of checkpoints and success criteria in checklist form and puts
forth some ideas for addressing some of the issues described above.
*An alternate example, available at
illustrates how the checklist may be presented in a more block-level
organization. This layout provides some more explicit grouping of
success criteria under their respective checkpoints as well as changes
the order in which the information is presented by presenting the
techniques available for addressing a particular success criteria before
querying the user for pass/fail decisions. Additionally, this layout
provides additional space for an author or reviewer to include notes as
to how a success criteria passed, failed, or did not apply.
Next steps:
*Paul has been working with some of the ideas surrounding
creating static and interactive renderings of the checklist document and
will be posting a follow-up note describing some of the issues and ideas
we've addressed thus far.
*Wendy will create a page to add to the above collection of links
that will show how an author might utilize the checklists to evaluate a
page or site.
*A number of organizational changes will need to be made to the
current working draft in order to effectively refer to individual
success criteria.
*Once we have consensus on how the checklists will take shape, a
transformation to automate the process of pulling the appropriate
information from the guidelines and techniques documents will need to be
developed so that we can easily update the checklist as each source
documents evolves.
*We'd also like to tie in some of the work that is being done at
W3C in the internationalization group regarding implementation
guidelines to generate more dynamic views of the checklist. Richard
Ishida, who is a W3C team member and has had some experience developing
implementation guidelines for Xerox has been sharing some of his
philosophies about creating checklists with us recently and we're hoping
to collaborate further with him to explore some ideas for creating
document views that are somewhat more interactive and flexible. An
example of this might be to utilize an expanding/collapsing mechanism
that would allow users to drill down through the checklist, exposing,
for example techniques for a given success criteria one at a time.
Discussion on this topic is on the Agenda for the September 5 Telecon.
Thanks,
-Ben
Ben Caldwell | mailto:caldwell@trace.wisc.edu caldwell@trace.wisc.edu
Trace Research and Development Center ( http://trace.wisc.edu
Ben has raised a number of significant questions in his summary. By
way of contribution to this discussion, I have several personal
opinions to offer, as usual. These are placed before the group for
discussion and debate, as necessary.
1. I think "dynamically-generated" presentations would be preferable,
if they can be implemented given the resources available to the
group. For example, if I am evaluating a web site that uses a given
combination of technologies, I should be able to generate a
checklist that specifies all of the techniques relevant to my
situation, with references to the success criteria that they
satisfy. Alternatively, if I am writing an authoring tool which
implements a given technology and I want to ascertain what
techniques should be followed in order that my tool can produce
highly accessible output that meets WCAG 2.0, then I will need a
checklist that is restricted just to the technology in question.
2. Ben inquired how technologies which, individually, aren't relevant
to all of the checkpoints should be treated. One solution would be,
instead of taking each technology separately, to write techniques
which presuppose that certain technologies are used in combination
with each other. For example, XHTML is typically used with one or
more audio or image formats, and with a style language (usually,
but not always, CSS), so it might be better to combine the relevant
techniques and examples under the assumption that certain types of
technology are typically used together. If this combining could
take place automatically it could be very flexible indeed, and such
a possibility might be worth investigating further. CSS is a good
example of a technology for which there are techniques, but it is
always used in conjunction with XML or HTML. The conformance claim
would be made in respect of the combined XML/XHTML/HTML/CSS etc.,
content; and it should be easy for an author to obtain a checklist
that recognizes this fact. I don't want to work through one
checklist for XHTML, another for CSS, etc., but rather to complete
a single, unified checklist relevant just to the technologies which
I have chosen. Whether this desire can be practically managed
remains an open question, but we should at least consider the
issue.
3. Regarding the review requirements in the level 2 success criteria,
by definition there aren't any "hard and fast" rules for
determining whether the content has the indicated characteristics;
this is why the success criteria say that a review must be carried
out (taking into account the information we provide), and, on that
basis, an opinion formed. The review should be undertaken according
to a consistent process and may involve testing with actual users
(cf. Appendix B of the latest internal draft). We may be able to
provide advice in the techniques on how to conduct such reviews.
Beyond that, I don't think definite technology-specific techniques
can be laid down; if they can, then they ought to serve as the
basis of further success criteria in the guidelines proper. The
Education and Outreach working group, as I recall, has been working
on issues of content evaluation and may have advice to give
regarding "best practice" in the conduct of qualitative reviews.
Also, we can offer (technology-specific) examples of what we regard
as exemplary.
4. As already indicated, I think we should distinguish carefully
between techniques and examples. When Wendy and I reviewed the
guidelines last November to gain an overview of how they related to
the techniques, we discovered that there were many issues best
addressed in "core" techniques, without referring to any specific
technology, but for which we could also provide technology-specific
examples. Thus, an explanation of how to write a good text
equivalent (checkpoint 1.1) need not refer to any particular
technology, but we can certainly provide examples of how checkpoint
1.1 as a whole is implemented in specific technologies, for example
SVG or XHTML. There aren't so many points in the guidelines at
which technology-specific advice is needed (what I mean is that
they tend to relate to certain checkpoints in the docment, e.g.,
under guidelines 1 and 2, less so in guidelines 3 and 4, and again
in guideline 5, to make a broad generalization here).
5. It has sometimes been suggested that the WCAG 2.0 techniques should
state explicitly which techniques, in which combinations, are
regarded as satisfying specific success criteria, and which ought
instead to be considered as alternatives. To be specific,
implementors want to know, for example, that a given success
criterion can be satisfied by implementing either technique A, or
techniques B and C together. This kind of information is essential.
I don't have a firm opinion on whether alternatives should be
prioritized. Obviously, selection among alternative techniques is
likely to be governed not only by technological factors (issues of
user agent baseline, checkpoint 5.2) but also the author's design
preferences more generally. I would argue that each technique which
relies on a particular feature of a technology should indicate, at
least, the version of the technology in which the relevant features
first became available. Whether filtering can be carried out with
respect to this information depends on how we set up the dynamic
checklist generation system, which appears to me increasingly to
take the form of a data base with a prescribed set of fields for
each technique.
I think that covers many of the issues which Ben raised.
Thanks, Ben, for getting out the information about the checklists.
I have been working on a prototype "gateway" interface for accessing the
checklists. We decided to present things in a step-wise fashion. On the
first page, the user selects whether to access a static or an
interactive version of the technology checklists, On the next page, the
user selects which technologies to include (e.g. HTML, CSS, script,
etc.).
Along the way, the user can also choose to create a custom checklist
(either static or interactive).
Just so you know, when I say "static checklist" I mean a version of the
checklist which is best suited to online viewing and/or printing out on
paper. When I say "interactive checklist" I mean a form-based version of
the checklist which the user can fill out, submit, and then receive a
conformance report or rating, along with the necessary EARL markup which
can then be included in the page or site itself. We have not created
these interactive forms. I have only created the gateway to them.
When I created these prototypes, I did not do an XSL conversion, though
we'd like to do XSL in the final version. So, in light of the fact that
I had to copy and paste everything, I did not create a complete
checklist. I only did the first three guidelines, with their
corresponding checkpoints success criteria. Even so, you can see that
the documents become quite long.
Also, you'll notice that I just copied and pasted the techniques from
1.1 into all of the success criteria. I did this just so that we could
have some place-holder content in the techniques. (Copying, pasting, and
formatting all of that information would have been too time-consuming.)
You'll also notice that not all of the text in my "gateway pages" is
linked yet, again, due to the large amount of time it would take to
generate all of the corresponding documents.
Lastly, you'll notice that the checklist that I created is somewhat
different from both of the versions that Ben referenced in his email
earlier. My version is simply another conceptualization of the same
basic idea. At some point we'll have to choose between
conceptualizations and then refine the one that we choose.
Ok. With that preamble, here is the link to the first step in the
gateway pages:
Follow all of the active links in these documents to get the big picture
of how the system fits together.
Paul Bohman
Technology Coordinator
WebAIM (Web Accessibility in Mind)
www.webaim.org
Center for Persons with Disabilities
www.cpd.usu.edu
Utah State University
www.usu.edu
Hi,
i think that would be important to have two kinds of checklist: a full
checklist as for the WCAG 1.0 and one interactive.
This second options is due for the users that prefer to have a
"Step-by-step" guide for reach the correct level for accessibility claim.
The option to have a "full checklist" is still there. But the issue is
that there is more than one type of full checklist.
For example, you could have a checklist with every success criterion for
every conformance level with all techniques for all technologies (this
would be a *HUGE* document).
You could also have a checklist with every success criterion for every
level *without* any technology-specific techniques (you can see this
option by going to the main gateway
page--http://www.webaim.org/wcag/checklist/step1--then clicking on
"pre-configured static checklists", then choosing "general - all
conformance levels").
Similarly, you could have every success criterion and every level with
only HTML, and so on, through all of the technologies.
As you can see, there is not really one checklist that fits every
situation, but it is still possible to generate one generic checklist
(without technology-specific information) which includes all success
criteria and all levels. I think that this is what you are referring to.
If it is not, then you'll have to clarify.
Paul Bohman
Technology Coordinator
WebAIM (Web Accessibility in Mind)
www.webaim.org
Center for Persons with Disabilities
www.cpd.usu.edu
Utah State University
www.usu.edu
Behalf Of Roberto Scano - IWA/HWG
----- Original Message -----
picture
Hi,
i think that would be important to have two kinds of checklist: a full
checklist as for the WCAG 1.0 and one interactive.
This second options is due for the users that prefer to have a
"Step-by-step" guide for reach the correct level for accessibility
claim.
Right.. is what i refer... good!
Roberto Scano
IWA/HWG EMEA Coordinator
International Webmasters Association / HTML Writers Guild
E-Mail: emea@iwanet.org
