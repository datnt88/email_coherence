I get a very strong feeling that we are all tacitly assuming that the
Web and all our Guidelines, etc. assume literacy on the part of a user?
Of course this is the basis of Jonathan's criticisms and also the
explanation of our emphasis on "text" as being fundamental.
I don't think this is "wrong" but perhaps just unremarked.
Love.
ACCESSIBILITY IS RIGHT - NOT PRIVILEGE
I think there are other reasons (and I'm deriving these comments
from discussions with Eric Hansen):
1) All content must be available only to eyes, only to ears, and
only to fingertips. (Refer to my comments on grouping checkpoints
and the category of perception and the senses.)
[1] http://lists.w3.org/Archives/Public/w3c-wai-gl/2000JulSep/0197.html
2) Given the state of current technologies (that are readily available,
not too expensive, and accurate enough), text is the best way to
ensure that information can reach all of those senses. Text is not
ideal for communicating all information (graphics and audio are often a
lot more effective than text, some users can't read visually displayed
text,
deaf non-readers seem to lose entirely in this model, etc.) However,
today's tools handle text characters as input much better than
images of text (OCR) or voice-to-text translation (although that seems
to be improving). How good is general visual-to-auditory translation?
Or auditory-to-visual?
Thus, I think the emphasis on text is not strictly bound to
assumptions of literacy but requirements to reach eyes, ears,
and fingertips.
- Ian
Ian Jacobs (jacobs@w3.org) http://www.w3.org/People/Jacobs
Cell: +1 917 450-8783
Writing ex officio again:
I don't think the guidelines assume that the reader of web content must be
literate. An illiterate person can in principle operate a computer via
speech input and listen to speech output. What the guidelines demand is
that (per Principle 4) content must not be expressed in a more complex
manner than the nature of the purpose and subject matter demand; and that
modality-specific (auditory/visual) presentations be provided to aid
comprehension where appropriate. This reduces the over-all comprehension
threshhold, but it also needs to be acknowledged that a certain ability to
understand language will be necessary in order to access most (though not
necessarily all) content. This is a plain and simple fact which no access
strategies can overcome. However, we can try to minimize complexity,
provide a consistent style of presentation, include graphical/auditory
material where appropriate, etc., to aid understanding.
This will not make all content accessible to all people, but it will
facilitate comprehension and under certain circumstances amount to the
diference between content's being accessible, or inaccessible, to
particular individuals.
IJ:: "Text is not ideal for communicating..."
WL: I think "ideal" misses the point that it's sofa king *good* for that
purpose that the Web (and our puny efforts) assume it. I think we're
pretty well agreed that we can (at least effectively enough to have
established an almost entirely verbal communication network) put more
stuff into text than we can put text into the other obvious media. Each
urge to do it the other way 'round has met with something right next to
ridicule, if not scorn g . It is so widely held that speech (yes even
ASL) is what identifies us as sentient and that text is a reasonable
representation, for most purposes, of speech (hence the word "language"
deriving from "tongue").
Love.
ACCESSIBILITY IS RIGHT - NOT PRIVILEGE
That's technology-specific, right? The fact that screenreaders
exist and braille terminals exist is what lets us "use text"
and assume that it will be presented somehow to people who can't
see, yes?
If screenreaders didn't exist -- would we need to provide an
audio stream with each web page? (A serious question, because
it deals with the evolution of technology and availability of
that technology to various groups. If we want to be completely
technology-agnostic, we'll need to consider these things.)
Here's an example -- I work with a fellow (Jack Berkowitz) who
used to work with DARPA projects. One of the things he's seen
was a very sophisticated image recognition program that could
look at a picture and tell you, for example, "this is an image
of a man standing next to a tree, and a van is driving by."
It could tell you what the man is wearing, what the text on
the van says, and what kind of tree it is. (This is all stuff
used for spy satellites and whatnot.)
Now, of course, that kind of technology is not readily available.
It won't be used by the common consumer for some time. However,
with increases in processing power for basic machines continuing
to go up, and with high technology routinely trickling down out
of the research labs, there's a possibility that within 10 years
all of us could have such a thing on our desktop machines.
This would mean that labelling images _may no longer be necessary_
at least not as we know it today. With today's technology you
could probably set up something to read most text off of navigation
buttons using OCR. Longdescs? Heck, with the stuff I've described,
you can pull information out of pictures without needing a longdesc.
So the "poster child" for web accessibility -- the ALT attribute --
may not be necessary in the future.
Will this affect our "principles"?
Kynn Bartlett kynn@idyllmtn.com http://kynn.com/
Director of Accessibility, Edapta http://www.edapta.com/
Chief Technologist, Idyll Mountain Internet http://www.idyllmtn.com/
AWARE Center Director http://www.awarecenter.org/
Vote for Liz for N. Am. ICANN Nominee! http://www.khyri.com/icann/
