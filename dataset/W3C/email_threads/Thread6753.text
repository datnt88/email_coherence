A colleague and I have been talking about how to do more precise testing of
W3C specifications, and how the specification markup might help.
GOALS:
Allow an external document (test case, erratum, email, etc.) to point
directly at a "testable" normative sentence in a Recommendation.
Encourage document editors to view some of the sentences as "test
assertions" and to write them in a style that conveys precisely what
they declare.
Explore possibilities for machine processing of testable sentences in
the future.
Link error assertions to error catalogues (see the work that Mike Kay is
doing with the XSLT document: (
Provide a tagging scheme for testing of grammatical statements, such as
the ad-hoc one employed in the XPath/XQuery specifications.
Possibly provide markup also for discretionary behavior.
So our proposal is to add a tagging structure to
the above goals.
Test cases will nearly always have to cite more than one testable sentence
and/or production, unless the Rec is issued with test assertions in a
separate appendix. We should experiment with enhanced tagging to see how it
influences sentence structure. Some complex sentences with multiple "or"
parts crossing each other may get restructured just to make citing them
more precise. Consider this sentence from part 16.4 of XSLT 1.0: "Thus, it
is an error to disable output escaping for an xsl:value-of or xsl:text
element that is used to generate the string-value of a comment, processing
instruction or attribute node; it is also an error to convert a result tree
fragment to a number or a string if the result tree fragment contains a
text node for which escaping was disabled." That one sentence has 8-10
testable assertions.
So far, we are not proposing concrete details. First we wanted to see what
people thought of the idea, if anyone has experimented with something like
this so far, and whether or not this would be worth a concrete proposal.
-scott
This sounds like it might force a particular writing style and constrain
the sentence structures used by editors. Am I reading too much into this?
I am concerned about anything that would increase the work load or the
constraints on editors. We've got an enormous amount of work to do as it is.
Jonathan
Well, in order to be able to test specification implementation it is helpful
to impose these constraints on the way the spec is written. I agree that it
adds to the already significant workload of editors who are not doing this,
but I think it is an important part of ensuring the quality of our
specifications to enable them to be tested.
Cheers
Chaals
This sounds like it might force a particular writing style and constrain
the sentence structures used by editors. Am I reading too much into this?
I am concerned about anything that would increase the work load or the
constraints on editors. We've got an enormous amount of work to do as it is.
Jonathan
Location: 21 Mitchell street FOOTSCRAY Vic 3011, Australia
(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)
There are many ways to "enable our specifications to be tested". And
we should not forget that ability to test is not the only goal.
An ideal specifications would be both readable by humans and testable
by machines. Most current specifications, especially complex and
interesting ones, do not satisfy both of these properties. There can
be two general directions for improving the situation:
- making humans write machine-testable text (code)
- making machines understand human-oriented text
Some steps can be done in both directions. For example, making every
bit of a spec addressable is not much extra work for humans and helps
machines a lot.
Interestingly, having smart enough machines is sufficient for humans
to write testable specs because a smart machine would tell the author
whether what s/he just wrote is testable. Compare this with writing
poems using pre-declared Java identifiers to avoid spelling mistakes
and having a spelling checker that highlights misspelled words as you
type your poem.
Personally, I do not like the idea of making humans write more code
than they already have to. I think it is a counter-productive approach
in the long term, especially since not all real specifications can
have 100% test coverage (some requirements cannot be pragmatically
tested at all).
Making spec bits addressable is as far as I would go [today and within
W3C scope]. My understanding is that we already have the tools to make
such addressing. And, practically speaking, it is not too much work to
apply any given addressing scheme to address every interesting piece
of a given specification. Do we really need a one-for-all standard
that editors would be mandated to use?
Thanks,
Alex.
There are many ways to "enable our specifications to be tested". And
we should not forget that ability to test is not the only goal.
Absolutely. But not being able to test whether a specification is being met
means that it is less a specification than a general description of an idea.
An ideal specifications would be both readable by humans and testable
by machines. Most current specifications, especially complex and
interesting ones, do not satisfy both of these properties. There can
be two general directions for improving the situation:
- making humans write machine-testable text (code)
- making machines understand human-oriented text
Some steps can be done in both directions. For example, making every
bit of a spec addressable is not much extra work for humans and helps
machines a lot.
EARL takes this approach - it simply requires that there is an identifiable
test - i.e. it can be addressed, and the test itself is assumed to be
specified in human-readable language. For some categories of test it is
possible to compare a reference example to a test example (e.g. visually),
and for others it is useful to provide the relevant part of the specification
(which is assumed to explain what the test is) along with the example being
tested (e.g. the CSS test suite, or WAI checkpoints).
There is another class of cases where it is possible to do the testing - e.g.
validation of various kinds, but where it is difficult to build general tools
that can use the results of testing because there is little machine-readable
information to identify which requirement was failed.
I agree that a useful step would be to make each requirement addressable, and
to work with that before we go further into this realtively uncharted
territory. (Well, there are organisations who have spent years on this. Maybe
some of them are represented on this list).
cheers
Chaals
Interestingly, having smart enough machines is sufficient for humans
to write testable specs because a smart machine would tell the author
whether what s/he just wrote is testable. Compare this with writing
poems using pre-declared Java identifiers to avoid spelling mistakes
and having a spelling checker that highlights misspelled words as you
type your poem.
Personally, I do not like the idea of making humans write more code
than they already have to. I think it is a counter-productive approach
in the long term, especially since not all real specifications can
have 100% test coverage (some requirements cannot be pragmatically
tested at all).
Making spec bits addressable is as far as I would go [today and within
W3C scope]. My understanding is that we already have the tools to make
such addressing. And, practically speaking, it is not too much work to
apply any given addressing scheme to address every interesting piece
of a given specification. Do we really need a one-for-all standard
that editors would be mandated to use?
Thanks,
Alex.
Location: 21 Mitchell street FOOTSCRAY Vic 3011, Australia
(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)
I do not think the above is true in general. For example, there are
numerous working implementations of HTTP specs while many HTTP
statements cannot be tested in a pragmatic way. The primary goal of a
specification is to enable building [compliant] implementations. This
goal is different from enabling [compliance] tests.
It would be great if all specs were 100% testable, but I do not think
it is possible in practice, regardless of the specs language. My
belief is based on a simple fact that both black- and white-box
testing techniques cannot achieve 100% coverage of a complex program
implementing the specs.
Testability should definitely be a priority, but it would be sad if we
get fewer good specs by accepting rigid and expensive testability
requirements. A poor solution is often worse than a simple
acknowledgment of the problem.
Alex.
Good point.
Chaals
I do not think the above is true in general. For example, there are
numerous working implementations of HTTP specs while many HTTP
statements cannot be tested in a pragmatic way. The primary goal of a
specification is to enable building [compliant] implementations. This
goal is different from enabling [compliance] tests.
It would be great if all specs were 100% testable, but I do not think
it is possible in practice, regardless of the specs language. My
belief is based on a simple fact that both black- and white-box
testing techniques cannot achieve 100% coverage of a complex program
implementing the specs.
Testability should definitely be a priority, but it would be sad if we
get fewer good specs by accepting rigid and expensive testability
requirements. A poor solution is often worse than a simple
acknowledgment of the problem.
Alex.
Location: 21 Mitchell street FOOTSCRAY Vic 3011, Australia
(or W3C INRIA, Route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France)
