Jacob, you're so close. If you'd just stop assuming the conclusion you'd
get it.
"How can the contents of that section be interoperability tested? Exactly
why is such a section allowed, even though it cannot be interoperability
tested?"
Two different implementations must be able to correctly parse obsolete
messages. Implementations should never generate those messages. The
easiest way to do the test (and hopefully every MUA vendor will do this) is
simply to telnet to port 25 and feed in the obsolete message from the
example. Thus, the obsolete section would be interoperability tested if
both implementations produced the same parsed message. There is no
requirement for interoperability on generation, and in fact, MUAs are
required NOT to generate such messages. Thus, your second sentence doesn't
follow.
If this still seems unclear, I would reread the whole thread and reread
section 4.1.2 in RFC 2026.
- dan
Daniel Kohn mailto:dan@dankohn.com
You keep coming back to this notion that a conformance
specification can somehow defeat the interoperability
requirements. This just isn't true. A protocol can say
what it likes about what it means for an implementation to
be conformant. But this has no effect on interoperability
requirements at all.
I am just trying to understand the IETF rules for moving a
standard from proposed to draft status.
I do understand that the base requirement is still, that
moving a standard from proposed to draft requires that
there are two implementations based on different code base
which can interoperate using every feature in the standard.
And I do now understand that this rule is only valid for
every single feature, not for any combination of features,
and not for an arbitrary number of recursive application of
the same feature.
But I still have the impression that there are exemptions
from this, that there are certain things you can say in a
standards document which is exempt from the
interoperability requirement. But I do not quite understand
which features are exempt in this way.
In particular, how can a standard ever specify a
requirement only for receipt, if all requirements must be
interoperability tested? Surely interoperability testing
requires that systems can both receive and generate a
certain format?
For example, the drums msgfmt document has a list of things
you should be able to receive but should not generate (the
obsoleted features section). How can the contents of that
section be interoperability tested? Exactly why is such a
section allowed, even though it cannot be interoperability
tested? Is it because the section is labelled "obsolete",
because the section is labelled "for receipt only" or why?
Take ICMP as an example from an entirely different area.
ICMP defines a bunch of different sorts of messages, quite
a few of which are only used in very specific
circumstances. There are lots of agents that generate ICMP
packets that have no need to ever generate certain sorts
of ICMP messages. It it then appropriate to claim that
these features of ICMP don't interoperate merely because
some agents cannot produce them? I think not.
The interoperability requirement is not for all
implementations, only for two different implementations
based on a different code base. So my understanding is that
there must be at least two different ICMP implementations
which can send and receive every single ICMP message, and
which can interoperate when handling this message, but it
is not necessarily required that every implementation can
handle every ICMP message, not even that there are two
implementations which can handle all the ICMP messages in
just those two implementations.
Jacob Palme jpalme@dsv.su.se (Stockholm University and KTH)
for more info see URL: http://www.dsv.su.se/jpalme/
And of course this again begs the question of what it means to have a generator
of a given protocol feature. As I pointed out before, while you may not
be able to get a set of GUI MUAs to generate deeply nested multiparts in
one go, such things do get generated quite regularly.
In the case of the obsolete stuff in DRUMS I would agree that this is
reasonable. Although I suppose that in the abstract sense we'd be better off
simply removing any obsolete feature that has never been used. But this amounts
to proving a negative about the installed base, which is impossible.
And as a practical matter, finding real examples of all the obsolete
stuff in DRUMS is likely going to prove to be depressingly easy.
But in the case of a new protocol, while the extreme situation of having
nothing but hand-created examples of a single isolated feature is probably
sufficient to meet the letter of the interoperability testing requirements, one
can argue that a feature that's demonstrably been shown to not be used other than in
testing isn't worth having and should probably be removed from the protocol.
But you're right in saying this isn't required for a move to draft.
There's also a slippery slope here should we start trying to figure out what
constitutes a legitimate "generator". For example, there are several
implementations of what you might call "MIME object generators" out there.
These are things that take one or more objects and put them in a MIME
structure. The ones I'm familiar with can be used to build basically arbitrary
MIME structures with only a few commands. Is such a thing a generator? Where do
we draw the line?
Personally, I draw the line by not worrying this issue on this basis at all.
When we move something from proposed to draft or from draft to full it makes
sense to review the list of features not only from the perspective of "does
this interoperate" but also from the perspective of "do we really need this".
The former is required by the process and if not met, of course justifies the
removal of a protocol feature. The latter isn't required but isn't prohibited
either, and can and has been used to remove unnecessary complexity from various
protocols.
And this is especially true of the move to full standard. A good example here
is multipart/parallel. There were several agents capable of sending and
receiving it back when MIME was moved to draft. But other, more powerful
constructs appear to have taken its place, and nobody bothers with it much any
more.
This was pointed out back when MIME recycled at draft, and at the time I
pointed out that the requirements for moving to draft had been met in full, and
so it should stay in. I still believe this to be true for draft standard. But
what about moving to full standard? I'm not sure multipart/parallel meets the
requirements for full standard. Perhaps it should be moved to a separate,
informational document at this point, should we ever get to moving MIME to full
standard...
Ned
Jacob, what seems to be lacking in this discussion is an application of
judgement. The IETF has never defined interoperability rules as formally as
you seem to desire them. Most RFCs (including the MIME specs), contain what
formalists may see as a huge mishmash of requirements, implementation
advice, background discussion, non-normative definitions, and even humorous
asides. (My personal favorite is the discussion of incorrect
implementations in RFC 1982: "Nothing can be done with these
implementations, beyond extermination.")
But, while some might say that this is no way to run a standards
organization, many (including myself) find that it the only way to do so,
and any other approach to be stiflingly bureaucratic.
So, to your specific question, no, my suggestion below is not the official
IETF policy on to how to deal with an obsolete features section. But, it
seems reasonable to me and it may very well seem reasonable to the IESG and
the AD responsible for overseeing the interoperability report.
If you want to review all the different approaches that have been taken to
IETF interoperability testing, you might start with
http://www.google.com/search?q=interoperability+testing+ietf&amp;num=30&amp;sa=Goog
le+Search . Instead, I would suggest that you use your judgement in
conducting the testing and then produce a report like
http://www.w3.org/Protocols/HTTP/Forum/Reports/rollup.txt , although
hopefully far less detailed since MHTML is a much simpler standard.
If you really want help from this mailing list or ietf-822, then I would
suggest writing up your plan for interoperability testing and having it
reviewed by the list (with the understanding that the IESG are the audience
that really counts at the end of the day). But these abstract conversations
are not getting us anywhere, and therefore I too hereby drop out of the
thread.
- dan
Daniel Kohn mailto:dan@dankohn.com
is
doesn't
I thought interoperability meant that one implementation
could receive what another implementation produced. You say
that interoperability means that two implementations will
handle the same manually generated input in the same way.
Is that really right? Or is that a special variant of
interoperability, to be applied to "receive-only" specs,
while "send-and-receive" specs will still be tested by
testing that one implementation can receive what another
implementation sends?
Jacob Palme jpalme@dsv.su.se (Stockholm University and KTH)
for more info see URL: http://www.dsv.su.se/jpalme/
