I believe it's soon time to release Link Checker 3.9.3. The only
showstopper (unless I've missed something) is the presentation of the
"forbidden by robots.txt" cases, which are now treated as 403's, with
screaming red background.
So apart from that, for all your urgent link checking needs, this one
could use some testing: http://qa-dev.w3.org/wlc/checklink :)
Ville,
Great!
Are you planning a short beta test soon? I haven't had time to test it
yet, but I went through the diff and things look good. I will try to
play with it within a few days, tell me how you'd like to schedule the
next steps.
olivier
I'll try to get the robots-text-is-screaming-red-403 issue fixed in the
weekend, after that we could do a quick beta test. But nothing prevents
from testing already now, because about all the real functional changes
for 3.9.3 are already in as far as I'm concerned.
The status of libwww-perl needs attention though, I believe the link
checker $TNV *could* in theory work with the 5.64 on v.w.o, 5.66+ is
needed for command line use. But perhaps the upgrade to 5.79 would not
be a bad idea.
I've notified the Debian libwww-perl maintainer about the 5.76 file:
redirect issue, perhaps there will be an updated .deb available soon.
Fedora Core 2 will most likely include 5.79 (it's in Rawhide now).
Haven't got time to look yet but I suppose from what you're saying that
5.79 fixes the file: redirect bug, which is good. That said, are we
sure it's a good candidate (i.e stable enough) to put into production?
I realize that updating lwp is starting to be important and urgent, I
just would not want to regret any hasty move.
olivier
Understood and agreed. But all the development work I'm doing is with
5.79 (and I've reviewed quite a bit of the current LWP codebase lately,
it should be in good shape), qa-dev currently has 5.76 and v.w.o has
5.64. As long as the production version will be using something that we
test 3.9.3 with, it's fine with me. Well, as long as it's newer than
5.60, excluding 5.76 ;)
Updating the system LWP on v.w.o would of course need the validator to
be tested with the new one as well. But if need be, one or even both of
{validator,checklink} can be using their "own" LWP installation,
basically it's just a matter of unpacking the LWP dist tarball, doing a
SetEnv to the libwww-perl-*/lib dir in Apache's config for the relevant
script, and removing the -T flag from the CGI's perl shebang. Note, I'm
not advocating this, just pointing it out as a possibility just in
case...
Ok, this is now done (although the implementation is somewhat ugly), and
ready for a beta test now.
Hi Ville, All,
I have just installed LWP 5.79 on qa-dev. Maybe we can check for a day
or two whether that causes no problem with either the validator or
checklink, and proceed with a beta (with 5.79 installed on w.v.o)
within a couple days?
I just tested the new feature (and style for the robots exclusion) and
it seems to work fine, great job.
I still find it frustrating that the link checker HAS to follow
robots.txt and telling users to check links manually, even in non
recursive mode, but I reckon I am against the majority here, and I
should probably just accept I am wrong and shut up ;)
olivier
Sounds good.
FWIW, I am not a huge fan of it either.
A doc snippet (and a pointer to it from the "forbidden by robots.txt"
explanation) how to allow the link checker in /robots.txt would probably
be a good idea, I'll look into it.
