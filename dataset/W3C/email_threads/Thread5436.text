Email has to be viewed in fixed width formating...
I have been thinking about this patent for a while and what seems to be
very unique about it is that a file is downloaded and it is associated
with an executable like MIME. My idea is why not remove the MIME
resolution and do everything in a different combination. My idea is to
make the browser dumb and run something called an Internet Archive
automatically.
So anybody, have a read and maybe comment... (Just an idea..)
We create something called a Internet Archive. The Internet Archive is
a file that acts like an file system within a file system. The Internet
Archive has a fixed length header, and body. Within the header are
references to other files of the archive. EG it would look as follows:
"File system"
1 2 3 4 5
[Header ][12345678901234567890123456789012345678901234567890]
a=1 b=17 c=39 aaaaaaaaaaaaaaaabbbbbbbbbbbbbbbbbbbbbccccccccccccc
The HTTP Client and HTTP Server are HTTP 1.1 protocol.
The HTML page contains a reference as follows
When the client downloads the HTML page and hits the content tag the
data is downloaded like an Image tag. The difference is the Internet
Archive references a compressed set of files that the HTTP client knows
about. This is similar to how a zip file. To ensure a certain level of
security the file would be signed.
What is special about the Internet Archive is that the first file in the
archive is executable content like one would click on an icon on a
desktop. Consider it like issueing an URL, not specifying the file
desired and getting the default file (eg default.html). The client
would download the content and then start the executable giving the
executable a handle to the downloading(ed) archive. There is no
resolution of mime types or anything along those lines, it is an
automatic execution. Once the executable content has started and
retrieves a handle to the Internet archive the running content would
manipulate the archive data however it pleased.
An optimization on the client side would be to cache Internet archives
and the content that they reference. For example consider the following
scenario.
File: /archive1.ia
[Header ][12345678901234567890123456789012345678901234567890]
a=1 b=17 c=39 aaaaaaaaaaaaaaaabbbbbbbbbbbbbbbbbbbbbccccccccccccc
File: /archive2.ia
[Header ][12345678901234567890123456789012345678901234567890]
a=1 D=17 c=39 aaaaaaaaaaaaaaaaDDDDDDDDDDDDDDDDDDDDDccccccccccccc
There are two Internet Archives, which reference the files a, b, c, and
D. Using HTTP 1.1 the header of the Internet Archive would be
downloaded first. The HTTP client would inspect which files are in the
cache and which are not. Then using HTTP 1.1 the individual files would
be downloaded using byte addressing.
EG Downloading both Internet Archives would be done as follows:
Http 1.1 Get /archive1.ia
ranges-specifier = 1=1-32
Client has downloaded the header and is inspecting what to get
Http 1.1 Get /archive1.ia
ranges-specifier = 1=1-17
Client executes first file, and gives a handle to the Internet Archive,
which is processed by the running executable
Http 1.1 Get /archive1.ia
ranges-specifier = 1=17-39
Http 1.1 Get /archive1.ia
ranges-specifier = 1=39-50
Now user browses to different Web Page
Http 1.1 Get /archive1.ia
ranges-specifier = 1=1-32
Client has downloaded the header and is inspecting what to get
Client retrieves content from cache
Client executes first file, and gives a handle to the Internet Archive,
which is processed by the running executable
Http 1.1 Get /archive1.ia
ranges-specifier = 1=17-39
Client retrieves content from cache
The identification of the files could be considered like cookies or URL
references.
An optimization could even to rename the Internet Archive with a new URL...
Eg IA://archive1/identifier
Where running the URL IA://archive1 would automatically download and
execute the "default file"
Christian Gross
Download a compressed archive of files containing executable code? Sounds
like a JAR file to me.
I'd be very interested to see the web entirely based on a
platform-independent programming language instead of a text markup language,
but I don't think it would actually be a good approach.
-Jake
It is similar to a jar... The entry point of the archive is the first
file, so that there is no resolution necessary. The difference is that
not the entire jar file is downloaded. Only what is necessary is
downloaded. Imagine putting shockwave into every archive, when the
content to play is only 5KB. That would be an incredible download hit.
Ok an HTTP 1.0 server would have to download the Internet Archive each
and every time. But by using HTTP 1.1, only the necessary bits are
downloaded, hence saving bandwidth.
We already have it... It is called Java, and .NET.
How could this Internet Archive work.
Lets say I am using IE or Mozilla and I want to download an applet. The
Internet Archive file would contain the Java Applets, and the runtime.
The runtime would execute the Java Application. While the size of the
Internet Archive will be in the megabytes, it is irrelevant because the
size of the file is virtual. The HTTP 1.1 protocol would use ranges to
download the bits it needs. The trick is that the archive would be
created dynamically on the server side using MIME encoding. You would
create a file, reference the runtime bits and let the HTTP server take
care of the rest. So the resolution still happens, but the Internet
Archive delegates the resolution to the server, unknown entirely to the
client and to the HTTP protocol. It is an implementation detail...
Christian Gross
I said "entirely". :-)
Back in January 1996 while working with Alfred Aho on my soon to be
aborted PhD, I developed the Content Handler Internet Protocol (CHIP).
The goal was to allow content providers to distribute platform
independent documents which could be bound at run-time to different
viewers based upon the capabilities of the platform the document was to
be viewed on. A CHIP Server could be a centrally available service
belonging to an administrative organization or could be co-located on
the content server.
I was attempting to solve the problem of heterogenous systems plus
ensuring that older versions of documents could be viewed in their
native viewers as newer versions with backward compatibility or
conversion modes are often lossy in the translation.
The CHIP worked is as follows. The client negotiates the Platform (OS,
Hardware Architecture, Applications, Versions) and the Document
datatypes (MIME, file extensions, versions) with the CHIP server. The
server in turn distributes to the client the appropriate executables
(viewers, interpretters, agents) and installation processes; or a
referral to another server to be checked. After viewing the client
could keep the executables until the next time they were required or
discard them.
The reason I bring this up is that even if the necessary software to
view the document was already installed on the client, the decision of
which software should be used to view a given document was pushed back
to a remote server. The client (a browser) does not make the decision
locally. It simply executes what it was given. This would seem to work
around the Eolas patent.
Jeffrey Altman
