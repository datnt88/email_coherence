Why is it with all these years in development Bobby does not detect
basic problems in markup that a good parser should be able to detect.
Why after all this time does it not detect a page full of empty elements
tabindex="" accesskey=""
Why doesn't it look for NOSCRIPT and alternatives when there are
SCRIPT elements
Such things pass WAI AAA according to Bobby, but which the W3C validator
shows to be full or pseudo accessibility (at least in the emtpy
tabindex="" accesskey="" case).
This is what strikes me about a lot of compliance, its the art of
throwing junk markup at a sub standard parser that is creating a Cult of
Pseudo Accessibility. The sub standard validators / accessibility
parser are doing just as much to harm real accessibility as they are in
trying to aid it.
As a developer with a programming background I just do not understand
why these tools are so poor. The W3C can produce good parsers, why
can't Watchfire? There are so many good parser out there, so why not?
What is so hard about detecting the problems or checkpoints with the above?
How much is this type of thing supporting a culture of ignorance where
sub standard accessibility validators encourage and perpetuate a Cult of
Pseudo Accessibility Design whose designers follow the new version of
the old school browser and parser tricks school of development.
Geoff Deering
Hi Geoff,
Bobby is not alone in missing out various tests - in fact it is
difficult to know all the things that should be tested, so it is not
surprising that tool developers have different opinions even before the
problems faced in actually implementing them are taken into account.
There has been an interesting discussion in the last day or so on the
Accesoweb (spanish) list about Coca-Cola, who launched an "accessible"
version of their spanish website. Clearly they have tested it with TAW
and Bobby, and have not detected the problems that come up even at
level-A. To be fair, these are problems that are not really identified
in the tool tests, nor in the documentation, although they are fairly
serious ones. (On the other hand it is nice to see a company like
Coca-Cola Espa?a is making a serious effort...)
There is a forum - the Evaluation and Repair Tools group, where people
discuss precisely how to do testing and what tools should do, and
developers such as Bobby's Michael Cooper are active participants in
this area. (Chus Garcia, developer of TAW, speaks spanish and
participates in discussions through Sidar where we have people who
follow both groups).
But most important are the techniques themselves - the WCAG group has
not really been inundated with tests that can be applied, which means
they haven't published documents sufficiently complete to enable tool
developers to get really good guidance. And most of what they have has
come from a handful of developers. We the people can contribute this
material, which would make a big difference.
The EuroAccessibility Consortium's goal is to harmonise web
accessibility testing in Europe through consistent interpretation of
WCAG at a detailed level. It has therefore been working on a checklist
for WCAG where each aspect of each checkpoint is called out. Sidar has
been participating in that work, because we believe that it will
provide a great deal of valuable input to WCAG (and because we like the
aspect of EuroAccessibility's rules that specifically recognises WAI as
the technical authority where decisions should be made, rather than
promoting further fragmentation of standards and approaches). Sidar has
also been active chairing the EuroAccessibility group on testing tools,
and we expect to see some major improvements, although we recognise
that software development often takes some time.
I share the frustration of seeing people rely on poorly-used tools as a
substitute for thinking. Although from time to time I am scathing about
the cavalier attitude to people, and the clear lack of professionalism
that this shows, I am also aware that many people trying to develop
accessible content are not professional web developers but experts in a
particular field trying to do their best with limited tools. Worse,
many of them do not have the resources to use the good but not free
tools which are available.
It isn't a cult of pseudo-accessibility that concerns me, but a cult of
"accessibility only if it costs nothing and requires no effort or
thinking or learning". Often (but not always) accessibility is
trivially easy and has negligible cost when included by a professional.
To avoid even that minimal effort strikes me as reflecting badly on
developers. (In Australia it is also against the law, but we live in a
special place grin/ ).
And I hope that we do get better tools, and that people use them. It's
tough on the bleeding edge...
cheers
Chaals
On Wednesday, Dec 10, 2003, at 14:15 Australia/Melbourne, Geoff Deering
[some snipped]
Charles McCathieNevile Fundaci?n Sidar
charles@sidar.org http://www.sidar.org
Hi Charles,
I do agree with some of your points, and many of the tests are not so
easy to do, but the ones I mentioned are *darn right easy* too do.
To be able to parse a document and detect empty values in certain
elements, or look for NOSCRIPT where there are SCRIPT elements is
something a first year CS student should be able to do, so why after all
this time, in a commercial product from a commercial company, why isn't
the project manager knowledgeable enough to isolate these problems and
have them corrected? These particular checks are trivial and should
only take a few days to implement them. Why haven't these been
identified and dealt with?
You say that most of these haven't been documented by WCAG for
programmers to implement, but these points are well documented in these
forums, they come up time and time again on these lists just falling on
seemingly deaf ears.
Just say I was project manager of this product, I'd be watching this and
a few other lists all the time for feedback on my product. We have all
been complaining about this for years. You'd have to either have your
head in the sand to be missing this, or be completely incompetent in
your job not to be able to address the specific areas of concerns that
I've pointed out. If you have just the basic understanding of
accessibility and programming these points would not have slipped by.
They would have been fixed. It's crap that it's too difficult.
It's absolutely true that to parse and validate web document for
accessibility is not a trivial matter. But, the specific items I point
out are trivial matters for a even a basic parser or an average
programmer (like myself). They are not hard to implement, as obviously
the W3C validator shows this. So if there are checkpoints that are very
easy to implement I cannot fathom, beyond sheer neglect and
incompetence, why this has not been done. These checks would not be
overlooked by competent people. Please enlighten me to what I am
missing here?
Look, I'm no great programmer, but I have worked with some that are
exceptionally talented, and I can assure you that I could sit down with
one of these programmers and say ?we have to parse to check for this and
this and this, and I know for certain that we can do it, cause I have
worked with these people on lots of great and successful projects.
This is a commercial product from a large commercial company, they are
selling us mediocrity, that's their product, and if they keep peddling
the line that an accessibility parser is too difficult, they have just
been feeding crap to us, because just about all their products are based
on parsing technology, they are specialists at precisely this type of
product. So why doesn't all this expertise show up in Bobby? I'm
flabbergasted.
If it was an open source project with little to no funding, I have no
complaints, only encouragement, but for a commercial product in a large
resourceful company making money from it and willingly promoting
pseudo-accessibility, it's pathetic. It's absolutely pathetic.
Do you know what it says to me? Watchfire bought Bobby because it
gained an early high industry profile, so they can sit back, put very
little effort into it and it will still make them money. And the
accessibility community is so darn forgiving and amicable they won't
complain too much about it's poor quality. But if it was a tool for
another sector of the development community it would be ridiculed and
rejected until they fixed it.
So many commercial companies are down right slack in the area of
accessibility because of the good nature of the accessibility community
and the incredible effort and patience shown by it to the tools
industry. It is also what I love and learn from in this community, but
I really feel at the same time the knowledge based and much of the good
work in the community is just exploited for cheap commercial gain and in
the long run the Accessibility movement and awareness will suffer
because of the impact of ignorance these tools will have on the general
web development industry.
Why do you need the expertise of the people on this list and others if
you can easily generate HTML soup that does not even conform to a valid
grammar which passes as WAI AAA. Piece of cake, what's all the fuss
about, you don't need any real skills or knowledge.
I really don't know what goes on in that company (Watchfire), but I do
know they have developed some great products in the past and when they
bought Bobby I originally thought "Great, now it will really be
redeveloped into a fine product" (Cast initially did a good but flawed
job I feel). But the time and results speak for themselves and it is
another sad tale of a product that showed so much promise, but to date,
delivering so little, and now doing real damage because uncorrected it
will create a cult or pseudo accessibility.
The source code to the W3C validator is open, maybe Watchfire need to
take it, examine it and go back to the drawing board and start again,
because, sadly, Bobby has become a Web Accessibility Joke, and this
should never have happened. It didn't deserve this, the web
accessibility community doesn't deserve to be treated in this way.
I know that most of these companies have representatives involved in
their relevant areas in the W3C, but I ask you, is this really a sign of
active involvement, or just token representation. Even if these people
are genuine, often their managers just put them there to fulfil a public
role, whether they like it or not. The proof of the pudding is in the
results, and I have seen little improvement in Bobby over this time. It
still has the same *basic* flaws that could have been fixed ages ago.
Something is very wrong in Bobby's development lifecycle.
Come on Watchfire, lift your game. If you can't fix it, give it to the
open source community to do something decent with it, but stop selling
and promoting a highly floored product. It's doing more damage than
good, but I guess it is providing cash flow, and that is the bottom line.
Geoff Deering
I think you are confusing the "letter of the law" and the "spirit of the
law." The plain and simple truth is that not every script element
requires a noscript element to be accessible; hence the concept of
user-checks.
If I have a script that provides some *non-essential* functionality, do
I really need to explain that to a user with scripting disabled in order
to provide that person with a usable experience? No. WCAG understands
this and doesn't require it. Section 508 suggests the explanation but,
IMHO, it's extraneous in most cases and rarely helpful.
I agree with you that there are some fundamental flaws. The main one is
that it stills displays the "Bobby Approved" graphic without verifying
even one user check. If they continue to use this logo, the validation
process should go throhugh a series of Yes/No questions such as "Have
you verified that the script element on line 53 of file...blah blah?"
Once those have past, the logo could be displayed. Granted, this
provides no more verification of accessibility than the current version,
but it is less likely to be misunderstood by a novice user.
I'd like to reference two clich?s:
1. "Guns don't kill people, people do."
2. "Guns just make it a lot easier for people to kill people."
These could also be interpreted as "Bobby doesn't misrepresent sites as
accessible, people do." and "Bobby just makes it a lot easier for people
to misrepresent sites as accessible." However, in the right hands at the
right time, both Bobby and guns can be used for good, too. ;)
Cheers,
James Craig
PS. I just know that last sentence is gonna come back to haunt me.
Why the big deal about Bobby? If it isn't the greatest tool, get one
that is better - there are plenty of others around that allow for much
more complex testing. Or testing for different formats - flash, word
documents, pdf, are all formats for which you can get tools that help
evaluations.
The EuroAccessibility Consortium's tools task force will be looking at
tools that people use, and how good a job they do compared to a
detailed list of what should be tested.
It appears, in preliminary assessment, that Bobby is no longer the most
effective tool - particularly the free online version of it. Reviews of
Bobby vs CynthiaSays, and of Bobby vs. LIFT machine, are available and
suggest that both of those are more effective on various specific
points - I am sure there are others. If you buy tools there are
extremely powerful and flexible ones available - WAI maintains a
partial list at http://www.w3.org/WAI/ER/existingtools at least, and I
am aware of other stuff out there that does a good job - if necessary
by combining tools.
I think Bobby did a lot of good when Josh Krieger developed it, many
years ago now. I think the best tools that are available now are a lot
better than any of the simple free online offerings, and people should
be aware of it. To the extent that serious projects are still using
simple tools rather than looking properly at the market I agree that
there is a problem, and that accessibility is not doing well (nor are
the people who are investing in development - including watchfire - so
we are doing ourselves a disservice by not helping the people who are
helping us...).
2 cents worth
Chaals
On Wednesday, Dec 10, 2003, at 23:07 Australia/Melbourne, Geoff Deering
Charles McCathieNevile Fundaci?n Sidar
charles@sidar.org http://www.sidar.org
For sure, but when a whole page is dependant upon scripts executing and
you get a page that is unusable and inaccessible when scripts are turned
of, and these parsers still continue on their merry way without the
slightest suggestion there could be a problem, you have a real problem.
As a programmer you should know that all they have to do is at least in
this situation parse the functions calls and match them in a DOM tree
table to see if they meet critical or none critical criteria and flag
them as such?
Now why hasn't anyone done this?
Sure, you know that. You know how to use these tools wisely, you
understand the issues. Most of us here do understand how to use these
tools within their limitations. But the vast majority do not, and there
are heaps of companies out there that use such tools without this
knowledge. Bobby has been in production long enough for some of these
things to be addressed, and Watchfire have not addressed them, so my
concern is that there is a developing cult of pseudo accessibility.
Exactly.
As I said, tools like Bobby, because Watchfire has done bugger all to
fix, are killing real accessibility. The test of accessibility in a lot
of large to medium companies is Bobby. To all those developers out
there, they are happy that they have mastered accessibility in 24 hours,
as Bobby tells them. And as for those of us who frequent these
discussions, well... what are we on about????
Well I do definitely know Bobby CAN be used for good. I use it and it
is helpful. I also use it because it is built into TopStylePro. I know
it's limitations, but with my toolset it is very handy and helpful.
But if I was involved in that project at Watchfire I'd be ashamed. I'm
not directly blaming the project manager or the developer because I have
been involved in many projects for large companies where the politics
absolutely killed the prospect of unfettered development and a
successful product, so it's not easy to lay blame on anyone, but I am
comfortable in saying, that as a company, their performance is very poor
in regards to the development of this project.
Geoff
As a programmer, building a validator that includes a JavaScript
interpreter seems like an enourmously daunting task. You mentioned you
were talking about changes that were "darn right easy to do."
Have you been watching the progress of the WAIzilla project? That where
I'd start if you want that kind of functionality. Get involved in the
project and help develop a better one. I suppose you might be able to
modify the validator to work in conjunction with the DOM inspector, but
even leveraging the tools available, it's a daunting task.
I was just joking about my sentence being taken out-of-contenxt: "Bobby
and guns can be used for good..." ;)
Well I believe at least one Watchfire developer is on this list. I've
mentioned specific validation problems here before and they were fixed
quite promptly.
If you have some specific milestones in mind, you might mention them
here. Start small and be constructive. Since I'm not involved in the
Bobby project, I was able to read through your frustration and
understand your concerns. I'm afraid I may not have been as receptive to
your ideas had I been involved; I probably would have been put-off by
your initial tone.
I suggest you start a new thread with a subject like: "Bobby: suggested
improvements" to get their attention in case they missed this thread.
Remember, be constructive. I'm not trying to patronize by repeating
that, but I realize how easy it is to be overly-critical. I do it too
often, to mixed reception.
Good luck,
James Craig
You can only do this for stereotyped code (the sort that links (not lynx)
can partially cope with). I don't think there is any doubt that
ECMAScript is Turing complete, so the halting problem is unsolvable; that
means that any fully general script analyzer will take an amount of
time that can only be determined by actually running the analyzer to fully
analyze the script. (The halting problem says that you cannot construct
an algorithm that will determine whether an arbitrary program will ever
complete and which, itself, will always complete in finite time.)
More prosaically, function calls can be against objects that are multiply
indirected through object variables; that means that you have to analyze
program and data flow; you cannot do just a static analysis.
It's not my use of Bobby that is a problem. As I mentioned in the
initial email, it is it's use by the masses creating this blanket of
ignorance of accessibility. A tool that is meant to help is creating
just as much harm. I do take issue at Watchfire's inability to address
problems with this products.
CynthiaSays does a good job of what it is meant to do.
The Lift machine also overlooks some really basic stuff. It can be as
misleading as Bobby, and it too is a commercial product.
The WAVE is a good tool also, but most developers are used to a
validating parser, and a lot of problem comes from not doing the basic
validating first. If the W3C validator finds problems and these tools
do not doesn't that indicate something they must address first? What is
the point of going on to the finer points of accessibility validation
when there are doctype errors. This goes against all the standard
wisdom of software quality checking.
If I am building web pages, how is a tool really helpful if it is
overlooking these checks? This should be the first thing checked because
there is no point going on until one does this, for sake of efficiency?
There's no point in working with documents if they have a declared
doctype and are invalid, until the errors are removed because that often
perpetuates the problem.
Some people may well know how to use these tools in ways that produce
truly accessible sites, but the fact is that these people are truly
knowledgeable about web accessibility, in such cases they have the
knowledge to compensate for any tools shortcomings. But others who are
not, buy such products to aid their accessibility and are misled by the
poor QA in these products. Like Dreamweaver MX 2004 and believe that it
will generate good quality W3C standard accessible straight out of the
box, when in fact the code generator is not that smart, and still
produces poor quality code that needs lots of nurturing to fix up. I've
grabbed it releases as it has become available and built a quick site
from standard setup, and it has utterly disappointed me that it still
does not build according to standards by any means of my measure that
constitutes efficient markup.
Now, if you take for example a lot of the code generators out there on
the market for programmers, the standards is far, far higher. It has to
be, because they get far more scrutiny than they do from this community.
I'm not saying this community is less informed, I'm just saying for
some reason we seem willing to tolerate sub standard products more that
anyone else.
Well I'm not happy with this. It's a disservice to the whole community
to not point out how Bobby has not overcome these very basic problems.
It should show some maturity. How old is it, at least 5 years isn't it?
I'm telling you straight forward that if this product was in my hands
it would not have the problems I have pointed out. I am certain of
that. They are easy problems to fix. What is going on? If you are
trying to work with these people what is their problem? I can't believe
they are so incompetent they can neither identify or rectify these
problems. They are either completely slack or pulling the wool over
your eyes if they say they are on the job. This is a commercial
company, not some open source developer trying to find a spare hour here
and there to work on a project of love (who I have the utmost patience for).
Geoff Deering
What I am saying was addressing what James was saying, about
*non-essential* and *essential* functionality and flagging it as a
possible problem.
What about all those sites that use document.write to generate all or
most of their content?
I would look at all these things and flag them and show them their page
free of all the javascript implementations. That does not need the
level of complexity that you have indicated. I'm just talking about
checking for the basic and obvious stuff, not a full on full blown DOM
analyser.
Geoff Deering
I just replied to this in my post to David Wooley
Thanks for that, I'll follow it up. I do have trouble keeping up with
all these things. Hopefully this will show how it should be done, but
Mozilla Composer still doesn't impress me that there has been any move
or redesign based on a decent rules based engine.
Well I hope they are listening.
Fair enough, but as I have stated if this was an open source volunteer
effort I do not carry this tone of address, I tend to be very supportive
and helpful (I think, I could be completely wrong), but when its a
business, and this product has had an extremely long history of issues
that remain outstanding, it is generating income for a company and still
falls short of a good level of quality accreditation, and they have
experienced all the nice interface of the WAI community, it's about time
someone gave them a polite shake to wake them up. After all this time
it seems to me that nothing is waking these people out of their stupor.
But if it is not appropriate to address these issues with such strong
language and vigor, I will refrain from addressing product issues on
this list. I'm happy to do that for the sake of the list and take my
issues about products and the damage they are causing elsewhere. That's
fair enough (please email me if you think that is appropriate, I won't
be offended).
I tend to as well, but for all these years it seems to have little
effect on addressing these issues, and I am becoming very frustrated
with the rising cult of pseudo accessibility that the lethegy of these
products QA perpetuates.
Geoff Deering
