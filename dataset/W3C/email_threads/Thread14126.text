There are several bugs in checkpoint 1.3 regarding auditory
description.
{EH: Revision 3 - Suggested Revision. I have changed my view since
posting an earlier version of this document on 4/18/99.}
{EH: Important Bugs:
(1) Please note the 4/16/99 version of the checkpoint incorrectly
implies that the players will generate "prerecorded" audio since
according to the glossary definition, "auditory description" pertains
to prerecorded audio.
(2) Changed to include animations. I am not sure if there is any good
reason why animations should not be included as well as movies; note
that checkpoint 1.4 would seem to refer to the possibility of auditory
equivalents for animations.
(3) This checkpoint was changed to Priority 2; it can't be a Priority 1
since a text equivalent has already been provided per checkpoint 1.1.
(4) Instead of referring to capabilities of "video players" in general,
this checkpoint should refer to the user agents used by individuals who
are blind; this checkpoint is crucial only for individuals who are
blind and therefore only needs to refer to individuals who are blind.
Fortunately, Web users who are blind often have highly capable user
agents that are well-suited to taking text equivalents and rendering
them to speech.}
1.3 Until most user agents used by individuals who are blind can use a
text equivalent of the time-based visual track of an audio-visual
presentation to generate a synchronized synthesized-speech equivalent,
provide an auditory description (i.e., a prerecorded auditory
equivalent of the visual {EH: Did I coin a term here? Any better
suggestions?} track that is synchronized with the audio track).
[Priority?2].
Note that checkpoints 1.1, 1.3., and 1.4 all relate to time-based
audio-visual presentations such as movies and animations with
accompanying audio. Checkpoint 1.1 requires a text equivalent of the
visual track (video or animation) and checkpoint 1.4 requires that it
be synchronized with the presentation. As noted, checkpoint 1.3 the
requirement for the auditory description (which is a specialized,
synchronized auditory equivalent of the visual track) is only in effect
temporarily.
Refer also to checkpoint 1.1 and checkpoint 1.4.
Techniques for checkpoint 1.3
Old 4/16/99 Version of Checkpoint 1.3
1.3 Until most video player technologies can generate an auditory
description of a video track from a text equivalent, provide an
auditory description of the video track (synchronized with the audio
track). [Priority?1]
Refer also to checkpoint 1.1 and checkpoint 1.4.
Techniques for checkpoint 1.3
Eric G. Hansen
Development Scientist, Educational Testing Service
ETS 12-R
Rosedale Road
Princeton, NJ 08541
Internet: ehansen@ets.org
Do You Yahoo!?
Get your free @yahoo.com address at http://mail.yahoo.com
Eric's revision of the text of the checkpoint undoubtedly clarifies it.
However, as Gregg has argued, consistently and persuasively, until such
time as multimedia players (that is to say, user agents) can synchronize a
spoken rendering of the text equivalent with the audio track of a
multimedia presentation, there is no other means available of providing a
synchronized equivalent to the video. He therefore maintained that this
item must have a priority 1 rating, as failure to include a description
renders the content inaccessible. However, it could be maintained, to the
contrary, that even if checkpoint 1.3 were not followed, there would still
be a textual equivalent available (checkpoint 1.1) which, at present,
could not be synchronized with the multimedia presentation. The lack of
synchronization might make such a description somewhat superfluous
however; perhaps this would depend on the length and nature of the video.
My own preference would be to opt for a conservative solution by adopting
substance of Eric's wording in so far as it clarifies the checkpoint, and
retaining the priority 1 classification.
Gregg has also maintained, with equal persuasiveness, that auditory
descriptions will be used by individuals who are vision impaired, not just
those who are legally blind. I would therefore suggest broadening (or
omitting) the reference to blindness contained in Eric's proposed
revision.
Eric's clarification of the "until" clause, and his effort to distinguish
between auditory descriptions as audio streams supplied by the content
developer, and as spoken renderings of text equivalents as generated by
the user agent/multimedia player, are reasonable amendments.
I still feel that the way in which the auditory description is produced
belongs in techniques. At the moment, the effective method is to use a
data file (typically in a dedicated audio format) and an audio player on
the client side. In a few years the most effective method will be to use a
data file with a different format (namely text, which happens to compress
well, and be useful for a number of other tasks) with an audio player (a
text to speech synthesiser, to be precise).
My personal feeling is that the additions are unnecessary complication.
But I don't think it's a show-stopper.
Charles McCN
There are several bugs in checkpoint 1.3 regarding auditory
description.
{EH: Revision 3 - Suggested Revision. I have changed my view since
posting an earlier version of this document on 4/18/99.}
{EH: Important Bugs:
(1) Please note the 4/16/99 version of the checkpoint incorrectly
implies that the players will generate "prerecorded" audio since
according to the glossary definition, "auditory description" pertains
to prerecorded audio.
(2) Changed to include animations. I am not sure if there is any good
reason why animations should not be included as well as movies; note
that checkpoint 1.4 would seem to refer to the possibility of auditory
equivalents for animations.
(3) This checkpoint was changed to Priority 2; it can't be a Priority 1
since a text equivalent has already been provided per checkpoint 1.1.
(4) Instead of referring to capabilities of "video players" in general,
this checkpoint should refer to the user agents used by individuals who
are blind; this checkpoint is crucial only for individuals who are
blind and therefore only needs to refer to individuals who are blind.
Fortunately, Web users who are blind often have highly capable user
agents that are well-suited to taking text equivalents and rendering
them to speech.}
1.3 Until most user agents used by individuals who are blind can use a
text equivalent of the time-based visual track of an audio-visual
presentation to generate a synchronized synthesized-speech equivalent,
provide an auditory description (i.e., a prerecorded auditory
equivalent of the visual {EH: Did I coin a term here? Any better
suggestions?} track that is synchronized with the audio track).
[Priority?2].
Note that checkpoints 1.1, 1.3., and 1.4 all relate to time-based
audio-visual presentations such as movies and animations with
accompanying audio. Checkpoint 1.1 requires a text equivalent of the
visual track (video or animation) and checkpoint 1.4 requires that it
be synchronized with the presentation. As noted, checkpoint 1.3 the
requirement for the auditory description (which is a specialized,
synchronized auditory equivalent of the visual track) is only in effect
temporarily.
Refer also to checkpoint 1.1 and checkpoint 1.4.
Techniques for checkpoint 1.3
Old 4/16/99 Version of Checkpoint 1.3
1.3 Until most video player technologies can generate an auditory
description of a video track from a text equivalent, provide an
auditory description of the video track (synchronized with the audio
track). [Priority?1]
Refer also to checkpoint 1.1 and checkpoint 1.4.
Techniques for checkpoint 1.3
Eric G. Hansen
Development Scientist, Educational Testing Service
ETS 12-R
Rosedale Road
Princeton, NJ 08541
Internet: ehansen@ets.org
Do You Yahoo!?
Get your free @yahoo.com address at http://mail.yahoo.com
--Charles McCathieNevile mailto:charles@w3.org
W3C Web Accessibility Initiative http://www.w3.org/WAI
MIT/LCS - 545 Technology sq., Cambridge MA, 02139, USA
