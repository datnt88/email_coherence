I'm not [the prime] authority on this subject, but some browsers handle
compress'd and gzip'ed content well. However, they are not well-behaved
enough to indicate whether they do or not (concerning Mozilla and NCSA Mosaic),
so the server doesn't know about that.
It seems that Accept-Encoding: and Content-Encoding: serve this purpose well,
the browsers just do not seem to send them (although Content-Encoding is
recognized in browsers above, even Netscape2.0 proved not to send
Accept-Encoding, but IMHO this issue may better be discussed through
www-talk [in HTTP/1.0 draft it's covered well enough, just the current practice
stays behind]).
Just a thought, but looking at my server there are a number of documents which if I PKZIP them, reduce in side anywhere from 20-60%
As bandwidth becomes more of a premium, and response times more critical as the number of users increase would it be appropriate to implement some form of compression of the raw text in the .HTM / .HTML documents ?
Obviously this would require support at two places - compression (on the fly - as some documents need to refresh frequently, or cached) at the server, and at the browser.
As long as the (de)compression algorithm was fast enought to reduce the overall transmission time there are benefits.
gzip/ungzip proved to be fast enough to speed up transfer, even when fetching
from local server (from the same host). on-the-fly-compression overhead on
server side may be considerable enough to advise caching of compressed files
(on server), but again we go off the HTTP issues.
[1]T. Berners-Lee, R. T. Fielding, H. Frystyk Nielsen,
"Hypertext Transfer Protocol -- HTTP/1.0", 02/19/1996. URL :
(or your nearest site), chapter 10.3, D.2.3
Jeremy E Cath
Jeremy_Cath@Sterling.Com
Mirsad Todorovac|
Faculty of Electrical Engineering and Computing|
University of Zagreb|
Unska 3, Zagreb, Croatia 10000|
e-mail: mirsad.todorovac@fer.hr|
Just a thought, but looking at my server there are a number of documents which if I PKZIP them, reduce in side anywhere from 20-60%
As bandwidth becomes more of a premium, and response times more critical as the number of users increase would it be appropriate to implement some form of compression of the raw text in the .HTM / .HTML documents ?
Obviously this would require support at two places - compression (on the fly - as some documents need to refresh frequently, or cached) at the server, and at the browser.
As long as the (de)compression algorithm was fast enought to reduce the overall transmission time there are benefits.
Jeremy E Cath
Jeremy_Cath@Sterling.Com
I guess the important thing to do is get it drafted into (if not the
standard then) recommended guidelines, so if browsers / servers want
to support http/1.1 they need to support the gzip/ungzip of the html
and data they are transfering.
If will follow up on the suggested reading, reason for this posting
was that it seemed to make sense to do to save bandwidth
Jeremy E Cath
Jeremy_Cath@Sterling.Com
