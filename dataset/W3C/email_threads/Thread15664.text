Or Ben-Natan just filed this on the HC list. Give it a look if you
can respond by tomorrow.
-- Al Gilman
Microsoft Corporation
Proposal For Aural HTML Extensions
Prepared By : Or Ben-Natan
Create Date : 6/6/97
Status : Draft
Version : 0.9
Filename : AuralHTMLProposal.doc
Copyright ? by Microsoft Corporation
All Rights Reserved
Amendments
Version
Author
Date
Change
0.9
Or Ben-Natan
6/6/97
Initial version
1 Overview *
2 Summary of requirements *
2.1 Propose user control over the rendering process *
2.2 Alternate media *
2.3 Navigation *
2.4 Forms and Input fields *
2.5 Error response *
3 Proposal for additional style sheet fields *
3.1 Define user control over the rendering process *
3.1.1 'InterruptSpeech' *
3.2 Offering Anchors and other input tags *
4 Additional Attributes For Other HTML tags *
4.1 Alternative content source *
4.1.1 VoiceFile *
4.2 Speech Recognition Grammar *
4.2.1 'GRAMMER' *
5 Events *
5.1 Error response *
5.1.1 OnSelectionTimeout *
5.1.2 OnSelectionError *
1 Overview 2
2 Summary of requirements 2
2.1 Define user control over the rendering process 2
2.2 Navigation 2
2.3 Forms and Input fields 2
2.4 Error response 3
3 Proposal for additional style sheet fields 3
3.1 Define user control over the rendering process 3
3.1.1 'InterruptSpeech' 3
3.2 Offering Anchors and other input tags 3
4 Additional Attributes For Other HTML tags 4
4.1 Alternative content source 4
4.1.1 VoiceFile 4
4.2 Navigation 4
4.2.1 'Select' 4
5 Events 4
5.1 Error response 4
5.1.1 OnSelectionTimeout 5
5.1.2 OnSelectionError 5
1 Overview 2
2 Summary of requirements 2
2.1 Define user control over the rendering process 2
2.2 Navigation 2
2.3 Forms and Input fields 2
2.4 Error response 3
3 Proposal for additional style sheet fields 3
3.1 Define user control over the rendering process 3
3.1.1 'InterruptSpeech' 3
3.2 Offering Anchors and other input tags 3
4 Additional Attributes For Other HTML tags 4
4.1 Alternative content source 4
4.1.1 VoiceFile 4
4.2 Navigation 4
4.2.1 'Select' 4
5 Events 4
5.1 Error response 4
5.1.1 OnSelectionTimeout 5
5.1.2 OnSelectionError 5
1. Overview
This document brings forward the Microsoft comments on the aural
style sheet, http://www.w3.org/Style/css/Speech/NOTE-ACSS together
with some other suggestions designed to improve the accessibility
of HTML to people with inherent of functional visual disability. .
The aural style sheet proposal focuses on the production of sound
when rendering text by text to speech engine. While this is a very
important area of focus we feel that this is not enough to address
the challenges of confronting voice based browser challenges.
Dealing only with output the current offering falls short of real
communication between the users and the browser. Users who cannot
see the text offered to them on the screen must be able to control
the manner by which content is rendered, select links and navigate
between pages and provide input such as order entry etc.
While it is possible to create a voice browser today, using the
existing HTML definitions, the result will be less than optimal as
the browser designer must make many assumptions, leaving no
control to the author of the application, or forcing the author to
learn another, proprietary configuration language.
OThe majority of our proposal may be implemented as additions to
the aural style sheet as well as additional attributes to existing
tags. No new tags are proposed. Those additions allow the author
to control the manner by which users who cannot have visual access
to the content displayed by the browser may fully interact with
it. In addition we propose the usage of media specific content
alternatives, or in more simple terms, the ability to provide a
voice file as an alternative to synthesized speech and the ability
to provide keyboard input definitions or spoken phrases as an
alternative to mouse selections.
Summary of requirements
1. ProposeDefine user control over the rendering process
When the browser renders tags it is important to define the level
of control the user will have over the process.
Users who frequently use the same WEB site normally know all that
is going to be said in the beginning of the page. This information
normally includes a welcome information and some instructions on
how to use the site. Invariably, users will want at some point to
skip those objects. The author of the application, on the other
hand, may want to limit this capability and force the user to
listen to anrecommend to the user to listen to the entire message.
The need to do this is in case there are new instructions,
promotions etc. We need a way for the author to specify whether to
allow the user to go to a next tag..
Alternate media
While text to speech technology is improving in quality over time,
the general listener experience still leaves much to be desired.
An alternative media representation such as a voice file is
necessary if professional quality audio is to be included in the
HTML page.
Navigation
Users want to use something other then the mouse to navigate. It
is impossible for people who are blind, for example, to see what
the mouse point to and select it. Rather they would prefer to
touch a key or say a word. This feature requires an HTML way of
specifying the input associated with each link. The input
specified may be a keyboard key or a phrase to be recognized by
speech recognition engines.
When speech recognition is used the author may need some over the
speech recognition parameters. This control includes pointers to
vocabulary, definition of sensitivity and more.
Forms and Input fields
We need a set of rules to define the way a browser does form
rendering. We need a way to define how input for input field is
solicited from users.
Graphical browsers place input fields in front of the users. The
user is compelled to provide the input by the very appearance of
the field on the display. Most people already know how to fill the
input fields - type in text, check a check box or select from a
selection list. In the case of voice browsers, the input or
navigation controls must be offered to the user.
Users of graphical browsers use the keyboard to provide input and
use the mouse to make selections. Voice browsers will have to
offer the user selection method through the keyboard as well as
selection through speech.
WEB authors must be able to specify what spoken phrases should be
used for the selection of links, radio buttons, check boxes, image
buttons, submit buttons, and selection lists. (Key access is
already provided by the accesskey attribute.
Error response
When using graphical browsers users select links and input objects
with the mouse. There can be no selection error. The object is
selected by clicking on it.
In a voice based browser it is easy for the user to enter
unexpected input or just stay there and enter no input at all. For
example, the browser may offer the selection of one of many anchor
tags using the keyboard, assigning a key to each anchor. Pressing
an unassigned key will be considered an error.
Authors must have control over the browser response to selection
errors and timeouts.
Proposal for additional style sheet fields
1. Define user control over the rendering process
1. 'InterruptSpeech'
Value: String | Yes|No
Initial: YES
Applies to: All elements
Inherited: Yes
InterruptSpeech controls the user's freedominform the user agent to
recommend that the user will not barge in and interrupt a message with
a voice or a keyboard selection. in stopping the speech rendering
process and move to the next input element.
Possible values to this attribute:
* Yes
* No
Browsers are free to define their behavior for InterruptSpeech. If
enabled, both keyboard and voice may be used to interrupt the speech.
Example:
P {InterruptSpeech : No}
1. Offering Anchors and other input tags
When relying on text to speech engines rather then on pre-recorded
voice files, the offering of anchors and other input tags may be done
using the text associated with the anchor or with input tag (text may
be associated with input tags using the label tag).
For example.
May be offered by the voice browser using the following words:
"for driving instructions press D1"
The example shows how the phrases "For" and "Press 1" were added to
the text embedded in the anchor tag.
On first glance it looks as if this 'wrapper' text should be left for
the voice browser, but on further examination one can find problems
with this approach. For example, how will you offer the following
anchor tag?
Speaking EnglishIn the English language you would rather say "To leave
us a message, press M1"
One may correctly assume that foreign languages will have even more
structures and special words whichwords, which apply to special cases.
There are several options to implement this feature. One is to assign
it a property in a style sheet. This may be a good idea because of the
way cascading style sheets effect entire documents from one place. It
is assumed in most cases one wrapper string will be used while a small
number of offering will sound different.
Another implementation idea is similar to the image map. In the case
of image map, the same mapping scheme may be applied to many maps in
the document. Assuming the browser may use its own default for most
cases, the author of the document may point each one of the small
number of offerings requiring a special link to a central location
with a different wrapper string definition.
1. Additional Attributes For Other HTML tags
1. Alternative content source
1. VoiceFile
Value: URL
Applies to: all elements
A voice file is an alternative source of content for the tag. For
example, a text paragraph may be rendered using a recording.
The value of VoiceFile is a URL pointing to the voice file.
A voice file may be used as an alternative to various elements
(e.g. an input field name, a table header (the th tag), a table
data td , etc.).
Speech Recognition GrammarNavigation
1. 'GRAMMERSelect'
Value: ascii ? string
Applies to: All input related tags ( A , input of all types
etc.)
The Select attribute allows a string to be used with the help of
speech recognition software for the selection of the input.
The Select string applies to anchors and input tags (of type
checkbox and radio buttons.)The GRAMMER attribute allows the
inclusion of a grammar block with an input tag. The grammar block
allows a speech recognition engine to analyze different type of
speech in a better way. At the present, the proposal does not
include the format of the block. This will have to be done in
coordination with the speech recognition industry.
For clarity purposes an example for the necessity of the GRAMMAR
attribute is provided here.
An HTML page may include a check box. The title of the check box
may be Are you an American Citizen.
A voice based user agent may ask the user, with the help of a text
to speech engine, "Are you an American Citizen"
The possible answers may be "Yes" or "No" but it could also be any
other word used for negative or positive respond in the callers
language. It could be "Ya," "you batchya," "sure," "of course" and
many other expressions. It is necessary to feed to the speech
recognition engine with many possibilities representing the
desired response.
2. Events
1. Error response
The action of error response is defined as an event in association
with a body of input or selection which includes the place where
the input is solicited from the user by means of talking to the
user and the place where the browser waits for the input.
Two types of error response are proposed. An error for a situation
where no selection is made or no input is entered and an error for
a case where a selection is made for something which is not
offered.
1. OnSelectionTimeout
The browser may generate OnSelectionTimeout event when the
user is asked to provide input of any kind such as a
selection from a list of anchors or an text input box and
fails to do so.
For example, the following block may be offered the user for
navigation.
P onselecttimeout="browser.speakout ("You have not entered
any selection, please enter your selection now")"
The OnSelectionTimeout onselecttimeot event is processed by
the browser according to the browser own definition of
timeout for input entry or selection of anchor tags.
The OnSelectTimeout event applies to all block tags as well
as form elements.
2. OnSelectionError
When the user selects an option not offered by the browser the user
must be notified that an error occurred. The notification and the
resulting action is to be performed by a script associated with
OnSelectionError event.
Example:
P onselectionerror="browser.speakout ("The selection you have entered
is invalid, please enter your selection again now")"
Some of the suggested aural requirements in Or's draft appear to
be undesirable for universal access.
Consider:
1. ProposeDefine user control over the rendering process
When the browser renders tags it is important to define the level
of control the user will have over the process.
Users who frequently use the same WEB site normally know all that
is going to be said in the beginning of the page. This information
normally includes a welcome information and some instructions on
how to use the site. Invariably, users will want at some point to
skip those objects. The author of the application, on the other
hand, may want to limit this capability and force the user to
listen to anrecommend to the user to listen to the entire message.
The need to do this is in case there are new instructions,
promotions etc. We need a way for the author to specify whether to
allow the user to go to a next tag.
It is better for accessibility if the author does not have the
last word. The user should have ultimate control, with the
author indications acting as default in the absense of user overt
action. This is discussed further in
Status of ACSS action item on 02 July 1977
--Al Gilman
Like Al, I have several reservations about Or Ben-Natan's Proposal For
Aural HTML Extensions recently posted to the HC list. Al pointed out the
overall problem: the proposal takes too much control away from the user and
gives it to the author. Allowing the author to force a user to listen to
particular parts of the page, making parts non-interruptable, and
specifying acceptable inputs by context violate much of what I consider to
be good UI design principles. On a distributed medium like the Web, it is
a recipe for disaster.
What follows is a rather long attempt to justify that statement, so if
you're not interested in the details, you'd best stop reading now.
Consider:
This appears to recommend completely disabling all user control of
navigation while some portion of a document is being read. What kinds of
things will authors consider important enough to be non-interruptable?
Certainly advertising messages, but I suspect many authors will disable
interrupts for entire pages. Imagine the Web listening experience when you
have the potential of following a link and suddenly you are stuck listening
to 100K of text on someone's favorite subject, and you can't stop it.
I'm not entirely sure of the purpose of this proposal, so I may be off-base
here, but it appears to address the issue of dealing with a menu of
hot-links. It seems to want to associate a different keystroke with each
anchor in a set of anchors, emulating the voice-text telephone menu systems.
I see no need for this. First off, those are terrible interfaces and the
navigation functions of most screen readers can avoid the necessity of
doing this. Consider the cognitive load in these two cases:
1.You listen to a set of menu items and key names,
construct a mental mapping of menu items to key names,
chose an item from the menu,
recall the key name for that menu item, and
find that key on the keyboard and press it to follow the link.
2.You listen to a set of menu items,
remember the order of the items,
chose an item from the menu,
press the back-arrow key enough times to get back to that item,
press a "select" key to follow the link.
The second approach seems to have the lesser cognitive load, and provides
the user with feedback: if they don't press "select" right away, the user
agent will start reading the document at the menu item they reached.
Besides increasing the user's cognitive load, assigning keystrokes to
anchors will permit inconsistency between pages. Some authors might use
numbers, some a mnemonic lettering scheme, and so on. The user is forced
to figure out a new response system for each page.
This proposal allows the author to control the inputs accepted by a speech
recognition engine for a particular link or INPUT tag. I really hope
that the proposal was suggesting that the author's suggestions were in
addition to whatever inputs are expected by default. If not, this will
destroy the consistency of speech interfaces. If an author uses the Select
attribute to allow the responses "sure" and "OK" to a checkbox, will the
user no longer be able to say "yes"? How is the user to know what the
permitted responses are at any given time? There needs to be a consistent
set of responses available to the user in any given context, regardless of
what the author wants. These are features of the user agent, not the
document being read.
Even if the proposal is to allow the author to augment the set of valid
responses, there are additional problems. What if the recognition engine
cannot recognize those words? What if a word for a positive response is
unexpectedly close to some word for a negative response in the recognition
space, so that if they say one word it is quite likely that the other will
be recognized? Most importantly, there is no user feedback. How is the
user to know if their response was correctly recognised? This is the most
important aspect of any voice interface.
Control of error response mechanisms belongs in the user agent, not the
document. An experienced user is not going to want the same level of error
notification as a novice, and will not tolerate it for long. Were I to
mis-type a key, I don't want to hear anything more than a half-second
tone. Hearing the same message every time, especially one that is not
front-loaded, would get old really fast.
I have some suggestions for addressing these problems in a more friendly
manner. They are:
1. Instead of making text playback non-interruptable, allow the author to
specify points at which a user agent's navigation functions should stop.
For example, a user agent might have a navigation function that moves
forward to the "next section" of the document (however that might be
defined). An author could place an attribute on any tag to get such a
browser to treat that tag as dividing a section, thus causing it to stop
and begin reading at that tag. The user then gets to decide if they want
to skip forward again or keep listening. This addresses the issue of
getting people to attend to new information on a page.
2. Dealing with speech input for links and INPUT tags is not a simple
issue. There are three topics to address here: active vocabulary, word
assignment and feedback.
a) By "active vocabulary" I mean the set of words that a recognition engine
will accept at any given time. This should be controlled by the user
agent, as it must be able to inform the user in some way just which words
are allowed. We could allow an author to suggest additions to the active
vocabulary, but the user agent must decide to accept or reject those
additions.
b) By "word assignment" I mean how the user agent decides what to do in
response to each word. Does it check or uncheck a checkbox when it hears
"sure"? If we allow the author to suggest additions to the active
vocabulary, they must also specify what should be done when those words are
recognized. You could have two attributes for this: SelectCheck and
SelectUncheck.
c) Feedback on the results of speech recognition is the most important
issue. Personally, I'd like to hear a non-speech signal telling me if I
checked or unchecked a checkbox. I'd also like to have a method of
reviewing an entire form quickly before selecting the "Submit" button,
hearing what I selected in each input item. Note that both of these ideas
have to do with the user agent, not the document.
This has gotten far too long for a response to a proposal that is somewhat
peripheral to this list, so I'd better stop now.
- MacK.
Edmund R. MacKenty
mack@sonicon.com SONICON Development, Inc. (1-617-926-2131)
aloha, al et. al.!
how sadly ironic that the MS proposal should degrade so ungracefully when
rendered by lynx or any other text-based browser... i can get realaudio
to stream through my desktop when browsing with lynx32, yet i can't get
consistently comprehensible aural output from a document automatically
converted into hypertext by Word97...
if MS is to convince me that they are serious about accessibility and
standards, then they will either bundle an HTML parser/validator with
their HTML generators, or at the very least, take the time to _validate_
the output of their automatic conversion utilities before posting,
mounting, or circulating any hypertext documents generated by such
utilities... checked against
for compliance with HTML 3.2 the MS proposal contained 199 errors...
and, while--for the most part--the actual body of the document was
comprehensible, the front-matter most decidedly is not--save for those
fortunate few who have access to a cell-by-cell capable browser... in
particular, anyone listening to the proposal as rendered by lynx 2.5
and greater, would have heard the table-ized content as:
Version Author Date Change 0.9 Or Ben-Natan 6/6/97 Initial version
of course, this is the root of the problem which we are attempting to
solve through our participation in the WAI and its working groups...
but what of the user who will not reap the benefits of our work? those
who, for whatever reason, physical and/or financial, have no choice but to
use antiquated equipment and/or access the web via a shell account that
features an ancient version of lynx which doesn't even support lynx's
de-table-ization kludge? while it is the purpose of this list to look
forward, we must not forget that true accessibility looks as far
backwards as it does forward...
what am i talking about? perhaps a listen to/look at/feel of
will make my point more forcefully... and, should Microsoft (and
its rivals in the GUI-based browser market) consider implementing an Aural
Accessibility Protocol/Patch, such as that outlined at:
which would (amongst other things) allow the user to de-table-ize
table-ized information, backwards-compatible access is extremely realizable...
by way of conclusion, i should stress that it is not my intention to
scapegoat Microsoft on this issue--invalid HTML is endemic to the
output of HTML authoring/conversion programs/utilities... and, while
SoftQuad has taken steps to remedy this with the release of HoTMetaL 4.0,
HTML validation within authoring/conversion programs is still in its
infancy... this, coupled with the ever-increasing popularity and
ubiquity of such authoring/conversion applications and utilities, presents
one of the most serious threats to an accessible internet...
gregory.
oedipus@hicom.net
gregory@afb.org
Gregory, your points are well taken and I advise that we do indeed have a
broad climate here, by broad I mean in this case down and up or
multiplatform rather than back or forward. it is nice as you say to take
care of the forward because that perhaps in one way or annother is where
we are all headed eventually perhaps looking forward to the day when
streaming computers are the network and the device is not dependant on
cost or anyother inhibitting factor. However. as you well point out and
should be heeded today we face the challenge of what is and not
necessarily what ms wants to be the standard. I propose that we take up
the challeng we've been handed in this model and attempt to develop a
parellel model.
Hands-On-Technolog(eye)s
touching the internet
voice: 1-(301) 949-7599
poehlman@clark.net
ftp://ftp.clark.net/pub/poehlman
Gregory,
Can you tell me what's wrong with the conversation? Email me privately.
Charles Oppermann
Active Accessibility, Microsoft Corporation
"A computer on every desk and in every home, usable by everyone!"
