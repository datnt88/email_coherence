It appears that nearly 75% of W3C members are not following the very
guidelines they help create.
Brant Langer Gurganus
Editor, Open Directory Project
Default QA Contact, Mozilla Evangelism
Technician, Protonic.com
Webmaster, troop545.cjb.net
Webmaster, www.firecrafter.org
Webmaster, www.msdpt.k12.in.us/etspages/ph
Junior Assistant Scoutmaster, Troop 545
Eagle Scout, Boy Scouts of America
Member, Internet Society
It's an interesting indicator that I hope Marko will run as often as
possible. I know that he will do it every 6 months.
The home page validation is an indicator but a loosely one, because
imagine members start to worry about the validity of their home page,
they will achieve a better press coverage... but it will not mean
that the rest of the Web site is valid or all Web sites that a
compagny has in charge.
For example, it would be good to define a relative scale of validity
for a whole website.
proportion of
valid pages
50% BAD
50%-70% you're on the good way
70%-90% good
90%-100% Great!!! you have a valid website.
After the same time we "evangelize" for validity, we have also to
evangelize for the correct semantic use of tags and the accessibility.
for example
You can make a valid document, which is completely incorrect for the
semantic, like using a "blockquote" element to indent un text and not
for a citation.
So we have work.
PS: When I come back from holidays, I will update the document
Web-Quality with ideas that have been sent.
If people feel that I have missed bits, examples, or they would like
to see more things in it. Please send your comments here.
Karl Dubost / W3C - Conformance Manager
--- Be Strict To Be Cool! ---
Having an artist in a family doesn't necessarily means everyone craves
his or her work. The situation with W3C members may be the same,
I don't know, I can't and won't speak for all W3C members.
My only experience is that my W3C Host, Keio university/Shonan Fujisawa
Campus, has most pages on its site valid, and that's partly because some
people from the W3C Team helped and convinced them it was important.
On the other hand, the global home for Keio university is invalid...
I wish the survey continues, in order to see whether these figures
should make me sad or optimistic. A possible conclusion, today, would be
that if "we" want to convince people to respect web standards, there may
not be any "easy target".
But then again, how do you define the proportion of valid/invalid
material? in volume? number of pages? bytes?
I like the "traffic approach" that Gerald Oskoboiny had developed in his
"top-invalid tool"[1] - ancestor to the LogValidator[2].
[1] http://lists.w3.org/Archives/Public/www-qa/2001Sep/0031.html
[2] http://www.w3.org/QA/Tools/LogValidator/
What's the traffic approach? Imagine you have 4 documents on a site
(we'll call them 1,2,3 and 4), accounting for, resp. 40%, 30%, 20% and
10% of the traffic for this site.
Now imagine that documents 1 and 4 are invalid. that's 50% of the
documents, and 50% of the traffic, and that's bad. If you have time to
fix both documents, fine, but if you have time to fix only one?
The usual approach woud be that, well, just fix one and you'll have only
25% of the documents that are invalid. The traffic approach says, fix
document 1 and go up to 90% of your traffic being valid.
That may sound ridiculous with 4 documents, but when it's 40000, with a
lot of legacy, unmaintained documents, you're happy when you can go from
50% valid to 90% valid by fixing only 25% of the documents.
I'm preparing an article/LogV tutorial that explains this and other
ideas to "fix" better, so stay tuned.
Now that's a summary :)
Olivier Thereaux - W3C
IMO such a document cannot be said to be valid. That validator.w3.org
doesn't find any errors does not mean that the document is valid,
similar to how running a document through your word processor's spell
checker is no match for having it proof-read by a person.
/Jonas
The W3C page on document validation somewhat discusses this problem
at http://www.w3.org/TR/html4/sgml/intro.html , even though they're
focusing on technical mistakes like illegal (but 'valid') attribute
values.
Validation is simply a check against the referenced DTD, nothing
else. So any HTML document that conforms to the referenced DTD is
valid. Whether the document uses the right markup for the right
content, or whether the text makes any sense at all, is not part of
the validation process. That's why even valid HTML, just like
spell-checked documents, can be complete gibberish. See
http://groups.google.com/groups?selm=35080%40sdcc12.ucsd.edu&amp;output=gplain .
But of course I do agree that semantic is very important. This aspect
of the standards sometimes gets lost in the recent coolness of
validation. Perhaps it gets lost because correct semantics require
that the author actually know the standards, while validation can be
done by a stupid machine.
Matthias
Do You Yahoo!?
Yahoo! Finance - Get real-time stock quotes
There's more than that, there are requirements in the W3C
specifications which can not be defined with a DTD. So can make a
three level rocket ;)
1. Validity with regards to the DTD
Automatic process if the validator checks everything and does
not contains errors.
2. Conformance with regards to the specifications.
For example, the stylesheet language when you are not using a
style element or/and an external style sheet.
See http://www.la-grange.net/2002/04/03-styleatt-wo-meta.html
3. Respect of the semantic as you said in your mail.
On top of that we can add the respect of the semantics. :)
I think the respect of the Semantic will be the most difficult to
achieve even if it's the easiest to achieve and understand.
Karl Dubost / W3C - Conformance Manager
--- Be Strict To Be Cool! ---
Test, please ignore.
