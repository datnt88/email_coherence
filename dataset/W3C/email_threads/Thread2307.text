Jeff Mogul and I valunteered to write up a draft on simple demographics
-- not the be-all and end-all, but something that would be enough to get
an appreciable number of content providers to stop sending cache-busting
responses.
It is alleged that some advertisers want to pay content providers, not
by the "hit", but by the "nibble" -- the number of people who actually
click on the ad to get more info.
Now, HTTP already has a mechanism for doing this: the "Referer" header.
However, it is normally disabled for privacy reasons -- according the
the spec
"Because the source of the link may be private information
or may reveal an otherwise private information source, it is
strongly recommended that the user be able to select whether
or not the Referer field is sent."
In the case of ads, the source of the link _really wants_ to let the
referred-to page know where the reference came from.
Suppose we augmented to semantics of the Referer header so that, if it
is used as a _response_ header (it is currently just a request header),
it means that the server requests that a referer header is sent on any
link followed from this page. If the user wishes to browse without
leaving any trail of where they came from, they could override this, of
course -- but I'm thinking that we would recommend AGAINST this, for the
following reason:
If one doesn't do some such thing as sending Referer, then I imagine
that what content providers would do is have the URI that is the target
of the link be unique to the content provider, so that the advertiser
can tell which content provider is the source of each hit. So, all that
turning off Referer does is cause cache-busting behavior.
What I'm looking for are comments on the privacy concerns with such an
approach.
Redmond, WA 98052
[This as Cc'd to the list, as the original was sent to the list, as well
as the fact that it seems a relevant thing to discuss here. I'm including
this message at the top, just to say "I hope this is appropriate, yet I'm
not sure."]
If you need any help, let me know.
Good point. The referrer header should be able to be requested to be
sent to the next page, but _only_ if the server that the link is on says
to go for it. If the server does not imply it, it should be assumed no.
But also, it may be worthwhile to have the Referrer header sent if the
page the browser is going to is on the same server as the link to it.
i.e. URL: http://www.megacorp.com/whatever.html has a link to URL:
that the browser send the Referrer header to the second one, stating that
it came from the first document. As they are on the same host, there
isn't really any large security issue.
Another idea would be for the first server to send a 'Trusted hosts'
header, that would imply that any hosts specified there are considered
trusted and the referrer should be sent to them. This way, if it is a
private server, they can allow referrer header to be sent to their sites
(such as URL: http://www.megacorp.com has a private site for their
employees, too at URL: http://employees-only.megacorp.com/private/ the
employees only place can include the former (public) WWW server as a
'Trusted Host' so that they can determine which hits came from inside
their company. Now, this also brings up an additional point: do we allow
the user to specify Untrusted hosts?
There would probably be a great deal of concern over a browser sending
the headers without asking the user, much like the fuss over Netscape
Navigator (tm) sending the 'From: ' header with the configured e-mail
address in one of their Beta versions. While referrer doesn't seem to be
as large of a security risk or privacy issue, it could cause some
nervousness among users and companies, if they were relying on security
by obscurity (not telling others about a private site, rather than
protecting it)
About the only way to avoid this is to make sure that the spec says that
this should default to 'none' if the 'trusted hosts' isn't there, or the
site with the link doesn't say that it wants Referrer sent.
If applicable, the spec should also make reference to the User having
control as well.
Kris "The Doctor" Benson kris@hackers-unlimited.com
President, Hackers Unlimited
Personal HomePage: http://www.hackers-unlimited.com/doctorkb/
Hackers Unlimited: http://www.hackers-unlimited.com/
JAPH, HTMLer, Webmaster, UNIX guy for hire...
##### May your beard and your .sig grow longer with wisdom #####
I would rather see a single mechanism for indicating the privacy
category (or categories) of the content of a message, than a specific
header field for every conceivable category or method by which the
privacy might be compromised. It most certainly should not be limited
to referrals from prior GET responses.
Likewise, it should make the common case efficient -- that is, no such
field would indicate that it is okay to send Referer (which is the common
case today -- the HTTP spec only suggests that the browser be configurable
to avoid sending it, not that it shouldn't send Referer by default).
Naturally, this should be done in PEP (or an equivalent replacement if
PEP is not in HTTP/1.2) since that matches PEP's intended capabilities.
...Roy T. Fielding
Department of Information &amp; Computer Science (fielding@ics.uci.edu)
Paul Leach:
I don't think that a two-way referer field can solve the nibble count
problem. For it to work, two-way referer would have to be enabled by
default, but for privacy reasons, it would have to be disabled by
default. My proposal is to add no extra mechanism, and to rely on
schemes that embed the referrer in the URI like this:
By having the above URI point to a CGI script which returns a 302
redirect to the real home page http://www.blah.com/ , this scheme can
be made to act in a cache-friendly way, especially if the 302 can be
cached by proxies which report hits.
In my opinion, HTTP already supports nibble counting in an adequate way.
There is no need to add a new mechanism. The gains which could be had
by adding a new --working-- mechanism would not outweigh the cost of the
mechanism and its introduction.
Koen.
#!/usr/bin/perl
$_ = $ENV{'PATH_INFO'};
s#^/##o;
print "Location: $_\r\n\r\n";
(Ok - so, I'm depending on the server to add the 302 code. If you want
to, you can add the one line change).
I use this to count hits on links going *out* from our site. It wouldn't
be hard to integrate the functionality into a server for performance.
Anyway - it doesn't require any changes to HTTP.
Benjamin Franz
I think you've got this wrong, but it doesn't matter -- I think your
proposal is cleaner. (Both proposal are just ways that the site declares
that it doesn't care if the referer info is disclosed to the target.)
If the 302 is cached, then the referrer info will be lost. Unless you
mean that the cache reports hits on cached 302 responses? I hadn't
thought about this, but I guess that it would probably fall right out...
it might be important to be clear that hitcounts should be reported in
this case, though.
For ads that are placed on a lot of sites, this would result in a lot of
cached 302s for the same underlying page.
However, you've made me realize that caches completely break my original
scheme....
If fact, "Referer" makes it very hard for a cache to be semantically
transparent: if a cache was trying to be semantically transparent, the
presence of "Referer" on a GET request should cause a cache to do a
conditional GET on the Request-URI. The only way to avoid this would be
to remember each different value of Referer: had been seen and to report
hit counts on each of them (somehow). Not only is this more complex than
using cached 302s, it also would result in exactly as many remembered
Referers as cached 302s in your proposal.
I agree. I do think it needs to be explained, because it isn't obvious
(wasn't to me, anyway, so I'll put such an explanation in the draft,
with credit to you (if you don't mind).
Paul
Not that I'm recommending this per se, but if a server cared about
this, it could use the Vary header to indicate the result
varies on the Referer request-header, causing any caches to treat the
results independently.
Of course this would mean a lot more bookkeeping entries in caches, but
implementation-wise, if caches could have unique entries for resources that
were logically different but physically identical (using a digest hash
or something), this wouldn't be that much uglier than some
special case method of keeping track specifically by Referer.
--Shel
Neat observation. Certainly better than some special purpose hack. But
I'll bet not many caches will try the optiimization you suggested to
avoid duplicate entries.
From: Shel Kaphan[SMTP:sjk@amazon.com]
Sent: Wednesday, July 10, 1996 12:19 PM
Subject: RE: Demographics
I had a series of discussions with the folks like clickshare who are
trying to make money from selling demographic data.
My first approach was to push the referer field - tracking ads was
one of the original applications I had in mind for it. Its a pity that
the concern for privacy that has reduced the impact of the referer
field was not present when cookies were thrown in. One of the problems
with concerns about security, privacy etc is that the criteria being
applied tend to shift depending on who proposed what.
I think that any discussion about privacy needs to take account of
the following realities :-
1) Content costs money to provide. In a capitalist system there must
be mechanisms that cover these costs or content won't exist.
2) Vanity publishing and technology research will not continue to
pay for the New York Times etc. indefinitely. A lot of content
providers have been prepared to give away content for free just
to learn the potential of the technology. If we cannot provide
mechanisms to pay for content then sites will soon start
disappearing.
3) The current protocols admit any number of ad-hoc hacks that create
linkage. Most of these mean that documents has to be
customized for each reader which in turn means that caching will
not work. This model enforces a communication with the host server.
4) Payment for content on a subscription model limits the audience for
a product, it means that the rich inter-linked nature of the
Web is lessened. The marginal cost of following a link becomes
very substantial. If charging mechanisms are restricted to
subscriptions alone the objective of disintermediation, removing
the power that Murdoch, Maxwell and their cronies have over
the movement of information will be lost. We will only be able
to buy content that comes from large publishing corporations.
There will not be the leavening of small independent
self-published works.
Consider the reason why the software industry is so inovative.
A large number of the key ideas come from independents who can
inovate without the constraints of consistency of corporate
view that constrains large companies. This keeps the large
companies honest. They have to keep up with the pace set by the
small companies or watch their market disappear. I want to
see that type of competition in news reporting so that the whole
story comes out, not just the part that suits the politics of
a newspaper proprietor. Remember the Time Cyberporn article?
In that case Time were caught out and they retracted (if
grudgingly). Normally the would not have retracted, they publish
the facts so the facts are defined to be what they published.
5) Current anonymous payment schemes are not practical for small
payments. Public key cryptography is barely practical even
with amortisation schemes such as payword. Empirical evidence
suggests that the holder of key patents has an unfounded
belief that electronic commerce cannot take place without him.
Consequently any payment scheme for small or large payments
is almost guaranteed to NOT provide the unlinkability which is
technically feasible.
Therefore if we reject advertising as a model on the basis
that it has privacy problems we are likely to end up with a
model where the purchaser BOTH pays and loses privacy.
The requests that I have had for demographics tracking have had to
take account of the following "needs".
1) Identify readership
a) volume (exposures/hits)
b) interest in/purchase of advertised product
c) demographic grouping
2) Provide audited measures of above in a manner which is
a) consistent across content providers
b) commensurate with other measurements from other media.
2b is a key point, the recent Nielssen report recieved criticism from
a certain quarter because it alledgedly overstated the number of
Internet "users". In fact the study had deliberately chosen a
definition of "user" which was commensurate with other media, in this
case the number of people in a household wich had internet access and
not the number of people who had used the internet. Why measure it
this way? Well consider a case where you want to buy a new car, you
know that your son can get details of prices via the internet, you
ask your son to do the search. In other words the potential audience
outreach is not necessarily the direct readership. There are similar
fudge factors for other media (pass on readership of periodicals).
One important point is that the advertisers are not really interested
in "readers", they are interested in an index that corresponds with the
measures they already use.
Phill
Phill
Paul Leach:
[Koen Holtman:]
Yes, this is what I mean.
Koen.
I have been following this thread for the past couple of days and being from a company that makes its living from measurement and analysis on access information of most of the major sites on the internet I can assure you that the refer field is of the highest importance to advertisers and sites. I agree with phil that we live in a capitalistic society where advertising pays for a great many things or subsidizes them. For example magazines and newspapers. I do agree that privacy is a concern on the Internet but if we as technologist do not provide a solution to content providers that will provide this information then sites and advertisers will just figure a way to hack around it. You see this already with sites like yahoo that redirect back to there sites when people leave. This is a performance hit that yahoo is willing to accept and apparently so is the consumer.
Perhaps we need to address the following questions separately:-
1) What is the information that the Advertisers/Auditors want?
I see this as beeing at two levels,
1) What is the information they want to obtain?
2) What measurements do they want to capture to achieve (1)
Referer comes under (2) in my view, as do most protocol level
hacks. The important question under (1) is "what financial
value will an advertiser recive from advertising at a site?"
2) What mechansims are needed to transport information captured
under (1)
Note that in my Log file format and Proxy notification specs I
worked mainly on the second issue and tried to make the transport
mechanism as separate as possible from the issue of what must be
transported.
A second scenario I think that the Newspapers in particular should
consider. Say I am a comuter who wants to download the Times each
night and pick up a loaded laptop on the way out to work. In that case
it would be very usefull for the laptop to inform the originator what
material was actually read the next time a download was taken.
This is a material benefit to the user - the newspaper can discover
what articles it publishes are important to readers and which they
don't bother reading.
[Yep Privacy issues up the Wazzo, privacy is only one ethical dimension
however]
Phill
