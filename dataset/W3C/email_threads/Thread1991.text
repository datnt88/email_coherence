Scott Adams just held a signing session at Kepler's in Menlo Park; this
being Menlo Park, I brought along a copy of the new specs, and as a
result, the HTTP-NG architecture spec now sports its own Dogbert
dedicated to the HTTP working group. Does that mean I have to give Scott
co-authorship?
Simon
(defun modexpt (x y n) "computes (x^y) mod n"
(cond ((= y 0) 1) ((= y 1) (mod x n))
((evenp y) (mod (expt (modexpt x (/ y 2) n) 2) n))
(t (mod (* x (modexpt x (1- y) n)) n))))
gif! gif!
(defun modexpt (x y n) "computes (x^y) mod n"
(cond ((= y 0) 1) ((= y 1) (mod x n))
((evenp y) (mod (expt (modexpt x (/ y 2) n) 2) n))
(t (mod (* x (modexpt x (1- y) n)) n))))
Hello All:
I have been following the byte range discussions with much interest.
What I propose is that instead of byte ranges, that a concept like
time code be utilized to control media on the web. Traditional time code
has the form:
hours:minutes:seconds:frames
I propose that this be augmented with, for example, the following
information:
URL:filename:hours:minutes:seconds:frames
This would allow the HTML creator to determine what frames
to be played from a video or audio stream. As for text information
the author could determine that each page is a frame for example. The
text creator would then determine the range of pages to send.
I am proposing the use of time code because I feel the HTTP server
should be viewed as a media server as opposed to a byte stream server.
If it is considered in this fashion then the HTTP media server coupled
with a time code based access mechanism could become much integrated
with content creation. For example, content creators could go straight
from non-linear edit systems to the web.
Comments ?
West Suhanic
What we really need (to repeat), is a general addressing mechanism
similar to that offered by HyTime. If we continually reinvent
addressing schemes with different syntaxes, it makes supporting all
the various syntaxes a real headache. One general (and extensible)
syntax is far more preferrable.
Not that I am arguing for adoption of the syntax...
It seems there at least a couple of questions that can be addressed separately:
1. Should there be one uniform syntax for addressing sub-parts of
"structured resources" independently of the content-type?
2. Should this addressing scheme go into URLs or elsewhere?
On (1), I find it hard to imagine that it is possible to predict in
advance what kinds of parameters, ranges, subspaces, sets, regions,
chapters, verses, etc. are going to be needed to describe this in a
world of increasing numbers of content-types, so unless someone can
demonstrate a sufficiently general design, I suspect this is
impractical.
On (2), since there is little guarantee of an association between a
URL and any particular data type, and decreasingly so a
content-negotiated world, I think it is a mistake to tie sub-part
addressing into URLs. It would seem that requests for sub-part
addressing would have to be tied to specific content-types in the
request.
Yes, which is precisely what HyTime does. I can do the same thing in
LISP. I cannot imagine a way to define a general adressing scheme
without also making the addresses almost impossible to remember
though... in an ideal world, one would not see most of these links "in
the raw" anyway.
I tend to agree.
Hi Again:
I think the central issue here is where the concept of media
is handled. If the HTTP server is considered as a media server
then it must have the facilities to deal with media. Time code
is the language of the professional media creators. Therefore
given the web's ever increasing consumption of media it would
have to deal with time code. However if the server is still
viewed as a byte stream server then this would push the
responsibilty for dealing with media out to the clients; ie,
browsers and any tools they use.
Either way there has to be a richer media control mechanism
than byte ranges. I think time code is it. For me the important
issue becomes which end handles it.
The only problem with having it in the client is that it requires
every client to understand the data format. What happens when a new
data format is invented, or when a client wants frame 1 of an MPEG
movie in GIF form, because it doesn't have the code locally for
handling MPEG?
I think the central issue here is where the concept of media
is handled. If the HTTP server is considered as a media server
then it must have the facilities to deal with media.
We've had this discussion at least once before. I firmly believe
that HTTP should NOT be used for real-time continuous media. The
URL mechanism allows us to include multiple transport protocols
(e.g., HTTP, FTP, Gopher) in the web, and if we want to include
real-time continuous, then we should use a protocol optimized for
that. We should not try to turn HTTP into a kitchen-sink protocol,
making it into a second-rate media protocol while also making it
harder to implement.
As a purely practical matter, this working group is chartered to
work on IETF standards, which normally require "rough consensus
and working code" to progress. We would be in relatively uncharted
territory when it comes to real-time continuous media, which is
still the subject of active research and debate. It would be
quite premature to try to standardize this kind of thing, especially
in the context of the most heavily-used protocol protocol in today's
Internet.
-Jeff
I'll second this, and point out that the Upgrade header field in the
draft of HTTP/1.1 is designed to allow changes in application protocol
when the server wants to send a resource with these characteristics.
...Roy T. Fielding
Department of Information &amp; Computer Science (fielding@ics.uci.edu)
One major point in making HTTP more supportive of media communication
such as this is that a significant number of users will be utilitizing
proxies. Each new protocol must be handled by the proxy, and if you
only have an HTTP proxy, you are out of luck.
The media would not have to be served in real-time. Rather
I envision the first pass providing the ability to provide
users with richer access to media via mechanisms like time
code. I don't think including a more media friendly mechansim
would make http a kitchen-sink protocol. It could make it
more powerful to work with media which would ultimately permit
a richer communications environment.
- West
