On 23 October 1996, the ERB will vote to decide the following
question. A straw poll indicates the question needs further
discussion in the work group.
C.10 Should XML allow nondeterministic content models (11.2.4.3)?
Yes, but if we do that, why not full regular expressions? We trashed that
(unwisely) in the name of SGML compatibility. I don't understand the
reasoning here.
-- David
RE delenda est.
David Durand dgd@cs.bu.edu \ david@dynamicDiagrams.com
Boston University Computer Science \ Sr. Analyst
--------------------------------------------\ http://dynamicDiagrams.com/
MAPA: mapping for the WWW \__________________________
On Thu, 17 Oct 1996 22:50:14 -0400 David G. Durand said:
My sense of the ERB's intention is that there is some desire to reopen
that question and to consider changing the earlier decision, at least in
individual cases (which include general regular expressions and
determinism in content models).
I should probably have said that explicitly; sorry.
-C. M. Sperberg-McQueen
Yes.
(I assume that "determinism" -- or the complementary "ambiguity" -- here
pertains to the sense clarified in Anne Bruggemann-Klein's work: that the
Glushkov NFA is also a DFA.)
Strictly speaking, this is an issue of validation, not parsing, i.e. the
software involved need only be a recognizer, not necessarily a parser. (A
similar comment applies to "syntax directed translation" via attribute or
transduction grammars, where the need to preserve the semantic content -- or
intent -- can introduce tradeoffs in algorithms between scope and efficiency.)
AFAIK, most recognition algorithms actually exploit nondeterminism in the
sense that they work as NFAs rather than DFAs (sometimes even constructing
states and transitions on the fly), because the problem is to validate an
instance as an admissible member of a class without necessarily preserving a
parse tree (like a non-constructive existence proof.)
Annex H notwithstanding, the only advantage of "deterministic" content
models is forwards compatibility with unreviewed 8879.
Arjun
"Features whose purpose is to cause errors should be removed" -- Erik Naggum
In fact,
the ambiguity rule can make things *easier* for implementors.)
Say what? The algorithms necessary to detect ambiguity are not typically
within the repertoire of the hypothetical CS bachelor's-degree type that
we'd like to be able to construct a validating parser. Furthermore, with
the parser generators that I have to hand, in no case does an ambiguous
content model complicate the task. Furthermore, since we've lost the
tag miminization that opens the trap that I have been told the ambiguity
exclusion exists to patch, I can't imagine why an XML parser author would
*want* thus to constrain DTD authors, aside from a desire to comply with
a non-useful clause in a standard that is there only to ensure compliance
with another standard, which in any case is likely to be amended soon to
remove this problem.
If it's not obvious, I am deeply unhappy with the prospect of the
restriction on so-called "ambiguous" grammars making it into XML.
Cheers, Tim Bray
tbray@textuality.com http://www.textuality.com/ +1-604-488-1167
In fact, the ambiguity rule can make things *easier* for implementors.)
True: the ambiguity restriction makes it harder to validate DTDs.
However, it can make it considerably easier to validate *instances*,
if the parser is allowed to assume a DTD with no nondeterminstic
content models (i.e., that the DTD has already been validated).
How much easier depends on the algorithm you use, of course,
but for many automata-based algorithms the savings are considerable.
The "run it through perl and feed it to yacc" algorithm on the
other hand does not benefit from the restriction at all (modulo
potential exponential blowups in pathological cases); but I've
never found this to be a particularly efficaceous way to process
SGML...
--Joe English
jenglish@crl.com
In fact, the ambiguity rule can make things *easier* for implementors.)
If you don't have &amp;-groups, detecting non-determinism (I think that's a much
less confusing term than ambiguity) is pretty trivial. In fact it you use
one obvious algorithm for checking instances, non-determinism checking can
be done in, I would guess, less than 10 lines of code. The obvious
algorithm I have in mind is a simplification of Algorithm 3.5 in the Dragon
Book (p140 in my copy), which is the algorithm for constructing a DFA from a
regexp. The simplification is that instead of the complicated final step
where you do the subset construction, you simply read off the DFA directly
from the followpos() sets. While you're doing that, all you have to do to
check non-determinism is to check each followpos set to see if it includes
two distinct positions labeled with the same symbol (ie generic identifier).
James
That is _exactly_ what we have to fix in XML.
XML must be amenable to bison and yacc, or similar tools.
(in practice you'd have to use flex or otherwise avoid lex, I suspect,
because of character set issues -- most implementations of lex are
not fully 8-bit clean, in that they swallow NUL)
The perl hacker's voice is loud.
If &amp; prevents that, drop &amp;.
If OMITTAG prevents that, drop OMITTAG (done already).
Lee
This is OK. But it still fails a few crucial tests for me. I've never
seen a beginning DTD designer fail to create an ambiguous content model in
their first 2 projects. And it takes some time to understand why this is an
error, since everyone know the rules for regexps and thus that it _need
not_ be an error.
I am actually more symathetic to &amp; groups than ambiguity because one is
a pain (in several parts of the anatomy, including the neck), and the other
is useful. So I'd rather XML admitted ambiguous models and broke SGML
parsers (a minority of the users will have those, if we're successful),
than retained an odd syntactic restriction that breaks users (and drives
them away).
What is the justification for unambiguity, independent of SGML
compatibility? I don't see a very good one. That is the kind of
justification we will have to offer the world at large, and be evaluated
on. Asking that question of XML features pretty much determines my
positions on a number of these seemingly minor issues.
-- David
RE delenda est.
I am not a number. I am an undefined character.
David Durand dgd@cs.bu.edu \ david@dynamicDiagrams.com
Boston University Computer Science \ Sr. Analyst
--------------------------------------------\ http://dynamicDiagrams.com/
MAPA: mapping for the WWW \__________________________
