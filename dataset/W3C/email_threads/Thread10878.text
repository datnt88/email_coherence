3) A dichotomy between "DTD-ful" and DTD-less parsing will make any
sibling-based relationship difficult at best; this will affect some
TEI or HyQ based hyperlinks, as well as sibling-based stylistic
decisions.
However, it will _not_ cause a problem for a large class of
applications; namely those in which extraneous whitespace
is irrelevant (full-text indexers, web-walkers, etc.) or
is dealt with separately by the application (CSS-based
formatters, any formatter based on TeX or TeX-like algorithms,
etc.)
Extraneous whitespace _can_ cause a problem for DSSSL-based formatters,
but I don't think that's a big problem either (please see below).
4) The only way to avoid the dichotomy is to preserve these whitespace
nodes even when a DTD is present.
That's one way to avoid it, but it's not the _only_ way.
I propose the following:
* If the author fails to provide a formal document type
definition, then all whitespace is assumed to be significant
(as per (1), above).
* If the author does provide a formal document type definition,
then applications must examine the DTD to determine where
whitespace is significant.
I think this will work. A large class of applications simply
_do not care_ about the distinction between element and mixed
content: they will produce the same results in either case.
Applications in that class do not need to examine the DTD.
I see this issue raising a distinction not unlike the issue addressed by the
'Required Markep Declaration' already provided for in the spec.
Where the RMD says what is required to parse this document properly (or at
all), we are now talking about what is required to properly parse
white-space. I don't really like the -xml-space attribute, it does a
reasonable job os the simple cases. (It still is a bit rough though, as
this whole discussion has pointed out.) When a document (or it's DTD) is
too complex for this simple tool to handle it, the document should just be
able to demand that the DTD be processed in order for white space to be
parsed properly. A DSSSL display engine would tell it's XML parser that it
cares about white space, and the XML parser might thus be required to
retrieve the DTD when it might not otherwise have needed it. Similarly, a
server which servers complex XML documents, might normalize the documents
such that white space processing was not neccessary (assuming it has access
to the DTD).
Somewhere, someone has to take into account white-space/RE handling. The
indication is that the user can not always be expect to take on this burden,
so someone else must carry it, in those cases where is significant.
Applications that do care about the distinction will need
to examine the DTD. I do not see this as an onerous burden
for any of the applications in this class that have been
mentioned so far: all the ones listed so far will need to
examine the DTD anyway (in order to process general entity
declarations), and compared to the effort involved in (say)
writing a DSSSL-O engine, parsing content models to see if
they contain a #PCDATA token is just not that difficult.
This assumes that the issue with DTD's is the complexity of parsing and
processing the DTD. If the issue is the bandwidth required for passing the
DTD, then these arguements do not hold. Unfortunately, I have encoundered
many documents where the DTD is an order of magnitude larger than the
instance. (Whether this is bad design on the part of SGML or the document
architect is irrelevant. I still believe it may be common)
I am concerned that a document parsed as XML (as opposed to SGML) will
require different HyTime location addressing, or a different DSSSL style
sheet, than if the same document was parsed as SGML. Such a situation
defeats a number of the goals of XML, mainly it's SGML compatibility.
-derek
"that which is not slightly distorted lacks sensible appeal: from which it
follows
that irregularity - that is to say, the unexpected, surprise, and astonishment,
are an essential part and characteristic of beauty" - Charles Baudelaire
But a "complex" document in this case is any document with whitespace in
element content. Which is to say, probably most:
So if we go with a scheme of "required DTD downloading to handle 'complex'
whitespace", either XML will get a "rep" as a hard to use language where you
must type this:
or as a language where you must basically always download the DTD.
Paul Prescod
Is this a valid summary of your proposal:
The spec should require the application to read the DTD for proper
whitespace handling of element content. Many applications do not care about
proper whitespace handling and can thus skip the DTD.
Paul Prescod
Surely it should be the other way round: many applications do not
care about the DTD and can thus skip proper whitespace handling.
///Peter
Taking into account such rules as ignoring RE's immediately following start
tags or immediately preceeding end tags (some people seem to think this is
in the spec, I didn't look very hard, but didn't see it right off... but
something like that should be there), your summary is exactly what I mean.
Whether a stylesheet is sensitive to extra whitespace/RE's is dependant on
the style sheet, but there are a number of HyTime location addressing
mechanisms which WILL break if pseudo-elements show up where they were not
there before (or disappear for that matter). It has been mentions that some
TEI locators will also break.
I have no real problem with keeping the -xml-space attribute also. I just
require that the parse tree for DTDless and DTDful parsing be the same,
which is what I believe David Durand meant when he said he required that the
"parse trees be the same."
-derek
(amused that somehow in the middle of a discussion on RE handling, hyper
linking rears it ugly head, esp. given that hyper linking etc. is what we
are scheduled to be discussing...)
"that which is not slightly distorted lacks sensible appeal: from which it
follows
that irregularity - that is to say, the unexpected, surprise, and astonishment,
are an essential part and characteristic of beauty" - Charles Baudelaire
In one of my versions of what I posted (I rewrote portions of it a number of
times as my ideas solidified), and may not have made it off my computer, I
mention that there should be some simple rules to allow from some
whitespace/RE's to be ignored. i.e. ignoring RE's after a start tag, or the
-xml-space attribute. I agree that we can not expect to treat all RE's as
data. I am just worried that the proposals being brought forth will break
HyTime when applied to XML. Given that I was actively involved with
drafting the forthcoming HyTime TC, it is important to me that HyTime is not
completely abandoned, when it need not be.
(Not that I am wed to HyTime. It has it's flaws by the cartload, but It
does do a number of things quite well, and I am hoping that the TC and
eliot's book will bear that out....)
-derek
"that which is not slightly distorted lacks sensible appeal: from which it
follows
that irregularity - that is to say, the unexpected, surprise, and astonishment,
are an essential part and characteristic of beauty" - Charles Baudelaire
Yes.
I don't follow this line of reasoning...
Applications only care about the DTD if they need information
in it that is not available from the instance alone. Under my [*]
proposal, the distinction between element content and mixed content
would be one such piece of information. This is, after all,
how it works in the base language SGML.
[*] I believe that Derek Denny-Brown is proposing the same thing.
Note that in XML there already is information in the DTD
that is not available from the instance (the replacement text
of non-predefined entities -- which DSSSL and HyTime engines
will need, so we're not asking them to do a whole lot more work),
and I'm willing to bet that before we've finished with hyperlinking [**]
there will be even more information in this category (e.g.,
#FIXED attributes and/or architectural declarations).
[**] Speaking of hyperlinking, does anyone have any ideas how
this should be specified? We probably ought to start thinking
about this...
--Joe English
jenglish@crl.com
From: "W. Eliot Kimber" eliot@isogen.com
There are two levels of abstraction that we usually work with:
1. The immediate result of parsing.
2. The result of applying application-specific semantics to the
results of parsing.
Abstraction (1) is what HyTime and DSSSL call the "SGML document grove" or
the "pGrove" (for parse grove). What can occur in this grove is completely
defined by the SGML property set (published in the DSSSL standard and soon
to be published again in the HyTime TC) and reflects simply applying the
SGML parsing rules to the input document. It is roughly equivalent to
"ESIS" except that the grove may be more complete and you have a formal way
to say what you want to be in the grove (the "grove plan").
Abstraction (2) is what HyTime calls the "extended SGML document grove", or
"epGrove". This is a new grove with HyTime-specific semantics applied. It
uses the same propery set as the first but may either suppress or remove
some things or may modify the content to reflect HyTime-specific semantics.
Any application is free to create it's own extended document grove. XML
processors will, presumably, provide their own XML-specific extended
document groves to reflect XML-specific semantics (for example, that
whitespace is collapsed when the -xml-space attribute is in effect).
Any location addressing applied against XML documents would, presumably, be
applied against the XML epGrove (or possibly a location-method-specific
grove derived from the epGrove), not against the pGrove.
In terms of Eliot's enlightening discussion, I would state my feelings
as follows: I would like to define well-formed XML so that the pGrove
for any well-formed XML is equivalent to the epGrove against which we
apply our location addressing. I'd like to avoid introducing an
application-specific epGrove in between well-formed XML and addressing
into that well-formed XML document.
I don't think it's a HyTime-specific issue, both because the problems are
not unique to HyTime and because the use of HyTime is not dependent on how
the parsing process is defined.
All location addressing, whether HyTime-defined or not, operates on an
abstraction of the data, not the original source data. This means that you
have to choose your abstraction carefully, which is what we're really
talking about in this whole RS/RE fracas.
There are two levels of abstraction that we usually work with:
1. The immediate result of parsing.
2. The result of applying application-specific semantics to the
results of parsing.
There may be more levels of abstraction, but we haven't exposed those yet
in our discussions of XML processing.
Abstraction (1) is what HyTime and DSSSL call the "SGML document grove" or
the "pGrove" (for parse grove). What can occur in this grove is completely
defined by the SGML property set (published in the DSSSL standard and soon
to be published again in the HyTime TC) and reflects simply applying the
SGML parsing rules to the input document. It is roughly equivalent to
"ESIS" except that the grove may be more complete and you have a formal way
to say what you want to be in the grove (the "grove plan").
Abstraction (2) is what HyTime calls the "extended SGML document grove", or
"epGrove". This is a new grove with HyTime-specific semantics applied. It
uses the same propery set as the first but may either suppress or remove
some things or may modify the content to reflect HyTime-specific semantics.
Any application is free to create it's own extended document grove. XML
processors will, presumably, provide their own XML-specific extended
document groves to reflect XML-specific semantics (for example, that
whitespace is collapsed when the -xml-space attribute is in effect).
The -xml-space attribute is a good example of how this works in practice:
an XML parser parses a document and creates a pGrove that contains all the
data characters it found. If the document has no DTD, then this means all
white space characters, not just those in what we know to be mixed content
(white space that is not taken as data is held in "markup" properties,
which are not, by definition of the SGML property set, content of the
objects that exhibit them--thus these characters may be in the grove but
they aren't part of the content of the elements in which they occur).
An XML processor then operates on the pGrove to produce an XML epGrove in
which the rules for -xml-space are applied, i.e., lists of white space
character nodes in the content of elements where white space gets collapsed
get replaced with single space character nodes. (Notice I didn't say
"characters get replaced", the operations are on nodes in groves, not
characters in strings, and each character is a node.)
Any location addressing applied against XML documents would, presumably, be
applied against the XML epGrove (or possibly a location-method-specific
grove derived from the epGrove), not against the pGrove.
Of course, the problem of knowing how to produce the XML epGrove
consistently remains. However, having these two stages can make it clearer
where the processing can happen and *why* using attributes to control it is
not necessarily a hack because the attributes are *not* feeding back into
the base parsing process (at least conceptually)--they are affecting the
construction of application-specific groves and applications are free to
use any information at their disposal to control grove construction.
Note also that grove plans are not sufficient to solve this problem because
grove plans only include or exclude entire classes of object or entire
property values--they can't selectively exclude things: that requires a
specific grove construction process.
Note that there's absolutely no requirement that applications actually
perform the grove constructions described above as discrete steps--most XML
processors will go directly from source data to XML epGrove without first
constructing the intermediate pGrove.
But note also that HyTime (and DSSSL) can operate with equal ease on either
grove and it could be possible to have both available and indicate which
you actually want to address when doing addressing. (Whether this is
practically useful or not, I wouldn't want to speculate at this point.)
Finally, I'd like to point out that from a HyTime perspective (in the new
grove-based world) any addressing notation that can be defined in terms of
node lists selected from groves can be naturally integrated into a
HyTime-based system. For example, TEI locators, whose grove-based results
should be obvious given knowedge of the grove plan used, could be easily,
meaningfully, and usefully used in conjunction with other HyTime-defined
location addresses.
Thus, it's not really useful to talk about "HyTime addressing" versus other
forms of address: it's all the same stuff at its core and the problems
posed by the data abstractions we're creating are the same. Thus the issue
of, for example, whether we should prefer TEI locators over SDQL queries is
an issue of appropriate syntax and user interface, not functionality [for
what it's worth, I will probably end up prefering TEI locators over SDQL
for XML use because it was specifically designed to meet the requirements
we presume the main XML audience to have].
Cheers,
E.
W. Eliot Kimber (eliot@isogen.com)
Senior SGML Consulting Engineer, Highland Consulting
2200 North Lamar Street, Suite 230, Dallas, Texas 75202
"Rats in the morning, rats in the afternoon...if they don't go away, I'll be
re-educated soon..." --Austin Lounge Lizards, "1984 Blues"
I wonder how HyTime can break when used with XML when there is no
current practise in the field? Same for DSSSL, or whatever other
processor you have.
Since XML is SGML (theoretically) we do have current practise.
So far, we have been trying like mad to make XML a pure subset of
SGML, to the extent of using hairy features of SGML to get it to
do what we want. To me, this means that unless *all* SGML systems
we care aboput are capable of supporting the features that XML
requires, the issue of whitespace-handling conformance is a non-issue,
as you're going to have to preprocess an XML document to get it
through your SGML system anyway.
SGML systems can be updated. It is better that they be updated to support
optional SGML features than proprietary W3C-XML features.
Why can't you have the preprocessor perform whitespace normalisation as well?
Because SGML has the whitespace handling behaviour that we want (other than
RS/RE). It allows insignificant whitespace in places where it is obvious to
author and parser that they could not be data. It would make no sense for us
to convert from a system that is less text-editor-friendly to a system that
is more. If any conversion is involved it should be downconversion from
SGML, using its reasonable whitespace handling rules (barring RS/RE) to XML
(as was originally envisioned by many participants).
Anyhow, we can all get what we want. If we use a simple syntax for
triggering whitespace removal, then those who think that All Whitespace
Should Be Significant can just choose not to ever use that syntax. Parser
writers still have to implement it, but it would be fairly trivial.
Paul Prescod
I wonder how HyTime can break when used with XML when there is no
current practise in the field? Same for DSSSL, or whatever other
processor you have.
If you can define "SGML", I might agree with you. Fact is, that SGML
is a large number of incompatible languages anyway.
If you can define "SGML", then please look to see if XML is "SGML" as
you define it.
The point is that we are only using SGML features...
Why can't you have the preprocessor perform whitespace normalisation
Really? Even in the face of *all* the tricks one could pull with an
SGML declaration?
[Joe English:]
That discussion begins in the next couple of days. Stay tuned.
Jon
