saying that a DOM heirarchy might take up to 4 times as much memory than
the file it was loaded from, depending on the implementation.
The last phrase is absolutely essential. That "four times" is someone
talking about a particular implementation, and is _not_ a reasonable rule
of thumb. I'd say 1:1 was closer to average for DOMs coded by someone who
knows what they're doing.
The DOM API, per se, only specifies how the data is accessed; it says
_nothing_ about how the data is stored, and implementations are free to
trade off performance, code size, and storage size to suit their users'
needs. A DOM may take more space than the XML file.... or may take less
space... depending on how it was written and the characteristics of the
individual file.
To take one obvious example, a DOM can save a considerable amount of space
by maintaining only a single copy of each unique element or attribute name
string. Since these are repeated many times in a typical mid-to-large-size
document, that can add up to significant savings. There are other, less
obvious, steps that can be taken to reduce storage, though some of them
impose performance costs. Depending on what you're trying to do, that may
or may not be a net win for your application's overall responsiveness.
So if you don't like one DOM implementation's costs, then by all means try
another!
Also see http://www.w3.org/DOM/faq.html#SAXandDOM for a discussion of some
of the tradeoffs. There _are_ some problems which are better approached via
SAX, or via a custom model... or via a custom DOM implementation.
Joe Kesselman / IBM Research
I forgot to add...
Regarding the whitespace text nodes; That's something the DOM doesn't
really have any choice about, since the XML Recommendation explicitly
requires that all whitespace be passed through to the application. Many XML
parsers have a "filtering" mode which allows applications to request that
whitespace-in-element-content be discarded; check yours to see if it has
that option. Note that the parser can only recognize this case if you are
validating against a DTD or schema; if you don't do so, it has no way of
determining which whitespace is and isn't meaningful and must deliver it
all to avoid damaging the document.
DOM Level 3's Load/Save chapter is considering permitting such a filter. I
believe we discussed the possibility of also allowing user-written filters,
so you could plug in logic to discard other unwanted information with or
without a DTD's advice.
Joe Kesselman / IBM Research
I read at some point some reference about the DOM level 1 specification,
saying that a DOM heirarchy might take up to 4 times as much memory than
the file it was loaded from, depending on the implementation. I completelly
agree with that.
I made an implementation for DOM level 2 (without the events part, which
actually is the real breakthrough of DOM 2) and i begin stress-testing it
on a 1.7 MB file containing some 230.000 entries (I just copied and pasted
the contents of the file, almost choking at some point XMLSpy, after i
moved to mighty... Notepad).
Anyway, these entries "eat" about 50 MB of memory which i find pretty
scaring, for a 1.7 MB file. I searhed my code for memory leaks or
over-allocations, but found none.
I tried to compute the size i was expecting from DOM to get, and got very
surprised as i saw a HUGE number of TEXT nodes (about 55.000), barely
containing TAB characters and "/r" characters.
I know that the DOM MUST reflect the structure of the document, but these
nodes are a pain in the lower layer and eat up huge amounts of memory.
While it might sound stupid to IMPOSE the "pretty-printing" formatting on
the developers of the DOM, at least some things could be done to reduce the
amount of these formatting text fields in the DOM.
The normalization method from NODE concatenates adjacent text nodes, but
it's not the matter here.
I'm looking forward for an answer, observations or whatever you have to say
about this.
Thank you!
Razvan Costea-Barlutiu
Department of Radiology,
The University of Chicago
5841 South Maryland Avenue
Chicago, Illinois 60637
E-Mail: cbrazvan@baltan.bsd.uchicago.edu
Any chance that you can put this 1.7MB file somewhere online (better -
zip'ed) so we can test with different browsers?
Konqueror (www.konqueror.org) has very good DOM-, CSS2- based "KHTML" engine,
and I can't say I have ever seen such (50mb) memory usage with it. ( I tested
it on a 1.8MB bug archive file from bugs.kde.org, everything was fine)
But of course it can vary depending on file structure.
Anyway, I am ready to test with Konqi your file, and tell you what exactly
memory usage was.
Vadim Plessky
33 Window Decorations and 6 Widget Styles for KDE
Do you have Arial font installed? Just test it!
Vadim--
As a result of the replies i got from the DOM involved people on the
mailing list i figured that the problem is in my implementation.
As Joseph Kesselman pointed out, there are a lot of elements that can be
simply replicated by pointers where duplicates are found.
This is the clear example of a database replication on an XML file, where
the DB structure can be defined in a XSL file or in a DTD and the DOM
implementation can use that information to build the tree.
My DOM implementation (which is at its VERY early stages) simply built
nodes again and again, regardless of the number of occurences of elements
or attribtes, therefore consuming large amount of memory.
I won't post the file because it is a trivial copy+paste created file, for
stress-testing only, considering the size of the file. I generated the file
with XMLSpy from the sample database that you can find in MSAccess. After
that, i just Copied and pasted its contents growing exponentially the size
of the file. The number of elements reached about 230.000.
So, it's a trivial example.
--Razvan
Razvan Costea-Barlutiu
Department of Radiology,
The University of Chicago
5841 South Maryland Avenue
Chicago, Illinois 60637
E-Mail: cbrazvan@baltan.bsd.uchicago.edu
Ok, I see.
May I ask you to try this file/link:
(it's exactly what I have on disk, but from Jan.5th, 2001; so current version
may vary)
As I do not meet every day new people doing own (new) DOM implementation, I
am very interested in work you done :-)
So, what will be memory usage/speed of your DOM implementation for URL above?
BTW: if you are interested in different DOM implementation(s), I highly
recommend to take a look on KHTML. It's Object-Oriented, C++-based. Works
pretty fast.
Vadim Plessky
33 Window Decorations and 6 Widget Styles for KDE
Do you have Arial font installed? Just test it!
Somebody have already implied that this is independent of the DOM
specification,
and to me this seems rather like a problem with the import implementation.
If the mechanism for importing an XML file into the proprieteray internal
structure
is using SAX, (which seems to be a good and widespread practice) then this
can be customized
by the application programmer in the sense that he writes his own XMLReader
for
XML text-files. (To make it simple the application programmer should perhaps
use an
existing xml parser)
This is of course more work for the application programmer....
But there's always a balance between usage of human resources and
OS-resources... :-)
Jan-Arve S?ther, System Developer
Birdstep Technology ASA
