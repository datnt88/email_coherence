Josh Cohen josh@netscape.com Netscape Communications Corp.
"You can land on the sun, but only at night"
Greetings,
I apologize for the lateness in posting this to the list.
If you view the open issues for HTTP/1.1 and the agenda for the Munich
meeting, you'll notice an issue called 'RE-VERSION'. After discussion
with the HTTP editors, I was encouraged to raise this issue on the list
and as an open item for HTTP.
The RE-VERSION essentiall boils down to the meaning of the
version in an HTTP/1.1 response.
I, and the editors, understand that this issue was heatedly and
deeply discussed previously, however, over the course of time,
I do not beleive that the previous resolution is sufficient.
To summarize, the draft now indicates that the response version
should be the highest version supported by the server, NOT
the version of the actual HTTP response.
My problem with this is based on the assumption in the draft
which dictates that the response version is hop-by-hop.
Overall, I beleive that the response version should indicate
the version of the response message.
The problems encountered so far, in addition to any confusion
because the 'response version', isnt the response version,
are as follows:
A client sends a 1.0 request, a 1.1 server responds with
a 1.1 response. ( minus certain http/1.1 features/headers).
GET http://foo/foo.html HTTP/1.0
blah: blahvalue
HTTP/1.1 200 Ok
blah: blahvalue
content...
When going through a proxy, how is the proxy supposed to maintain
the hop-by-hop nature of the responses?
Worse, if a 1.0 proxy is in the stream, it will blindly pass
the 1.1 response code back to the client, and clearly fails
to honor the hop-by-hop nature of the response.
(this is the case with squid, netscape proxy, and presumable others)
Previously, the 1.0 didnt clearly define what the behaviour
should be in this case.
On deciding what to send in a 1.1 response to a 1.0 client,
there is no canonical list of things which a
server must not send when sending a 1.1 labeled response
to a 1.0 server. There will surely be more than just
chunked encoding.. This seems like a nightmare for
proxy/server implementors dictating constant maintenance
releases to block new server reponse features/headers
from being sent to 1.0 clients.
( how can it be prepared to block something which hasn't
been invented yet?)
The only reason I could find in the previous discussion
for this behavior was to allow partial implementations
to take advantage of some 1.1 features, but not all.
These days, since a great deal of the most contentious
features have been separated from the core http/1.1 draft,
I dont think its too much to ask for a reasonably
compliant implementation that can at least deal with
all the core http/1.1 headers/features.
Lets say Im implement a client that understands
cache-control ( IMHO a valuable 1.1 feature ),
but is 1.0 otherwise. Should a server send
a cache-control: directive or the usual ugliness
of removing the last-modified: header? (or some other way).
Or should it send both? (subverting the usefulness
of the cache-control making it redundant)
Finally, with things the way they are, does the response
version actually mean anything useful? How useful is knowing
what the highest version supported by the server?
Wouldnt knowing the version of the actual response message
be more useful and less ambiguous?
The way I see it we have these options:
1) leave as-is, keeping the broken hop-by-hop behaviour
( but vigorously specify what must not be sent to a
1.0 client in a 1.1 labeled response )
2) make the response version = the request version.
3) create an additional 'response-version: ' header
to indicate the message version in use.
4) keep the same rules in the draft, but make our version
2.0. ( which will mean that the server must send a 1.x
response to a 1.x client )
Personally, I think the right thing to do is #2.
Yes, this will have some effect on the current implementations.
However:
1) the effect shouldnt put them in any worse position than they
already are. ( still broken )
2) The IETF process draft/draft standard rfc/proposed standard rfc etc,
is meant to allow changes. Implementing a draft implies that changes
will need to be made.
(Im sure Im missing some issues or other stuff.. feel free to comment :)
Josh's #2 prefered choice matches my position ... I wouldn't mind if
a header were added to label the characteristics of the origin server.
Only required if the response level is less than the server's
ability. Possibly not terribly useful.
Dave Morris
I agree completely. It always made more sense for the version number
to reflect the response rather than the capabilities of the server.
During the "contentious" discussion two arguments were made for
sending the highest version of which the server is capable. Neither
made much sense to me: 1) This is the way it was planned when HTTP/1.0
was created; and 2) An HTTP/1.1 client might choose to lie and say it
is 1.0 if it thinks it is talking to a 1.0 server and then if the
server is really 1.1 the client will never know unless the server
returns the highest version of which it is capable.
Actually, I think the original intent was that a 1.0 client should be
able to read a 1.1 response and function properly by ignoring anything
it didn't understand. Of course, chunking makes this fail spectacularly.
As a final observation I would point out that a single program can
be a server for multiple protocols. (In fact a few years ago I
wrote a combination gopher/http server.) Thus a single program could
be both an HTTP/1.0 and an HTTP/1.1 server each part complying with
the relevant specification. Which "virtual protocol" is used would
depend on the request version header. This seems to me to be completely
compatible with both HTTP/1.0 and HTTP/1.1 specs and functionally
equivalent to Josh's #2 choice (i.e version number represents response
version).
John Franks Dept of Math. Northwestern University
john@math.nwu.edu
My previous response to this thread may have been a little too
flip. There is a serious issue here which has been discussed
before but maybe not really resolved. It deserves our attention.
There are two distinct pieces of information that might be
communicated by a version header. First there is the SENDER VERSION
(SV) which is the highest version the sender is capable of supporting.
Second there is the ENTITY VERSION (EV) which is the lowest version
for which a receiver supporting only that version can still
successfully receive the entity. Of course EV = SV.
With the current spec the version header is hop-by-hop so the receiver
of a transaction can compute EV = min { SV(sender), SV(receiver)}.
This complicates life for proxies, though. It means that a 1.m proxy
must be capable of translating an entity with EV == 1.m to an entity
with EV == 1.n for all n = m. This is because hop-by-hop implies a
1.m proxy talking to a 1.m server can only ask for a response with
EV == 1.m, even though it may acting on behalf of a 1.n client with
n  m.
This seems to put a heavy burden on proxies. The current spec precudes
the possibility of a proxy pushing this burden onto the server where
it would be easier to deal with (in general it will be easier to
*generate* an entity with EV == 1.n for all n = m than it is to
*translate* an entity from EV == 1.k to EV == 1.j for all j = k = m).
Of course, at present we only have versions 1.0 and 1.1 so the proxy
need only be able to translate an entity with EV == 1.1 to one with EV
== 1.0. This requires removing any chunking, but Josh Cohen asks if
it requires anything else. I don't know. We need to understand and
document exactly what is required for this translation.
A concern that I have is that, if the version header is hop-by-hop and
must contain SV, then we have precluded a proxy design that would
allow a proxy to request a lower EV than its SV. There are many
reasons a proxy might want to do this including separate caching of
versions with different EV's instead of translating.
This discussion is relevant even for HTTP/1.1. A 1.1 proxy between a
1.0 client and a 1.1 server will always have to unchunk the server's
response even if it is uncacheable and just being passed through.
There is no real reason for requiring the proxy to accept this burden
and refusing to let it request an unchunked version from the server if
it knows it needs one.
It seems to me that one way to remedy this is to somehow communicate
(up to) three version numbers: The SV of the sender, the EV of the
current transaction, and, for requests, an RV or Requested Version to
be used in the response. It would also be reasonable so say that
the EV of a request is the requested version for the response and
that would simplify things somewhat.
John Franks Dept of Math. Northwestern University
john@math.nwu.edu
It was resolved, twice. I consider it closed.
Yes, that is the cost of progress. In order to take advantage of more
advanced protocol features, a proxy must make up for its weaker clients.
There is no way around it. In fact, that should be considered a valuable
feature by anyone who purchases a proxy.
That would be stupid. If a proxy has no use for the advanced features,
then why has it implemented them? For example, the chunked encoding
allows for more reliable transfer of dynamic content, particularly
when the content is cachable. You are suggesting that a 1.1 proxy
should disable that capability just because the client of the current
request is 1.0, even though the benefits received from chunked content
apply to all future requests as well.
In general, there is no requirement that a client (including a proxy)
send a 1.1 request instead of 1.0. There can't be, since then the
client would be using the 1.0 protocol and not HTTP/1.1. Thus, the
concern you mention is unfounded.
Done that -- it took me ten minutes (not counting the two years arguing
about RFC 2068).
....Roy
Roy,
The version number design which you have promulgated since 1993 gets
rehashed every six months because:
1) It is counterintuitive to the point of being confusing,
2) It is flawed,
3) It greatly complicates some kinds of proxy design, and
4) It has no discernible function.
We can probably live with these problems, but one price we will pay
is that this aspect of the protocol will get rehashed at least every
six months as new people wrestle with what ought to be a trivial part
of the protocol.
But later you say the opposite:
It is specious to say that a 1.1 proxy can send a 1.0 version number
because then it becomes a 1.0 proxy. What is really happening is that
the proxy is lying in its version header because that is the only way
it can request the response it wants from the server. This is one
example of a flaw in the version header design: a proxy may sometimes
need to lie about its capabilities in order to get the response it
wants.
The reason that the version header comes up again and again is not
that difficult to understand. What implementors NEED to know in
processing a transaction is the *version of that entity*, i.e. the
lowest version number such that a client or proxy of that version can
handle this entity. The current version header gives only an upper
bound estimate for this number. It is a non-trivial (and potentially
error-prone) task to calculate this entity version. If versions 1.x
with x  1 come into being this problem will get harder.
Apparently the original design intent was that the major version
number would be the "entity version" and the minor number would
indicate capability. This is manifestly no longer the case.
There is substantial evidence that new implementors *expect* the
version header of a response to contain the entity version (which they
need and which the origin server knows) rather than a statement of
capability. When they discover this is not the case (either by
reading the spec or when something breaks) they are annoyed by the
extra work, seemingly gratuitously created for them, and they come
here to complain. This is unlikely to change anytime soon.
I do not believe that statements like "this is the cost of progress"
or "this is the way we have done it since 1993" are responsive. The
fact that the archive is full of such statements does not constitute
a resolution of the issue.
On the other hand RFC 2145 by Mogul et al. was a big step forward, in
that it at least specified precisely what the current spec says.
The bottom line, though, is that there are three pieces of version
information related to an HTTP transaction: 1) the capability version
of the sender, 2) the entity version of the transaction, and, for
requests, 3) the requested version of the response. We have specified
that the capability version goes in the header, but it is actually the
other two which are required for interoperability. Often, but not
always, some of the numbers coincide. Often, but not always, it is
possible to derive all three numbers from the collection of all
headers. However, even when this is possible, there is no simple
algorithm for doing so. Even RFC 2145 suggests that in certain,
(perhaps exceptional) circumstances clients and servers can lie about
their capabilities and send an incorrect version header. Though it is
not explained, the purpose is presumably to correctly communicate the
entity or request version when the correspondent will otherwise compute
them incorrectly.
The current specification is workable, but problematic. All the
issues mentioned above have, indeed, been raised before and are in
the archives. Emphatically denying their existence may temporarily
silence the topic on the mailing list, but doesn't help implementors.
The fact that the issue gets rehashed every six months might be taken
as prima facie evidence that the design could be improved.
John Franks Dept of Math. Northwestern University
john@math.nwu.edu
You seem to have figured it out. You just don't agree with it.
No it isn't.
No it doesn't.
Bullshit.
The versioning semantics are central to the design of HTTP to support
future standard extensions to the protocol, including the extensions
from HTTP/1.0 to HTTP/1.1. It is this design that allows us to introduce
things like transfer encoding, 1xx responses, and PEP/Mandatory header
fields. The HTTP-version is the only field which is required NOT to be
forwarded blindly by any HTTP proxy, regardless of version. ALL of those
rules I listed yesterday depend on the minor protocol version indicating
the *capability* of the sender. Without these versioning semantics, the
entire HTTP design collapses and we will never be able to improve HTTP,
not even with a major version change, except via an external indicator
on the URL scheme or DNS to indicate a new protocol can be used.
The fact that some people seem incapable of understanding that should
not require the WG to endlessly cycle through the same discussion.
The fact that some people think all version numbers have the same purpose
is not an excuse to dismantle a working design. The fact that some
implementers choose not to read the specifications before attempting
to write an implementation does not justify changing the specification
to correspond to their bugs which will clearly never be able to
interoperate with future versions of the protocol.
How you can think that those two statements oppose one another is beyond
my understanding. The only difference between an HTTP/1.0 proxy and an
HTTP/1.1 proxy is that the latter declares its conformance with the 1.1
specification. Every feature of HTTP/1.1 is also an HTTP/1.0 feature.
Every header field defined in the HTTP/1.1 specification is also an
HTTP/1.0 header field. And yes, that also applies to Transfer-Encoding
(try it and see for yourself). Whereas an HTTP/1.1 server is required
not to send a Transfer-Encoding to an HTTP/1.0 client, an HTTP/1.0
server can do so at will. Granted, it would be stupid, but it wouldn't
make it any less stupid by adding an "entity version" to the message.
An HTTP entity is completely described by the entity-header fields that
are included with the entity. *Any* change to the protocol that requires
understanding of a particular aspect of the entity, which is not defined
by an existing version of the protocol, will also require incrementing
the minor protocol version. Adding an "entity version" would be no more
revealing to the recipient than allowing a mandatory header field to be
passed on to an old client.
What flaw? The proxy is lying because it doesn't want the capabilities
required of an HTTP/1.1 proxy. If it had those capabilities, it wouldn't
need to lie, nor is there any reason for a fully-capable proxy to lie.
As I explained before, those requirements exist for the *benefit* of
proxies.
You must be talking about some other protocol, since none of those
statements are true about HTTP/1.1.
The major version number indicates the message format, which is the
case and has always been the case. Look at an HTTP/1.1 message (any
valid message) and point out the part which is not valid HTTP/1.0
other than the HTTP-version field.
So, what you are telling me is that we should stop all work on improving
HTTP because some implementers are untrained savages, apparently reared
by animals in a jungle, and unable to read the English language presented
quite clearly in three separate RFCs. Personally, I think implementers
who don't think they already know more about the protocol than the
protocol's designers will have the sense to actually read what has been
written on the subject and implement accordingly. If they do so, I can
guarantee they will interoperate with other compliant implementations.
If they don't, there will be no interoperability, and thus no reason to
have a standard or waste time discussing it in this WG.
...Roy T. Fielding
Department of Information &amp; Computer Science (fielding@ics.uci.edu)
One concrete example:
A 1.1 proxy cannot request an unchunked
response from a 1.1 server without violating RFC 2145. So far I
have seen two responses to this, 1) It's a feature not a bug, and
2) Become a 1.0 proxy and send a 1.0 request.
Neither of these is a reasonable answer. There are many valid reasons
a 1.1 server might sometimes want a 1.0 response (e.g. to reduce
de-chunking overhead if the response is only going to be passed to a
1.0 client). Answer 2) is a clear violation of RFC 2145. The current
spec is flawed because an implementor is required either to forgo some
proxy funcitionality or to lie and violate RFC 2145.
This problem will be exacerbated as we add additional transfer encodings
and move to versions 1.x, with x  1.
Can you back this statement up? Suppose the semantics were that the
request version header indicated the desired response version
(usually, but not always the highest version the requestor is capable
of) and the response version header indicated the version of the
response (usually the minimum of the request version and the
responder's capability). Can you give some concrete examples of
how "the entire HTTP design collapses" with this semantics?
John Franks Dept of Math. Northwestern University
john@math.nwu.edu
That is true, and it's also on purpose. In order to reliably transfer
data, it is necessary to know the actual length of the data being
transferred (data error detection is handled at the transport layer).
Failure to supply a length may result in prematurely truncated responses
being misinterpreted as full responses, which was (and still is) a
significant problem with HTTP/1.0. The minimum change necessary to
enable sending dynamically-generated data in efficient, length-delimited
chunks was to require that all HTTP/1.1 applications be prepared to
receive chunked messages; a server may respond with a Length Required
error (to prevent yet another form of denial of service attack).
In other words, it is not an optional feature of the protocol. Either
the proxy is willing to accept chunked or it is not an HTTP/1.1 proxy.
I have yet to hear an actual proxy implementer claim that it is an
unreasonable burden.
....Roy
