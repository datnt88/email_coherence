NB: I use the abbreviation DTD here to mean a formal declaration of a document's syntax, which may be by a DOCTYPE declaration (as in HTML 4.0), by the use of XML namespaces, or by some other technique. 
The four important ideas we want in section 2.4 are: 1. 
Any accessiblity features must be kept in the document 2. The document should be syntactically valid 3. The author (or previous author) may know more than the tool about accessibility, or conversely the author may not know anything about accessibility We would also like clean markup, but I am not sure that there is a particular accessibility requirement for this (given that we require structure to be navigable, bad markup is bad markup generally) Idea 1 is (in my reading) covered in 2.2 - use applicable accessibility features. 
We should add some technique stuff. 
Idea 2 belongs in 2.1 - make valid documents. 
We should have a checkpoint which says that explicitly. 
Idea 3 is a bit more complex. 
If the author can write a more accessible markup scheme they should do so, and include reference to it in the document so a tool can check against it. 
At one point we had a proposal to require some published document type to be used, which would need to be reinstated to make this work. 
Where a document received is invalid, we have a difficult problem. 
The tool can flag a validity error. 
If it is known that the document type has been superseded, it can attempt to validate the document against the newer syntax. 
In the case where it cannot find a way to validate the document, then it can either force validation, by removing whatever "should not be there", it can produce a document which has no declared type, since it cannot be validated, it can produce a document which incorrectly claims conformance, or it can create a document type on the fly to which the document conforms. 
The first of these should never be done without asking the author. 
That is a requirement under the checkpoints of 2.5 as they stand. 
The risk of forcing compliance is that extra accessibility enhancements will be lost. 
I think this only applies to HTML - in XML the rule is that if an element should not be there then it and its content are ignored. 
This allows the reqiurements of 1 and 2 to be satisfied. 
In the case where the author knows a lot about designing accessibly, we would expect a tool to allow them to create their own DTD. 
In a case where an accessibility 
problem could be identified, checkpoints under guideline 2.6 would come into play. 
Even in the case of a DTD there are machine-checkable things, 
and there is a lot that can be said on how to write a DTD which promotes accessibility - allowing (or requiring) the inclusion of alternative content, the seperation of presentation from content and structure, and supporting device-independence are the basic requirements which can be expressed at any depth between bullet points and an encyclopedia. 
This would be required of such a tool under the current section 2.7 In the case where the author knows nothing about accessibility, checkpoint 2.6.3 and guideline 2.7 come into play. 
So I propose that we: add a checkpoint to 2.1: Documents should be valid according to a published machine readable (on the web) syntax. 
[priority 2] Techniques: check that the syntax of the document is legal according to the specified syntax. 
If there is a known updated version (e.g. HTML, which is periodically revised) try to validate against the newer version. 
Where a document does not validate, no document type should be claimed for it. 
add a checkpoint: allow the user to override any structural changes [priotrity 1] This includes, but is not limited to changes in the markup and in the document type declarations to replace the checkpoints currently in section 2.5 Charles McCN 
If the "DTD registry" idea is given adequate notoriety by and within W3C I think these ideas validate. 
The notion that there might become a centralized location which browsers could check to see what syntax needed observance, etc. is very powerful IMHO - emphasis on the "H" because I wouldn't have a clue how to go about ensuring that any "approved" DTD furthered accessibility - but it smells right. 
Love. 
ACCESSIBILITY IS RIGHT - NOT PRIVILEGE 
I think the w3c approach is moving to the use of namespaces in XML, which will allow the combination of the bits you need for a given document, with the mechanics available on the web. 
This is getting a push by W3C in a lot of what it is doing. 
Ensuring accessibility in XML namespaces is a whole different can of worms. 
The reason behind using applicable W3C specifications is that these have already been filtered through WAI, and in theory are as accessible as they can be. 
Beyond that it is outside the scope of the working group, although where possible our techniques material should include references to work being done. 
Charles If the "DTD registry" idea is given adequate notoriety by and within W3C I think these ideas validate. 
The notion that there might become a centralized location which browsers could check to see what syntax needed observance, etc. is very powerful IMHO - emphasis on the "H" because I wouldn't have a clue how to go about ensuring that any "approved" DTD furthered accessibility - but it smells right. 
Love. ACCESSIBILITY IS RIGHT - NOT PRIVILEGE 
--Charles McCathieNevile mailto:charles@w3.org 
W3C Web Accessibility Initiative http://www.w3.org/WAI MIT/LCS - 545 Technology sq., Cambridge MA, 02139, USA 
In an attempt to get a handle on 2.5 I tried to restate the problem again. 
It basically boils down to wanting to: Prevent the removal of structure and content that adds accessibility but may be part of older or newer markup that is not supported by the tool, without preventing the tool from cleaning up the markup (which often helps with access). 
The dilemma is if the tool does not recognize the targeted elements how can it distinguish between elements that help access and elements that hinder access. 
Given the range of authors, it is highly unlikely that the average author can handle the decision making. 
If mechanisms and conditions exist that allow the tool to update and seek out information about the unknown markup over the web, thats great but we cannot depend upon that. 
Perhaps we need to become more specific without dating the guideline. 
Can we establish in W3 some registry of elements that are necessary for access in both older and newer markup languages and reference this in this guideline? 
Jutta 
I apologize if this has been discussed already or is not pertinent to this discussion - I may be way out of scope for these guidelines. 
However, I am curious how server-side scripting directives or other types of 
place-holding elements that are not defined anywhere fit into the picture? 
For example, the WAI guidelines are all generated from "source" documents. 
These documents are primarily HTML but also include directives for where to pull information into the document at the time of generation. 
For example, there is a statement that says, "put a table of contents here" another that says "put the references here." 
However, I like to edit chunks of content in a WYSIWYG editor and luckily, all of the directives are commented out (e.g., !-- processing directive -- ) so this isn't an issue - for our set of documents. 
These strategies won't be found in a DTD nor in a registry anywhere (I assume). 
This will further the problem that Jutta outlines, because there is a slim chance at best that the tool could a. access the server-side script then b. analyze the content it produces for accessibility. 
I don't think we can assume that people using these types of templates are versed in a markup language. 
A company could provide a template to all employees regardless of markup language knowledge and say, "put your content here. 
we'll generate the rest (nav bars, advertising, etc.)." 
Perhaps this isn't an issue at all - if all directives are commented out the tool will ignore them. 
but, i'm not sure that is a safe assumption, either (unless it becomes an authoring practice....i can add something to techniques for server-side scripting in the WCAG but that doesn't guarantee anything). 
--wendy 
WC:: "...place-holding elements that are not defined anywhere fit into the picture?" 
WL: Although this is an important point it is difficult to imagine it being addressed in an authoring tool, it's sort of like the illegitimate ALT="text" problem in that the tool that could recognize that "insert description here" is different from "picture of my dog, Shea" would make us all obsolete. 
Trying to force the templates to spot unmodified place-holders is a nice idea but... E.g., in HotDog when you try to save a templated file without replacing "enter title here" you get a gentle nudge (after all the title of your web site could be "enter title here"!) but of course not all template makers are going to furnish such facilities. 
Love. 
ACCESSIBILITY IS RIGHT - NOT PRIVILEGE 
the issue that I was trying to raise with my previous e-mail is if the authoring tool modifies invalid or inaccesible markup, server-side directives and other "place holders" might be considered invalid or inaccessible and therefore removed. 
Thus potentially causing a problem for authors who are not markup language savvy. 
--wendy 
In the examples which spring to mind this is already covered. 
The two mechanism used for incorporating stuff into web pages are elements like SCRIPT, which need to be parsed somehow, and commented server-side things. 
In a case such as Cold Fusion, which makes use of CFML, a specialised markup language, an authoring tool which produces it needs to understand it (2.5.1). 
The output of Cold Fusion pages is HTML, and should be HTML 4.0 if the authoring tools or authors follow WCAG. 
In the unlikely event that somebody tries to use an authoring tool which does not understand Cold Fusion to edit a CFML page the tool will be faced with the choice of throwing out the CFML markup and trying to create a valid HTML page, in which case it should ask the author, or leaving it in there and not being able to validate it. 
There is not much else a tool can do. 
In the case of the scripts used by you and I, and languages like php, the pages are valid HTML, with all the magic done from inside comments. 
An authoring tool should not remove the comments anyway, but the document is always valid HTML already. 
(Although in a poorly designed language the scripts might break down if things are shifted around by someone who doesn't know what they are doing. 
Again, it isn't something a tool can reasonably be expected to address) Charles McCN the issue that I was trying to raise with my previous e-mail is if the authoring tool modifies invalid or inaccesible markup, server-side directives and other "place holders" might be considered invalid or inaccessible and therefore removed. 
Thus potentially causing a problem for authors who are not markup language savvy. 
--wendy 
--Charles McCathieNevile mailto:charles@w3.org 
W3C Web Accessibility Initiative http://www.w3.org/WAI MIT/LCS - 545 Technology sq., Cambridge MA, 02139, USA 
