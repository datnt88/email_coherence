I took an action to draft a partioning of our problem space. 
RDFCore: A base abstract syntax and a semantics for it. 
The abstract syntax is equivalent to n-triple (can n-triple be that abstract syntax). 
Nothing more - does not include type, containers, reification. 
RDFSchema: Schema as currently conceived. 
Vocabularies (aka standard library): Reification and containers RDF/XML: Syntax considerations only. 
Defines the language using some suitable mechanism (not necessarily BNF) and defines (formally?) a transform from RDF/XML to n-triple. 
With RDFCore, Eric's suggestion to set a goal of having draft document to discuss at the face to face is an excellent one. 
With an eye on the calendar, would it be possible to move forward on any of the other areas in parallel? 
DanBri - do you think that progress can be made on schema, or is it too dependent on the core? 
On the syntax front, would it be possible to investigate how best to specify the language and its transformation to n-triple? 
On the vocabularies front, can we make progress with reification based on Frank's questions or should we wait till the core is further along. 
Brian Am I correct in thinking this means that the Core includes the content of the curent P158 to P176 in the formal spec? 
Is type then introduced under vocabularies (as a standard property used to indicate type information)? 
This starts to get into the basis of my comment at the telecon, that we might want to include some stuff currently in Schema in these descriptions. 
I was specifically thinking of some of the ideas discussed in Section 2.1, and the core classes described in Section 2.2, of Schema. 
Section 2.1 (correctly) notes the similarity of the RDF schema type system to that of object-oriented programming languages, starting off with some built-in types (or classes) like "resource", "class", "property", and their relationships, and then allowing for user-defined types/classes. 
Those built-in types and their relationships (I claim) ought to be part of the model (or abstract syntax) specifications (I don't insist on subclasses or subproperties; just the basics). 
--Frank Frank Manola The MITRE Corporation 202 Burlington Road, MS A345 Bedford, MA 01730-1420 Yes, I think so. 
That is what I had in mind. 
The current situation where type, and some vocabularies (reification and containers) are introduced in m&amp;s before schema defines the typing mechanism seems awkward. 
This paritioning groups the definition of type along with the rest of schema. 
Is the motivation for this suggestion to get a better modularization? 
Are you suggesting that the Abstract Syntax and Semantics [need to be careful about that acronym] as suggested in the draft partition CANNOT stand alone without notions of type, Class etc? 
If you are suggesting that the step all the way from ASS as in the draft partition proposal to schema is too big and to break that up into two layers - built in typing and then user defined typing, I wouldn't disagree with you. 
I suggest there is value in identifying a base layer which is minimal on which everything else could be built. 
Right now I don't expect that MUST include concepts of type, Class etc, but I could be proved wrong. 
Brian snip Better modularization, and more precision as to our intentions. 
One way of interpreting RDFS is that it's one of a possible collection of schema specifications for RDF (much as XML Schema is one of several schema specifications for XML, another being DTDs). 
Under this interpretation, you can write RDF without using RDFS. 
But can you really? 
It seems to me that the M&amp;S formal model, when it talks about "sets" called "Resources", "Literals", "Properties", and "Statements", is trying (unnecessarily, or at least without any reason that I can see) to avoid saying simply that RDF has these as built-in classes, as (mostly) described in Schema Section 2.2. 
Conversely, Schema Section 2.2 says "Every RDF model that draws upon the RDF Schema namespace (implicitly) includes these [core classes]." 
But, when you look at the formal model in M&amp;S, so apparently does every other RDF model, whether there's a schema around or not (either that or the M&amp;S formal model is talking a group of sets that are distinct from any of the core Schema classes, but which, confusingly enough, have the same names). 
[NB: I noted in another context that M&amp;S doesn't define a concept of a "set" anyway, which is another difficulty in using the term here.] 
Generally, yes. 
The M&amp;S already uses the notion of type, and really uses the notion of Class too (although it uses the word "set", I think that's just to enable postponing introducing "Class" until the schema spec.; if there's an intended difference in meaning, I'd like to know what it is). 
One of the things we need to decide is how much (and what kind) of a built-in type system we want to assume for RDF. 
I agree that we don't want to put too much in the ASS, since a SmallASS provides more flexibility [I mean, for development of type systems that may not look like RDFS, of course!]. 
However, my principle is that I don't mind having a BigASS if that's what it takes to avoid having a DumbASS. 
I agree. 
It's just that I think the concepts of type (or Class), and specific classes like Statements, are in the base layer already. 
It's just that we seem to want to avoid calling them "classes" in M&amp;S for some reason (we call them "sets" instead), only to turn around first thing in Schema and say "you know those sets foo and bar and ... we talked about in M&amp;S? 
Well those are the classes foo and bar and ... here." 
I don't see the point in doing that. 
I can see that some care is need in making this partition to avoid overconstraining things. 
Perhaps those who were in on the earlier partitioning between M&amp;S and Schema could share some of the ideas they were kicking around here. 
--Frank Frank Manola The MITRE Corporation 202 Burlington Road, MS A345 Bedford, MA 01730-1420 Right, it is a mistake to be too much of a TightASS about everything. 
I thought the point was that in the base, the sets (classes, whatever) are needed to give the semantics, but are not directly referred to by anything in the language (rather like the universe of discourse in FOL) , whereas in Schema there are expressions which indicate (denote, whatever) the classes directly. 
If that impression is correct (;-/) then it would make sense and in fact would be a very natural kind of 'layering'. 
Pat IHMC(850)434 8903 home 40 South Alcaniz St.(850)202 4416 office phayes@ai.uwf.edu 
