Someone asked me just now if I think that tools have made a difference to accessibility. 
I thought that what I said below was clearly saying they did, but since apparently it isn't I will (try to) explain why I think so. 
For most people, learning accessibility testing is very difficult. 
Just using the list of checkpoints is almost impossible without already knowing what is in the techniques documents, and knowing some stuff that could be added to them. 
The tools that have been produced for testing and repairing accessibility problems in Web pages have been enormously helpful by making it easier for people to do what they need (make acccessible pages). 
At times people have claimed that a tool can automatically test everything and there is no need for a person. 
I don't think that is true - I know that some tools recognise their limitations and explicitly ask the user to check some features, and others just test a certain group of features. 
People have from time to time misunderstood or misused the information they get from tools - this is something we need to keep thinking about. 
But the 
tools themselves are helpful, and seem to be getting better all the time. 
Allowing people who aren't experts in either the web or accessibility to produce accessible web pages (by the right mix of guidance, help, tesing, etc) and providing ways to make existing web content more accessible are two important things that tool developers have done to make the Web a better place, and I look forward to them getting even better at this. 
I suspectit will be a while before they can take away all the need for thinking. 
But already they can free up a lot of time to concentrate on the really difficult issues by making the simple things very much easier. 
cheers Chaals 
It is impossible to automatically validate for accessibility, so manual validation is always needed. 
A sweeping generalisation:-) 
True, but I suspect a defensible one for a while. 
The current generation of tools are certainly helpful and reduce the time required, but are not yet able to replace all the thinking a person can do. 
[snip] 
My personal approach is to check a page against the checkpoints for WCAG 1.0 (all of them, not just the "barely minimal level A"). 
For this I use whichever automated tools I know will help - which is more a case of me learning to use enough tools and save myself work than there being a particular tool that is perfect. 
(The process of manual validation is checking against the checkpoints. 
The better I know my tools, the more and more reliably I can automate the drudgery of that, but doing the full check is important...) In that process I test in a couple of browser types, and look for behaviour I know they will reveal. 
And I agree that accepting feedback is always a valuable and important part of ongoing accessibility. 
From the authoring / updating side it is equally important to document the process required, so an update doesn't make a page become less accessible. 
just my 2 cents. 
Charles 
IMO a pretty good target is a three-level approach: (1) Automatic testing with Site Valet (2) Does it work as linearised text - e.g. view in in Lynx (3) Provide a prominent and accessible feedback option for people to raise any issues that remain in spite of your best efforts. 
Make sure someone is tasked with dealing with such feedback! 
SWAD-E http://www.w3.org/2001/sw/Europe ------------ WAI http://www.w3.org/WAI W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France 
I'd say also very tedious to do with any degree of thoroughness: a recipe for oversights! 
Any tool has to compromise somewhat between doing a thorough job and overloading the user with mostly-irrelevant information. 
Of course, the only tool that can guarantee complete support for WCAG is one whose report on any page is the WCAG itself. 
But a useful tool is one that adds to that, by drawing a users attention to specific things that are (or might be) in violation of the WCAG. 
In the case of an organisation managing a web team, another role for 
tools is in automatic monitoring of updates in support of an overall QA strategy. 
When someone makes a "trivial" update and commits some blunder through inattention, better an email reminder from Valet the next morning than that it goes undetected! 
Yes. The spellcheck is a useful analogy: the limitations on what it can do are broadly comparable, and are familiar to anyone likely to be using web-accessibility tools. 
Nick Kew 
Oh yes, I particularly appreciate this. 
(It's why I use WYSIWYG editing tools and then machine test their XHTML if needed rather than edit code by hand myself). 
Yes, nice analogy. 
Chaals 
tools is in automatic 
monitoring of updates in support of an overall QA strategy. 
I agree with Nick's Comments on using Accessibility Testing to support the Overall QA Process. 
While Agreeing, I thought that I could add some detail to the concept that would show how this could effectively be realized. 
- Integration with Existing Quality Assurance Systems By Integrating with Existing systems you will decrease the training curve and make it easier to integrate accessibility validation into the current QA Processes - Integration with Test Management Systems A Global test management system allows for QA Specialist to share information about testing and technical scripts as well as web site or web based application development. 
* Something like Mercury Interactive's TestDirector is a good example of a global test management system in use today. 
- Integration with Web Application Test Management Systems Countles Scripts have been developed to test the quality of commercial, government and all web sites. 
The accessibility testing solution should be integrated into this type of test structure to allow for testing of dynamic user driven content, pages, or streams of content. 
* Something like Mercury Interactive's QuickTest is a good example of a global test management system in use today. 
- Integration with Content Management and Authoring Systems Whether it be a FrontPage or the Microsoft .Net 
Enterprise Servers, the accessibility test management system should provide integration with the systems currently being used by the organizations. 
- The solution must provide data sharing, collection, and other relevant team services Multi User data, Reports, human testing data, run data, etc are necessary for management to accurately understand their current state of accessibility as well as for development and QA teams to standardize on practices and applicable test scripts. 
- Automated email or other alerting of Failures, Warnings or other configurable events in a "event driven accessibility management system" - Most Importantly the solution should be capable of integrating the "Human" (Referred to as manual in these posts) Testing with the Machine testing in the same content or test management system. 
Whether these integrations are Direct Integrations or achieved by Exposing Full and Open API's that allow for further customization and Integration by other developers or internal resources is fine. 
However, it is important that the tools can be customized without requiring intensive training or extensive programming experience. 
An easy way of putting it is that internal IT Staff should be able to customize and extend the solution, if resources are available. 
To Accomplish this the solution should be Open and Extendable, via Programmers API's and individual customization features allowing for customization down to individual checks and sub-checks (Requiring no Programming Skills). 
Additionally the tool istself should be able to test documents or extracted streams of content on the fly. 
By providing integration into: Training, QA Systems and Processes, Content Authoring and Management Systems while making available Robust Team Services in an event managed Accessibility Solution an organization will find it possible to achieve their goals for content that is accessible by all regardless of physical or technical ability. 
And Lastly a platform and client free solution that provides integration with all of the above elements allows for accessibility management for even the most diverse organizations environments. 
Cheers, Rob Yonaitis HiSoftware Accessibility Test Managent Solutions - HiSoftware wins the 2002 da Vinci AwardT... Category: "Electronics &amp; Information Technology." 
