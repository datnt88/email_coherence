[Despite my best efforts, I'm posting.] 
And I am describing, if you like, a perfect platonic design, to which we can aspire, though social and engineering factors limit our ability to implement it perfectly. 
Like with all technical specs, the fact of imperfect adherence in some cases does not detract from the importance of having made the perfect idealistic design which has provable properties. 
One deals with deviations from the perfect in a form of perturbation theory. 
This seems like an enormous and dangerous deviation from the "let it break" approach that catapulted the Web past the wreckage of so many beautifully Platonic but sadly unworkable hypertext systems. 
On the contrary, his aspect of the semantic web has exactly that "let it break: flavor, in that in fact if there is no document or in fact there are local misunderstandings about what things mean, the web in general goes on. 
Those old hypertext systems required complete consistency across the system. 
But still both web and semantic web are based on a design where when you point to a document you can retrieve a document. 
The web design didn't allow a link to be deemed to point to whatever the reader wanted to philosophically argue it might be considered to point to. 
Perhaps that approach qualifies as "perturbation theory", but I'd always thought that the genius of the Web was that it simply didn't bother with perfection, even especially at the URL/URI level. 
Your idea of why the web worked is just right, I think, and am in fact proposing the same thing for the semantic web. 
(That was what I meant by perturbation theory - a theory which allows one to start off by considering what happens when it doesn't break, and then work out what happens when it does break by considering the local effect of deviations. 
It works eg in phsics when considering what happens to the energy levels of an electron when the atom is placed in a magnetic field. 
It does *not* work on logic, when someone writes just one small assertion that 1=2 - the whole thing falls apart and you can prove anything. 
On the semantic web you deal with a subset of documents which don't say 1=2, and if you find they do you fix it. 
You require a certain amount of consistency locally, and it is the combined efforts to produce local consistency which tend to help but not completely generate global consistency. 
) Tim Simon St.Laurent Ring around the content, a pocket full of brackets Errors, errors, all fall down! 
Is that supposed to be "his" or "this"? 
I find Patrick Hayes' approach far more plausible on "let it break" as he seems to start out _without_ the Platonic pretensions. 
If it's "his" I agree here, but it doesn't seem coherent with the following sentences. 
I don't think most people expected URLs to morph into the philosophical demilitarized zone of URIs. 
From my perspective, the philosophy isn't the fault of your opponenents - it's the necessary consequence of the entire URI approach, especially as it enters new arenas for which it's not clear it's appropriate. 
It was tough for readers to argue with URLs. 
It's very very easy for readers to argue with URIs, especially when those URIs move between contexts. 
Perhaps that approach qualifies as "perturbation theory", but I'd always thought that the genius of the Web was that it simply didn't bother with perfection, even especially at the URL/URI level. 
I think you've wandered miles from that, to say the least. 
You may think you're proposing the same thing, but in fact you're building an enormous system of pieces which don't accept breakage easily - and then saying "well, it may not always conform to reality, so hopefully people will fix it." 
I think you need to start from broken/breakable rather than pretend it's just not broken. 
Adding exception handling after the project is complete doesn't make any sense to me. 
Simon St.Laurent Ring around the content, a pocket full of brackets Errors, errors, all fall down! 
Gentlemen, I found your latest contributions an absolute pleasure to read. 
I'm worried about it coming to the proper conclusion, but in the mean time it's fascinating entertainment. 
I'm dying to see what Pat says about the whole refining-to-the-point-of-splitting-hairs approach. 
I wonder a little if the role (or a role) of running code and interoperability testing in standards development isn't a little watching Tim interact with Fido: everyone using the code shares a kind of experience which helps establish some elements of shared meaning. 
-- sandro 
