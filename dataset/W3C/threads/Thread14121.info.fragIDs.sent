In an appendix to the Guidelines, various techniques for validating and verifying the accessibility of documents are proposed. 
These range from the use of validation tools, to displaying the document with user agents that have different capabilities. 
Should these techniques be prioritised? 
The existing list seems rather lengthy and, while I would not suggest omitting any of the items, it would seem reasonable to provide content developers with guidance as to which approaches have proved most effective practice as means of detecting coding and design shortcomings that hinder access. 
However, it can also be argued that quick solutions such as evaluation tools should not be used as substitutes for the longer but also more revealing process of examining different renderings of documents by various user agents, under diverse conditions. 
This point suggests that an attempt to prioritise the evaluation and verification techniques would lead to a contest between (1) speed and efficiency of application through validation tools; and (2) comprehensiveness of assessment, via more reliable methods of human checking. 
Should we simply leave these considerations to the discretion of content developers as in the Proposed Recommendation, or seek to classify the verification techniques, perhaps even indicating which should be tried first, or which should receive first priority? 
My personal opinion is that we should provide, as informative assistance, some methods of verification. 
The checklist, as it is composed of the checkpoints in the document, and is a complete set, is the one part of this which should be normative. 
I don't think we should attempt to prioritise the various methods, as the appropriateness of a given test is extremely dependent on the needs and abilities of the person who requires the test. 
We could usefully give some ideas about teh various strengths and weaknesses in each approach, but that itself must be done very carefully. 
Charles McCN In an appendix to the Guidelines, various techniques for validating and verifying the accessibility of documents are proposed. 
These range from the use of validation tools, to displaying the document with user agents that have different capabilities. 
Should these techniques be prioritised? 
The existing list seems rather lengthy and, while I would not suggest omitting any of the items, it would seem reasonable to provide content developers with guidance as to which approaches have proved most effective practice as means of detecting coding and design shortcomings that hinder access. 
However, it can also be argued that quick solutions such as evaluation tools should not be used as substitutes for the longer but also more revealing process of examining different renderings of documents by various user agents, under diverse conditions. 
This point suggests that an attempt to prioritise the evaluation and verification techniques would lead to a contest between (1) speed and efficiency of application through validation tools; and (2) comprehensiveness of assessment, via more reliable methods of human checking. 
Should we simply leave these considerations to the discretion of content developers as in the Proposed Recommendation, or seek to classify the verification techniques, perhaps even indicating which should be tried first, or which should receive first priority? 
--Charles McCathieNevile mailto:charles@w3.org 
W3C Web Accessibility Initiative http://www.w3.org/WAI MIT/LCS - 545 Technology sq., Cambridge MA, 02139, USA 
We have tried to provide more information about each of the various tests in the latest release of the Techniques document. 
I agree with Charles that we don't need to prioritize the list, and feel that giving developers more information in Tehchniques to help them decide which tools or methods to use would be most helpful. 
--w 
