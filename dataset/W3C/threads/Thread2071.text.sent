I disagree. 
A system that wanted to use this technique could look for a "Hostname:" header line, and if it's missing provide the user with a list of the hosts available at that address. 
The problem is that in this case, the client not sending a host[name] header also are the clients which only support one URL in a redirection status code - or am I missing something? 
I also belong to the group that believes that having the full URI in a request line would be more consistent with proxy requests but that it's something for version 2.0. 
If there really is a demand for a quick solution then a host[name] header can be added. 
However, I am getting more and more convinced that the Web community is getting too large for quick solutions - the inertia is simply too big and that time simply will run from this solution. 
-- cheers -- Henrik Frystyk While we can imagine changing HTTP's GET to include the full URL or to ask browsers to include the full URL in the header, fixing it in HTTP at this point will not have the desired effect of allowing service providers to avoid allocating two IP addresses to the same host. 
In order for this change to be effective, it would have to make its way into almost all web browsers. 
I think that's a latency of at least a year or two now. 
Yes, we know net addresses are currently a scarce resource, but trying to fix this with HTTP at this point just isn't going to work. 
I think this should probably be a requirement for HTTP 2.0, but there is no migration strategy that will make this work for HTTP 1.0. 
I disagree. 
A system that wanted to use this technique could look for a "Hostname:" header line, and if it's missing provide the user with a list of the hosts available at that address. 
If they wanted to make it really robust, they could have all of the hostname-specific content a directory down, and only look at the Hostname header if the request is "GET /". 
If the header were there, the server could generate a redirect to the appropriate subdirectory, and if not provide the list of links to hostname-specific info. 
In this scenario, even if someone with a browser which supported this extension mailed a URI to someone using a non-extended browser, it would still work since the directory information would be present. 
The subdirectory stuff could be phased out once all the browsers supported the extension. 
Jim Seidman, Senior Software Engineer, Spyglass Inc. 
I think this could be made to work, by a combination of client and server strategy. 
If we assume an intermediate state where half the clients support a full URL in the request, and others only do a partial, then a upgraded server receiving a full URL knows what to return, for a partial URL it puts up a single page advertising the different top level URLs it knows about, and - as with the migration strategy for form support - URLs of up-to-date browsers. 
- Mitra Mitra mitra@path.net 
Internet Consulting (415)488-0944 And Jim Seidman replied: and went on to elaborate on this scheme. 
I stand corrected; there is a migration strategy. 
Now the main question is whether you want to change GET to reference the entire URL, ask for a "Hostname:" or ask for a "Full-URL:" in the header with the entire reference (including, for example, original base URL and relative address, or # anchor references). 
The migration strategy for modifying "GET" doesn't look good, though. 
Sorry, my message must have been poorly phrased after a long Sunday at work. 
My intent was that as a migration strategy, redirection would occur if (and only if) a Hostname field was present and the client was retrieving the root document. 
For example: GET / HTTP/1.0 Hostname: megacorp.com 
HTTP/1.0 302 Moved Temporarily URI: http://megacorp.com/megacorp/index.htm But when the client requested any other URI, the server could ignore the Hostname field: GET /megacorp/index.htm 
Hostname: megacorp.com 
HTTP/1.0 200 OK A client which didn't support the Hostname field would never receive the 302 response, but would instead just get a document listing the different hosts for that address. 
(Of course this same strategy could be applied to a Original-URI or similar scheme.) 
As a transitional scheme, this is nice because all of the URIs for all of the hostnames, with the exception of the root document, would be unique. 
If someone told someone, "Hey, look at the great content at their browser supported the Hostname field, or even if it handled redirects properly. 
The URI would just work. 
Jim Seidman, Senior Software Engineer, Spyglass Inc. Hi folks, We seem to have a number of suggestions :- 1) A request line for the original URI 2) A request line with the intended host name The point is that for the security digest function we have to have (1). 
This is because the keyed digest is produced as a function of the URI to prevent spoof of the URI. 
[the method is also included]. 
For the digest to work the original URI has to be reconstructed. 
This is not necessarily possible if there is a proxy chain that is preforming multiple URI transformations. 
So if (1) is going to be there in any case why not use it for this as well? 
Jeff and I are going to be very keen on having the Digest authentication scheme in HTTP/1.1. 
The basic scheme is a dangerous security hole - Thank you ITAR regulations! 
The Digest scheme has nothing like the flexibility of Shen/S-HTTP but does allow the Basic scheme to be squished quickly. 
Phill. 
