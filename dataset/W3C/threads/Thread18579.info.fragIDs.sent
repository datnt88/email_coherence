I believe that the HTTP HEAD request only get you the RFC-822-ish HTTP message head, not the HTML HEAD ... /HEAD block. 
On the other hand, Brian Behlendorf did coin the following tempting dodge: ----- Forwarded message from Brian Behlendorf ----- Date: Sun, 11 May 1997 17:25:44 -0700 (PDT) From: Brian Behlendorf brian@hyperreal.com 
Another response I'd give is that if I was writing the client, one thing I could do would be to use the "byterange" part of the HTTP/1.1 spec and only access the first, say 500 bytes of a document or object, on the premise that any TITLE is likely to be there 90% of the time. 
So long as all the HTTP headers and the first chunk of text can fit inside 1000 bytes, then it'll just be one TCP/IP packet; the majority of delay when connections start up come from waiting for a second or third packet, it doesn't make much difference if the first packet is 5 bytes or 1000. 
But that's a nit I guess. 
On a larger scale, the question is, is there a framework for general metainformation about internet objects. 
Some people are starting to make noise that PICS could be used as a framework: http://www.w3.org/PICS/ 
By sending a GET with a BYTERANGE restriction one could get a single- packet sample, and test for HEAD closure in the fragment returned (similarly for PNG if the description is in the head of the file). 
One could iterate in cases where the GET of the HEAD failed to be complete. 
That would get all present TITLE , META and LINK information. 
So not all the meta-data based methods require new filing conventions or the registration of MIME headers. 
Al Gilman 
If Al is right (and he usually is), then there could be an argument for a 
modification to HTTP that would facilitate the extraction of titles from HTML head elements, text fields from PNG images, etc. 
I have not had time 
to read through the HTTP specification (I am still working through the HTML 4.0 draft in my spare moments), but one solution that comes to mind is a pattern matching scheme. 
The server would read the file until a pattern supplied by the client was matched, and then transmit all of the data up to and including the octets that matched the pattern. 
This approach would eliminate the need for the server software to be able to interpret each particular file format (HTML, PNG, audio file formats, etc.), since the pattern matching request would be provided by the client (E.G. " /title "). 
Patterns could be regular expressions, although it would probably be necessary to adopt a more sophisticated technique for handling binary files. 
He is, HEAD is just for HTTP header less the body. 
I was told this morning by one of our HTTP guru that these headers should in theory include "metadata" information for things that are found under META HTTP-EQUIV in the HTML doc, but that this is not implemented (and things like TITLE or DESC and just not here). 
Indeed, this part of HTTP could be clarified and extended and Javier is on the hook to produce a requirement document for that, that we will submit to the W3C HTTP working group. 
This is assuming that the client knows more about the document format that the server. 
For HTML, this is true, but for image format, this is probably not true. 
In fact, the client might not even know which format is going to be returned (it can give preferences: PNG first, then GIF and the server decides). 
to follow up on what Daniel Dardailler said: 
I have a recommended approach to how we handle WAI requirements on capbility-negotiation. 
The requirements for HTTP should come from the Styles work area. 
HTTP and Styles should mutually work out how much information about the media capabilities of the client session can/should go from client to server in support of autogeneration of pages or selection of styles. 
They will have to figure out whether it will work to put stylesheet subtypes in the existing Accept header or whether some new header field possibly named Target_Media would work better. 
The WAI needs to agree with the Styles work area on how we describe the media capabilities active and/or preferred in the client session so as to get 
- full coverage of disability-accomodating adaptations in the interaction media - full benefit out of the tailoring potential of the styling resource. 
This will separate disability-coverage from HTTP-message concerns. 
We can still demand to check that what we agree with Styles on media characterization, when put into what they agree with HTTP on capability negotiation, does not disclose exploitable information to the server. 
The point is that we need a better MEDIA type to cover all cases of adaptive accomodation. 
The Styles have to understand this type regardless of where they are applied, or how much the server gets into the process. 
-- Al Gilman PS: The Styles people need this anyway. 
Once the authors discover that they need to try harder on logical layout to reach WebTV and different-size-screens, there will be a demand to be able to say: "This stylesheet performs autolayout for screens in the range from WebTV to 1024X728." 
Now you've confused me. 
Why would HTTP be extended here since the model is as follow: - the server sends *one* HTML document with multiple pointer to various SS in it, categorized by media target (see example in - the user-agent decides which one it wants, and fetch it. 
In which circumstances would the user-agent need to negociate further with the server (e.g. send it a preference list). 
Yep. 
to follow up on what Daniel Dardailler said: 
[I had said] 
Probably just my confusion. 
I was thinking there was a scenario which would work like the server-side decision to send .gif or .jpg. 
I wonder if the single-HTML-document scenario isn't a little over-confident. 
There is a possible scenario where adaptations are done in a page generator engine at the server based on capabilities sent from the client. 
This approach has more ultimate capability, that is it can be taken further if you push it, than what one can do with styles. 
I might not want to rule it out. 
My preferred strategy is to work the flexible presentation problem in a way that treats the WWW as a black box, i.e. don't assume what is client vs. server functionality. 
Then make sure we have enough communication capability (and cooperation rules) so that a range of solutions are supported. 
On the other hand, I think that the characterization of media targets is more important, and is _our_ problem, not _their_ problem. 
Somehow, we need to come up with a way to wean server operators off the use of the User Agent string to discriminate service decisions. 
And the right short list of media targets could really help. 
Al Gilman 
