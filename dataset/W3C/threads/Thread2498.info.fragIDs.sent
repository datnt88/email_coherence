Warning: long message. 
This message contains proposed changes and additions to several sections of RFC2068, as a resolution of the STATUS100 issue. 
Please refer to RFC2068 for the original language (if any). 
See although a lot of the discussion is not easily found except by looking at a lot of the HTTP-WG mailing list archive. 
Comments should be reported as soon as possible, since the HTTP/1.1 editorial group intends to issue a last-call on this issue within the next week or so. 
-Jeff 
=== Major revisions to 8.2 8.2 Message Transmission Requirements 8.2.1 Persistent connections and flow control HTTP/1.1 servers SHOULD maintain persistent connections and use TCP's flow control mechanisms to resolve temporary overloads, rather than terminating connections with the expectation that clients will retry. 
The latter technique can exacerbate network congestion. 
8.2.2 Monitoring connections for error status messages An HTTP/1.1 (or later) client sending a message-body SHOULD monitor the network connection for an error status while it is transmitting the request. 
If the client sees an error status, it SHOULD immediately cease transmitting the body. 
If the body is being sent using a "chunked" encoding (section 3.6), a zero length chunk and empty footer MAY be used to prematurely mark the end of the message. 
If the body was preceded by a Content-Length header, the client MUST close the connection. 
8.2.3 Automatic retrying of requests If a client sees the transport connection close before it receives a final response to its request, if the request method is idempotent (see section 9.1.2), the client SHOULD retry the request without user interaction. 
If the request method is not idempotent, the client SHOULD NOT retry the request without user confirmation. 
(Confirmation by user agent software with semantic understanding of the application MAY substitute for user confirmation.) 8.2.4 Use of the 100 (Continue) status The purpose of the 100 (Continue) status (see section 10.1.1) is to allow an end-client that is sending a request message with a request body to determine if the origin server is willing to accept the request (based on the request headers) before the client sends the request body. 
In some cases, it may either be inappropriate or highly inefficient for the client to send the body if the server will reject the message without looking at the body. 
Requirements for HTTP/1.1 or later clients: o If a client will wait for a 100 (Continue) response before sending the request body, it MUST send an "Expect" request-header field (section 14.XX) with the "100-continue" expectation. 
o A client MUST be prepared to accept a 100 (Continue) status message followed by a regular response, even if the client does not expect a 100 (Continue) status message. 
o A client MUST NOT send an "Expect" request-header field (section 14.XX) with the "100-continue" expectation if it does not intend to send a request body. 
Note: Because of the presence of older implementations, the protocol allows ambiguous situations in which a client may send "Expect: 100-continue" without receiving either a 419 (Expectation Failed) status or a 100 (Continue) status. 
Therefore, when a client sends this header field to an origin server (possibly via a proxy) from which it has never seen a 100 (Continue) status, the client should not wait for an indefinite or lengthy period before sending the request body. 
Requirements for HTTP/1.1 or later origin servers: o Upon receiving a request which includes an "Expect" request-header field with the "100-continue" expectation, an origin server must either respond with 100 (Continue) status and continue to read from the input stream, or respond with an error status. 
If it responds with an error status, it MAY close the transport (TCP) connection or it MAY continue to read and discard the rest of the request. 
It MUST NOT perform the requested method if it returns an error status. 
o An origin server SHOULD NOT send a 100 (Continue) response if the request message does not include an "Expect" request-header field with the "100-continue" expectation, and MUST NOT send a 
100 (Continue) response if such a request comes from an HTTP/1.0 (or earlier) client. 
o An origin server SHOULD NOT send a 100 (Continue) response if has already received some or all of the request body for the corresponding request. 
o An origin server that sends a 100 (Continue) response MUST ultimately send a final status code, once the request body is received and processed, unless it terminates the transport connection prematurely. 
o If an origin server receives a request that does not include an "Expect" request-header field with the "100-continue" expectation, and the request includes a request body, and the server responds with an error status before reading the entire request body from the transport connection, then the server SHOULD NOT close the transport connection until it has read the entire request, or until the client closes the connection. 
Otherwise, the client may not reliably receive the response message. 
For compatibility with RFC 2068, a server MAY send a 100 (Continue) status in response to an HTTP/1.1 PUT or POST request that does not include an "Expect" request-header field with the "100-continue" expectation. 
This exception, the purpose of which is to minimize any client processing delays associated with an undeclared wait for 100 (Continue) status, applies only to HTTP/1.1 requests, and not to requests with any other HTTP-version value. 
Requirements for HTTP/1.1 or later proxies: o If a proxy receives a request that includes an "Expect" request-header field with the "100-continue" expectation, and the proxy either knows that the next-hop server complies with HTTP/1.1 or higher, or does not know the HTTP version of the next-hop server, it MUST forward the request, including the Expect header field. 
o If the proxy knows that the version of the next-hop server is HTTP/1.0 or lower, it MUST NOT forward the request, and it MUST respond with a 419 (Expectation Failed) status. 
o Proxies SHOULD maintain a cache recording the HTTP version numbers received from recently-referenced next-hop servers. 
o A Proxy MUST NOT forward a 100 (Continue) response if the request message was received from an HTTP/1.0 (or earlier) client and did not include an "Expect" request-header field with the "100-continue" expectation. 
Otherwise, proxies MUST forward response messages with status code 100 (Continue), unless the proxy itself added the "Expected: 100-continue" field to the request, or unless the connection between the proxy and its client has been closed. 
8.2.5 Client behavior if server prematurely closes connection If an HTTP/1.1 (or later) client sends a request which includes a request body, but which does not include an "Expect" request-header field with the "100-continue" expectation, and if the client is not directly connected to an HTTP/1.1 (or later) origin server, and if the the client sees the connection close before receiving any status from the server, the client SHOULD retry the request, subject to the restrictions in section 8.2.3. 
If the client does retry this request, it MAY use the following "binary exponential backoff" algorithm to be assured of obtaining a reliable response: 1. Initiate a new connection to the server 2. Transmit the request-headers 3. Initialize a variable R to the estimated round-trip time to the server (e.g., based on the time it took to establish the connection), or to a constant value of 5 seconds if the round-trip time is not available. 
4. Compute T = R * (2**N), where N is the number of previous retries of this request. 
5. Wait either for an error response from the server, or for T seconds (whichever comes first) 6. 
If no error response is received, after T seconds transmit the body of the request. 
7. If client sees that the connection is closed prematurely, repeat from step 1 until the request is accepted, an error response is received, or the user terminates the retry process. 
If at any point an error status is received, the client o SHOULD NOT continue and o SHOULD close the connection if it has not completed sending the request message. 
=== 10.4.1 100 Continue: === One new sentence added at the end, as a cross-reference: 10.4.1 100 Continue The client may continue with its request. 
This interim response is used to inform the client that the initial part of the request has been received and has not yet been rejected by the server. 
The client SHOULD continue by sending the remainder of the request or, if the request has already been completed, ignore this response. 
The server MUST send a final response after the request has been completed. 
See section 8.2.4 for detailed discussion of the use and handling of this status code. 
=== What follows is basically what I sent on Wed, 02 Jul 97, in === http://www.ics.uci.edu/pub/ietf/http/hypermail/1997q3/0027.html === but with a few changes: === (1) I've changed the header name from "Expected" to "Expect", === just to save a couple of bytes. 
=== (2) Following Scott Lawrence's suggestion in === http://www.ics.uci.edu/pub/ietf/http/hypermail/1997q3/0032.html === I've changed the status code from 412 (Precondition Failed) to a new === 419 (Expectation failed) code, and included additional language === for specifying that new code. 
=== (3) I've added some clarifications based on my message on "Is 100-Continue === hop-by-hop?", === http://www.ics.uci.edu/pub/ietf/http/hypermail/1997q3/0078.html === (4) I did NOT add an "Expect: 100-hopbyhop" because nobody has === spoken up in its favor. 
=== (5) I reorganized the paragraphs slightly, and introduced a new === subhead. 
10.4.20 419 Expectation Failed The expectation given in an "Expect" request-header field (see section 14.XX) could not be met by this server, or, if the server is a proxy, the server has unambiguous evidence that the request could not be met by the next-hop server. 
14.XX Expect The Expect request-header field is used to indicate that particular server behaviors are required by the client. 
A server that does not understand or is unable to comply with any of the expectation values in the Expect field of a request MUST respond with appropriate error status. 
Expect = "Expect" ":" 1#expectation expectation = "100-continue" | expectation-extension expectation-extension = token [ "=" ( token | quoted-string ) *expect-params ] expect-params = ";" token [ = ( token | quoted-string ) ] The server SHOULD respond with a 419 (Expectation Failed) status if any of the expectations cannot be met. 
This header field is defined with extensible syntax to allow for future extensions. 
If a server receives a request containing an Expect field that includes an expectation-extension that it does not support, it MUST respond with a 419 (Expectation Failed) status. 
14.XX.1 Expect 100-continue When the "100-continue" expectation is present on a request that includes a body, the requesting client will wait after sending the request headers before sending the content-body. 
In this case, the server MUST conform to the requirements of section 8.2.4: it MUST either send a 100 (Continue) status, or an error status, after receiving the "Expect: 100-continue" request header. 
If a proxy receives a request with the "100-continue" expectation, and the proxy either knows that the next-hop server complies with HTTP/1.1 or higher, or does not know the HTTP version of the next-hop server, it MUST forward the request, including the Expect header field. 
If the proxy knows that the version of the next-hop server is HTTP/1.0 or lower, it MUST NOT forward the request, and it MUST respond with a 419 (Expectation Failed) status. 
Proxies SHOULD maintain a cache recording the HTTP version numbers received from recently-referenced next-hop servers. 
Note: Because of the presence of older implementations, the protocol allows ambiguous situations in which a client may send "Expect: 100-continue" without receiving either a 419 (Expectation Failed) status or a 100 (Continue) status. 
Therefore, when a client sends this header field to an origin server (possibly via a proxy) from which it has never seen a 100 (Continue) status, the client should not wait for an indefinite or lengthy period before sending the request body. 
=== 13.11 in RFC 2068 incorrectly allows a proxy to inject === its own 100 response into the reply stream. 
The change === below modifies *only* the last sentence of the first === paragraph. 
13.11 Write-Through Mandatory All methods that may be expected to cause modifications to the origin server's resources MUST be written through to the origin server. 
This currently includes all methods except for GET and HEAD. 
A cache MUST NOT reply to such a request from a client before having transmitted the request to the inbound server, and having received a corresponding response from the inbound server. 
This does not prevent a proxy cache from forwarding a 100 (Continue) response before the inbound server has sent its final reply. 
The alternative (known as "write-back" or "copy-back" caching) is not allowed in HTTP/1.1, due to the difficulty of providing consistent updates and the problems arising from server, cache, or network failure prior to write-back. 
=== Add this to the end of 8.1.2.2 (Pipelining) Clients SHOULD NOT pipeline requests using non-idempotent methods or non-idempotent sequences of methods (see section 9.1.2). 
Otherwise, a premature termination of the transport connection may lead to indeterminate results. 
A client wishing to send a non-idempotent request SHOULD wait to send that request until it has received the response status for the previous request. 
[End of changes for STATUS100] 
An observation: I find it interesting that the set of rules to limit use of 100 Continue seems to require such a long specification, given that the original mechanism was so simple... JM 8.2 Message Transmission Requirements JM ... JM Requirements for HTTP/1.1 or later clients: JM ... JM o A client MUST be prepared to accept a 100 (Continue) status JM message followed by a regular response, even if the client does JM not expect a 100 (Continue) status message. 
JM ... JM Requirements for HTTP/1.1 or later origin servers: JM o Upon receiving a request which includes an "Expect" request-header JM field with the "100-continue" expectation, an origin server must JM either respond with 100 (Continue) status and continue to read JM from the input stream, or respond with an error status. 
If it JM responds with an error status, it MAY close the transport (TCP) JM connection or it MAY continue to read and discard the rest of the JM request. 
It MUST NOT perform the requested method if it returns JM an error status. 
I would reword this to reflect that the 100 Continue response MUST be sent after the request _headers_ have been recieved, since the 'request' includes the body. 
JM o An origin server SHOULD NOT send a 100 (Continue) response if JM the request message does not include an "Expect" request-header JM field with the "100-continue" expectation, and MUST NOT send a 
JM 100 (Continue) response if such a request comes from an HTTP/1.0 JM (or earlier) client. 
JM o An origin server SHOULD NOT send a 100 (Continue) response if JM has already received some or all of the request body for the JM corresponding request. 
I don't see the point of these two SHOULD NOTs, since the client MUST be prepared to accept an unexpected 100 response anyway. 
Arguing against these rules: - As noted elsewhere, existing 1.1 servers (yes, there are some) won't have been coded to include these restrictions (since the Expect header was only suggested a couple of weeks ago). 
- I think that it is poor design to encourage look-ahead in the data stream to determine whether or not body has been received. 
JM ... JM o If an origin server receives a request that does not include an JM "Expect" request-header field with the "100-continue" JM expectation, and the request includes a request body, and the JM server responds with an error status before reading the entire JM request body from the transport connection, then the server JM SHOULD NOT close the transport connection until it has read the JM entire request, or until the client closes the connection. 
JM Otherwise, the client may not reliably receive the response JM message. 
Does this amount to a rule for the purpose of avoiding bugs in some TCP implementations? 
I can live with this rule since it is not a MUST. 
JM For compatibility with RFC 2068, a server MAY send a 100 (Continue) JM status in response to an HTTP/1.1 PUT or POST request that does not JM include an "Expect" request-header field with the "100-continue" JM expectation. 
This exception, the purpose of which is to minimize JM any client processing delays associated with an undeclared wait for JM 100 (Continue) status, applies only to HTTP/1.1 requests, and not to JM requests with any other HTTP-version value. 
I think that making this a special case allowed _only_ for HTTP/1.1 is going too far. 
We already have the requirement that 100 Continue must be accepted by the client anyway. 
We're talking about as few as 'HTTP/1.1 100CRLF" - 14 bytes - 23 if you send the ' Continue'. 
What justification is there for the complexity of this restriction? 
Furthermore, I think that the above rule, which is stated using 'MAY', is really a 'MUST NOT': A server using any revision of HTTP later than HTTP/1.1 MUST NOT send a 100 (Continue) status in response to an HTTP/1.1 PUT or 
POST request that does not include an "Expect" request-header field with the "100-continue" expectation. 
Referring to the use of the imperitive 'key word's, RFC 2119 says that: Imperatives of the type defined in this memo must be used with care and sparingly. 
In particular, they MUST only be used where it is actually required for interoperation or to limit behavior which has potential for causing harm (e.g., limiting retransmisssions) I don't believe that this rule on future versions of the protocol meets that test. 
JM Requirements for HTTP/1.1 or later proxies: JM ... JM o If the proxy knows that the version of the next-hop server is JM HTTP/1.0 or lower, it MUST NOT forward the request, and it MUST JM respond with a 419 (Expectation Failed) status. 
How is the client to know that repeating the request using HTTP/1.0 could resolve this situation? 
Should clients always back off to 1.0 if they receive a 419? 
Scott Lawrence EmWeb Embedded Server lawrence@agranat.com 
Agranat Systems, Inc. Engineering http://www.agranat.com/ 
Responses to comments from Scott Lawrence: An observation: I find it interesting that the set of rules to limit use of 100 Continue seems to require such a long specification, given that the original mechanism was so simple... H. L. Mencken once said "For every complex problem, there is a solution that is simple, neat, and wrong." 
Anyway, a lot of the lengthening that I added was to address the complaints about ambiguity in the previous draft. 
Requirements for HTTP/1.1 or later origin servers: o Upon receiving a request which includes an "Expect" request-header 
field with the "100-continue" expectation, an origin server must either respond with 100 (Continue) status and continue to read from the input stream, or respond with an error status. 
If it responds with an error status, it MAY close the transport (TCP) connection or it MAY continue to read and discard the rest of the request. 
It MUST NOT perform the requested method if it returns an error status. 
I would reword this to reflect that the 100 Continue response MUST be sent after the request _headers_ have been recieved, since the 'request' includes the body. 
You're right that it needs a re-wording (and one "must" should be a "MUST"), but I don't think that the requirement is exactly that the server MUST wait for the entire set of request headers. 
It could, for example, decide to send the 100 Continue as soon as it sees the Expect header, if it has no intention of rejecting the request based on other headers. 
How about: o Upon receiving a request which includes an "Expect" request-header field with the "100-continue" expectation, an origin server MUST either respond with 100 (Continue) status and continue to read from the input stream, or respond with an error status. 
The origin server MUST NOT wait for the request body before sending the 100 (Continue) response. 
If it responds with an error status, it MAY close the transport (TCP) connection or it MAY continue to read and discard the rest of the request. 
It MUST NOT perform the requested method if it returns an error status. 
Note that since the decision between sending 100 (Continue) or some error status could take the server an arbitrary amount of time, so we can't actually say how soon after receiving the request headers the server must send a response. 
o An origin server SHOULD NOT send a 100 (Continue) response if the request message does not include an "Expect" request-header field with the "100-continue" expectation, and MUST NOT send a 
100 (Continue) response if such a request comes from an HTTP/1.0 (or earlier) client. 
o An origin server SHOULD NOT send a 100 (Continue) response if has already received some or all of the request body for the corresponding request. 
I don't see the point of these two SHOULD NOTs, since the client MUST be prepared to accept an unexpected 100 response anyway. 
We do have an obligation to limit the number of unnecessary bits that travel over the Internet. 
One might argue that adding HTTP/1.1 100 Continue CR LF CR LF to every response to a PUT or POST is insignificant, or one might argue the contrary. 
Anyway, the second rule seems innocuous (since if the server is receiving the request body, manifestly the client isn't waiting for the 100 Continue). 
The first rule might cause some delays for existing clients that wait for 100 Continue, if there are any. 
Arguing against these rules: - As noted elsewhere, existing 1.1 servers (yes, there are some) won't have been coded to include these restrictions (since the Expect header was only suggested a couple of weeks ago). 
We shouldn't unnecessarily break any deployed systems. 
On the other hand, the use of words such as SHOULD NOT will ultimately be used to determine whether an implementation complies with the HTTP/1.1 standard, and since that standard does not yet exist in its final form, it's unlikely that any existing "1.1" server could actually meet the final-standard rules for conditional compliance, anyway. 
- I think that it is poor design to encourage look-ahead in the data stream to determine whether or not body has been received. 
The language does not specifically require the server to look ahead into the data stream. 
However, if the server has actually read some of the request body, I see no harm in encouraging efficient use of the Internet. 
o If an origin server receives a request that does not include an "Expect" request-header field with the "100-continue" expectation, and the request includes a request body, and the server responds with an error status before reading the entire request body from the transport connection, then the server SHOULD NOT close the transport connection until it has read the entire request, or until the client closes the connection. 
Otherwise, the client may not reliably receive the response message. 
Does this amount to a rule for the purpose of avoiding bugs in some TCP implementations? 
I can live with this rule since it is not a MUST. 
Yes. 
I'd appreciate it if Henrik Frystyk or Jim Gettys could review this rule, since I included it based on my understanding of their implementation experience and suggestions. 
For compatibility with RFC 2068, a server MAY send a 100 (Continue) status in response to an HTTP/1.1 PUT or POST request that does not include an "Expect" request-header field with the "100-continue" expectation. 
This exception, the purpose of which is to minimize any client processing delays associated with an undeclared wait for 100 (Continue) status, applies only to HTTP/1.1 requests, and not to requests with any other HTTP-version value. 
I think that making this a special case allowed _only_ for HTTP/1.1 is going too far. 
We already have the requirement that 100 Continue must be accepted by the client anyway. 
We're talking about as few as 'HTTP/1.1 100CRLF" - 14 bytes - 23 if you send the ' Continue'. 
What justification is there for the complexity of this restriction? 
See above. 
But I agree with you that this is a judgement call. 
I'm just worried that we may not need to send these extra bytes, and we have the chance now to discourage 23*N extra bytes over the Internet for many years to come (where N is a large number!) What do other people think? 
Furthermore, I think that the above rule, which is stated using 'MAY', is really a 'MUST NOT': A server using any revision of HTTP later than HTTP/1.1 MUST NOT send a 100 (Continue) status in response to an HTTP/1.1 PUT or POST request that does not include an "Expect" request-header field with the "100-continue" expectation. 
I don't think the HTTP/1.1 spec can actually define the behavior of an implementation of a later version of HTTP, without also at least defining that behavior for an implementation of HTTP/1.1. 
This is basically what you said, I think: I don't believe that this rule on future versions of the protocol meets that test. 
but part of my proposal which you are paraphrasing here doesn't have the same problem. 
(Perhaps, though, I need to change "Requirements for HTTP/1.1 or later XXX" to "Requirements for HTTP/1.1 XXX".) At any rate, your proposed change doesn't address the RFC2068 compatibility issue, which is that *existing* clients might be waiting for 100 (Continue) without having sent the Expect header. 
(Unless you are assuming that all such deployed clients are gone by the time that HTTP/1.2 arrives.) Requirements for HTTP/1.1 or later proxies: o If the proxy knows that the version of the next-hop server is HTTP/1.0 or lower, it MUST NOT forward the request, and it MUST respond with a 419 (Expectation Failed) status. 
How is the client to know that repeating the request using HTTP/1.0 could resolve this situation? 
Should clients always back off to 1.0 if they receive a 419? 
If you send "Expect: 100-continue" and you get a 419 (Expectation failed) response, then you know that there is no guarantee that you will get a 100 (Continue) response before you send the request body, no longer how long you wait. 
At this point, the user-agent has two choices: (1) fall back to the HTTP/1.0-like behavior (this is NOT the same thing as falling back to HTTP/1.0), i.e., send the request body without waiting. 
(2) tell the user that the request cannot be accomplished. 
My guess is that, in reality, relatively few (if any) general-purpose applications are actually going to require "Expect: 100-continue" in the first place, and so this is really only an issue for applications in which the need for server pre-confirmation is actually significant. 
When we write the HTTP/1.1 spec, we can't presume to decide for these applications whether it is semantically necessary to get the server's pre-confirmation (i.e., 100 response). 
All we can do is to give them a relatively unambiguous signal about whether it will be available or not. 
The application implementor has to make the final decision. 
-Jeff 
In order to allow maximum flexibility shouldn't: o A client MUST be prepared to accept a 100 (Continue) status message followed by a regular response, even if the client does not expect a 100 (Continue) status message. 
Instead read: A client MUST be prepared to accept 100 (Continue) status messages... 
How about this? 
o A client MUST be prepared to accept one or more 100 (Continue) status messages prior to a regular response, even if the client does not expect a 100 (Continue) status message. 
-Jeff 
In order to allow maximum flexibility shouldn't: o A client MUST be prepared to accept a 100 (Continue) status message followed by a regular response, even if the client does not expect a 100 (Continue) status message. 
Instead read: A client MUST be prepared to accept 100 (Continue) status messages... Thanks, Yaron 
How about Even if a client has not indicated that it is prepared to accept initial 100 responses, it MUST still be prepared to accept one or more 100 responses prior to a final response header (e.g. a 200 response) and the body of the message. 
Gregory Woodhouse gjw@wnetc.com 
/ http://www.wnetc.com/home.html 
If you're going to reinvent the wheel, at least try to come up with a better one. 
I think we have lost sight of the fact that it isn't 14 (or 23) bytes but rather those bytes encapsulated in a packet. 
The implication to network routers and TCP/IP stacks is not linear with length. 
The routing function is more costly then the simple buffering associated with length. 
Secondly, this 100 Continue packet may require a separate acknowledgement packet. 
The assumption of at most 2 packets is based on the TCP/IP application sending the data with a single API call, etc. 
I learned the hard way that sending a line of data in one write followed by CRLF in a second is bad news as is sending each line of the HTTP headers one per write request. 
All in all the implications to the network are much greater than the simple 23 bytes we are discussing. 
Dave Morris (FWIW ... the minimum would be: HTTP/1.1 100CRLFCRLF or 16 bytes, wouldn't it?) 
accept one or more 100 responses"? 
(help) 
This should be the case for 1xx responses in general, so the requirement should also be in general. 
....Roy 
No, this is not an appropriate use of SHOULD NOT. 
If we reference the Bradner RFC, then we follow its rules, and one of them is that we MUST NOT use the capitalized forms for things which are not interoperability requirements. 
Likewise, inappropriate. 
Recommendations should be presented as recommendations, not as requirements. 
....Roy 
Agreed. 
I really think we need to add language to 10.1 that makes it clear that 1) Proxies should be passing through all 1xx messages 2) That multiple 1xx messages may be sent between the time that a request is made and non-1xx response is sent. 
3) That clients, at minimum, MUST be able to ignore any incoming 1xx responses. 
Yaron 
From:Roy T. Fielding [SMTP:fielding@kiwi.ics.uci.edu] 
Sent:Friday, July 18, 1997 4:37 AM Subject:Re: Proposed resolution for the STATUS100 issue 
o An origin server SHOULD NOT send a 100 (Continue) response if the request message does not include an "Expect" request-header field with the "100-continue" expectation, and MUST NOT send a 
100 (Continue) response if such a request comes from an HTTP/1.0 (or earlier) client. 
No, this is not an appropriate use of SHOULD NOT. 
If we reference the Bradner RFC, then we follow its rules, and one of them is that we MUST NOT use the capitalized forms for things which are not interoperability requirements. 
If you are referring to RFC2119, it says: 6. Guidance in the use of these Imperatives Imperatives of the type defined in this memo must be used with care and sparingly. 
In particular, they MUST only be used where it is actually required for interoperation or to limit behavior which has potential for causing harm (e.g., limiting retransmisssions) For example, they must not be used to try to impose a particular method on implementors where the method is not required for interoperability. 
I suppose one could start a pointless argument about whether the intention behind "potential for causing harm (e.g., limiting retransmissions)" applies to "limiting the transmission of unnecessary bytes over the network." 
I'll leave this decision to the working group chair. 
Larry, if you ask me to remove this SHOULD NOT, please say so. 
o An origin server SHOULD NOT send a 100 (Continue) response if has already received some or all of the request body for the corresponding request. 
Likewise, inappropriate. 
Recommendations should be presented as recommendations, not as requirements. 
I've rephrased this as: o An origin server MAY omit a 100 (Continue) response if has already received some or all of the request body for the corresponding request. 
-Jeff 
I'd like to thank everyone who commented on the previous draft of this proposal. 
I've incorporated most of the specific comments in the revised draft, below. 
Changes include: (1) Changing "HTTP/1.1 or later" to "HTTP/1.1", in contexts where this was incorrectly placing a requirement on the behavior of an implementation of a future version of HTTP/1.x (2) Made it clear that user-agents should retry requests, not "clients" in general (3) Converted requirements for clients to ignore unexpected 100 (Continue) responses, and for proxies to forward 100 responses, into a general requirement for 1xx responses. 
(4) Modified some TCP-specific language, to make it clearer that non-TCP transports are supported for HTTP. 
(5) Require that the origin server MUST NOT wait for the request body before it sends a required 100 (Continue) response. 
(6) Allow, rather than require, a server to omit 100 (Continue) if it has already seen some of the request body. 
(7) Allow servers to defend against denial-of-service attacks and broken clients. 
During our editorial group discussion today, we agreed that the proposal (with these changes) was pretty close to the right solution, so we are likely to issue a last-call on this soon. 
I.e., speak up now if you have complaints. 
-Jeff P.S.: Note that there is a new issue, open; the section on Idempotent Methods will be revised. 
Those changes will NOT be included in the resolution for STATUS100. 
=== Major revisions to 8.2 8.2 Message Transmission Requirements 8.2.1 Persistent connections and flow control HTTP/1.1 servers SHOULD maintain persistent connections and use transport-level flow control mechanisms, if available, to resolve temporary overloads, rather than terminating connections with the expectation that clients will retry. 
The latter technique can exacerbate network congestion. 
8.2.2 Monitoring connections for error status messages An HTTP/1.1 client sending a message-body SHOULD monitor the network connection for an error status while it is transmitting the request. 
If the client sees an error status, it SHOULD immediately cease transmitting the body. 
If the body is being sent using a "chunked" encoding (section 3.6), a zero length chunk and empty footer MAY be used to prematurely mark the end of the message. 
If the body was preceded by a Content-Length header, the client MUST close the connection. 
8.2.3 Automatic retrying of requests If a user agent sees the transport connection close before it receives a final response to its request, if the request method is idempotent (see section 9.1.2), the user agent SHOULD retry the request without user interaction. 
If the request method is not idempotent, the user agent SHOULD NOT retry the request without user confirmation. 
(Confirmation by user-agent software with semantic understanding of the application MAY substitute for user confirmation.) 8.2.4 Use of the 100 (Continue) status The purpose of the 100 (Continue) status (see section 10.1.1) is to allow an end-client that is sending a request message with a request body to determine if the origin server is willing to accept the request (based on the request headers) before the client sends the request body. 
In some cases, it may either be inappropriate or highly inefficient for the client to send the body if the server will reject the message without looking at the body. 
Requirements for HTTP/1.1 clients: o If a client will wait for a 100 (Continue) response before sending the request body, it MUST send an "Expect" request-header field (section 14.XX) with the "100-continue" expectation. 
o A client MUST NOT send an "Expect" request-header field (section 14.XX) with the "100-continue" expectation if it does not intend to send a request body. 
Note: Because of the presence of older implementations, the protocol allows ambiguous situations in which a client may send "Expect: 100-continue" without receiving either a 419 (Expectation Failed) status or a 100 (Continue) status. 
Therefore, when a client sends this header field to an origin server (possibly via a proxy) from which it has never seen a 100 (Continue) status, the client should not wait for an indefinite or lengthy period before sending the request body. 
Requirements for HTTP/1.1 origin servers: o Upon receiving a request which includes an "Expect" request-header field with the "100-continue" expectation, an origin server MUST either respond with 100 (Continue) status and continue to read from the input stream, or respond with an error status. 
The origin server MUST NOT wait for the request body before sending the 100 (Continue) response. 
If it responds with an error status, it MAY close the transport connection or it MAY continue to read and discard the rest of the request. 
It MUST NOT perform the requested method if it returns an error status. 
o An origin server SHOULD NOT send a 100 (Continue) response if the request message does not include an "Expect" request-header field with the "100-continue" expectation, and MUST NOT send a 
100 (Continue) response if such a request comes from an HTTP/1.0 (or earlier) client. 
o An origin server MAY omit a 100 (Continue) response if has already received some or all of the request body for the corresponding request. 
o An origin server that sends a 100 (Continue) response MUST ultimately send a final status code, once the request body is received and processed, unless it terminates the transport connection prematurely. 
o If an origin server receives a request that does not include an "Expect" request-header field with the "100-continue" expectation, and the request includes a request body, and the server responds with an error status before reading the entire request body from the transport connection, then the server SHOULD NOT close the transport connection until it has read the entire request, or until the client closes the connection. 
Otherwise, the client may not reliably receive the response message. 
However, this requirement should not be construed as preventing a server from defending itself against denial-of-service attacks, or from badly broken client implementations. 
For compatibility with RFC 2068, a server MAY send a 100 (Continue) status in response to an HTTP/1.1 PUT or POST request that does not include an "Expect" request-header field with the "100-continue" expectation. 
This exception, the purpose of which is to minimize any client processing delays associated with an undeclared wait for 100 (Continue) status, applies only to HTTP/1.1 requests, and not to requests with any other HTTP-version value. 
Requirements for HTTP/1.1 proxies: o If a proxy receives a request that includes an "Expect" request-header field with the "100-continue" expectation, and the proxy either knows that the next-hop server complies with HTTP/1.1 or higher, or does not know the HTTP version of the next-hop server, it MUST forward the request, including the Expect header field. 
o If the proxy knows that the version of the next-hop server is HTTP/1.0 or lower, it MUST NOT forward the request, and it MUST respond with a 419 (Expectation Failed) status. 
o Proxies SHOULD maintain a cache recording the HTTP version numbers received from recently-referenced next-hop servers. 
o A Proxy MUST NOT forward a 100 (Continue) response if the request message was received from an HTTP/1.0 (or earlier) client and did not include an "Expect" request-header field with the "100-continue" expectation. 
This requirement overrides the general rule for forwarding of 1xx responses (see section 10.1). 
8.2.5 Client behavior if server prematurely closes connection If an HTTP/1.1 client sends a request which includes a request body, but which does not include an "Expect" request-header field with the "100-continue" expectation, and if the client is not directly connected to an HTTP/1.1 origin server, and if the the client sees the connection close before receiving any status from the server, the client SHOULD retry the request, subject to the restrictions in section 8.2.3. 
If the client does retry this request, it MAY use the following "binary exponential backoff" algorithm to be assured of obtaining a reliable response: 1. Initiate a new connection to the server 2. Transmit the request-headers 3. Initialize a variable R to the estimated round-trip time to the server (e.g., based on the time it took to establish the connection), or to a constant value of 5 seconds if the round-trip time is not available. 
4. Compute T = R * (2**N), where N is the number of previous retries of this request. 
5. Wait either for an error response from the server, or for T seconds (whichever comes first) 6. 
If no error response is received, after T seconds transmit the body of the request. 
7. If client sees that the connection is closed prematurely, repeat from step 1 until the request is accepted, an error response is received, or the user terminates the retry process. 
If at any point an error status is received, the client o SHOULD NOT continue and o SHOULD close the connection if it has not completed sending the request message. 
=== What follows is basically what I sent on Wed, 02 Jul 97, in === http://www.ics.uci.edu/pub/ietf/http/hypermail/1997q3/0027.html === but with a few changes: === (1) I've changed the header name from "Expected" to "Expect", === just to save a couple of bytes. 
=== (2) Following Scott Lawrence's suggestion in === http://www.ics.uci.edu/pub/ietf/http/hypermail/1997q3/0032.html === I've changed the status code from 412 (Precondition Failed) to a new === 419 (Expectation failed) code, and included additional language === for specifying that new code. 
=== (3) I've added some clarifications based on my message on "Is 100-Continue === hop-by-hop?", === http://www.ics.uci.edu/pub/ietf/http/hypermail/1997q3/0078.html === (4) I did NOT add an "Expect: 100-hopbyhop" because nobody has === spoken up in its favor. 
=== (5) I reorganized the paragraphs slightly, and introduced a new === subhead. 
10.1 Informational 1xx This class of status code indicates a provisional response, consisting only of the Status-Line and optional headers, and is terminated by an empty line. 
Since HTTP/1.0 did not define any 1xx status codes, servers MUST NOT send a 1xx response to an HTTP/1.0 client except under experimental conditions. 
A client MUST be prepared to accept one or more 1xx status responses prior to a regular response, even if the client does not expect a 100 (Continue) status message. 
Unexpected 1xx status responses MAY be ignored by a user agent. 
Proxies MUST forward 1xx responses, unless the connection between the proxy and its client has been closed, or unless the proxy itself requested the generation of the 1xx response. 
(For example, if a proxy adds a "Expected: 100-continue" field when it forwards a request, then it need not forward the corresponding 100 (Continue) response(s).) 10.4.1 100 Continue The client may continue with its request. 
This interim response is used to inform the client that the initial part of the request has been received and has not yet been rejected by the server. 
The client SHOULD continue by sending the remainder of the request or, if the request has already been completed, ignore this response. 
The server MUST send a final response after the request has been completed. 
See section 8.2.4 for detailed discussion of the use and handling of this status code. 
10.4.20 419 Expectation Failed The expectation given in an "Expect" request-header field (see section 14.XX) could not be met by this server, or, if the server is a proxy, the server has unambiguous evidence that the request could not be met by the next-hop server. 
14.XX Expect The Expect request-header field is used to indicate that particular server behaviors are required by the client. 
A server that does not understand or is unable to comply with any of the expectation values in the Expect field of a request MUST respond with appropriate error status. 
Expect = "Expect" ":" 1#expectation expectation = "100-continue" | expectation-extension expectation-extension = token [ "=" ( token | quoted-string ) *expect-params ] expect-params = ";" token [ = ( token | quoted-string ) ] The server SHOULD respond with a 419 (Expectation Failed) status if any of the expectations cannot be met. 
This header field is defined with extensible syntax to allow for future extensions. 
If a server receives a request containing an Expect field that includes an expectation-extension that it does not support, it MUST respond with a 419 (Expectation Failed) status. 
14.XX.1 Expect 100-continue When the "100-continue" expectation is present on a request that includes a body, the requesting client will wait after sending the request headers before sending the content-body. 
In this case, the server MUST conform to the requirements of section 8.2.4: it MUST either send a 100 (Continue) status, or an error status, after receiving the "Expect: 100-continue" request header. 
If a proxy receives a request with the "100-continue" expectation, and the proxy either knows that the next-hop server complies with HTTP/1.1 or higher, or does not know the HTTP version of the next-hop server, it MUST forward the request, including the Expect header field. 
If the proxy knows that the version of the next-hop server is HTTP/1.0 or lower, it MUST NOT forward the request, and it MUST respond with a 419 (Expectation Failed) status. 
Proxies SHOULD maintain a cache recording the HTTP version numbers received from recently-referenced next-hop servers. 
Note: Because of the presence of older implementations, the protocol allows ambiguous situations in which a client may send "Expect: 100-continue" without receiving either a 419 (Expectation Failed) status or a 100 (Continue) status. 
Therefore, when a client sends this header field to an origin server (possibly via a proxy) from which it has never seen a 100 (Continue) status, the client should not wait for an indefinite or lengthy period before sending the request body. 
=== 13.11 in RFC 2068 incorrectly allows a proxy to inject === its own 100 response into the reply stream. 
The change === below modifies *only* the last sentence of the first === paragraph. 
13.11 Write-Through Mandatory All methods that may be expected to cause modifications to the origin server's resources MUST be written through to the origin server. 
This currently includes all methods except for GET and HEAD. 
A cache MUST NOT reply to such a request from a client before having transmitted the request to the inbound server, and having received a corresponding response from the inbound server. 
This does not prevent a proxy cache from forwarding a 100 (Continue) response before the inbound server has sent its final reply. 
The alternative (known as "write-back" or "copy-back" caching) is not allowed in HTTP/1.1, due to the difficulty of providing consistent updates and the problems arising from server, cache, or network failure prior to write-back. 
=== Add this to the end of 8.1.2.2 (Pipelining) Clients SHOULD NOT pipeline requests using non-idempotent methods or non-idempotent sequences of methods (see section 9.1.2). 
Otherwise, a premature termination of the transport connection may lead to indeterminate results. 
A client wishing to send a non-idempotent request SHOULD wait to send that request until it has received the response status for the previous request. 
In my proposal, this point was only intended as an optimization permission or recomentation. 
I didn't want to preclude a server which had the information from bypassing the 100 (Continue) so I would be happy with any wording which expressed the exception case allowing the omission. 
Either: o An origin server need not send a 100 (continue) response if it ... missing? 
^^ (which I agree feels like awkward wording) or: o It is not necessary for an origin server (or proxy) to send a 100 (Continue) response if it has already received some or all of the request body for the corresponding request. 
Dave 
My personal (not wg-chair) opinion is that we should avoid placing any requirements we don't need to place. 
Limiting the transmission of unnecessary bytes over the network is grounds for good implementation advice, but not for a SHOULD NOT. 
There are a few cases where we've placed requirements for reasons other than interoperability, so I don't think it's a hard rule. 
Officially, we can't make requirements that don't match experience; in going from Proposed to Draft, we cannot have a "SHOULD NOT do X" if we can't document two independent interoperable implementations that don't do X; but I don't think that's an issue in this case. 
Larry 
