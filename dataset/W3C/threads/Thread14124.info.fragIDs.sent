The relationship between checkpoints 1.1 and 1.3 caused significant confusion during last Tuesday's teleconference, and I am concerned that it would be likewise obscure to most readers. 
This shortcoming could be rectified by adding an explanatory note to checkpoint 1.3 which explains that the combined effect of checkpoints 1.1 and 1.3 is that a description of the video must be provided both as text, and as a synchronized audio stream. 
I would argue that such clarification is needed irrespective of the proposed "Until most multimedia players [...]" qualification of checkpoint 1.3. 
My recall of the idea behind 1.3 was that it called for non-text equivalents to be presented where appropriate. 
Audio description of video, however it is generated, is a particularly outstanding example (but in my opinion is an example not a checkpoint). 
I don't think this is a showstopper - the point is handled in other places anyway. 
Charles The relationship between checkpoints 1.1 and 1.3 caused significant confusion during last Tuesday's teleconference, and I am concerned that it would be likewise obscure to most readers. 
This shortcoming could be rectified by adding an explanatory note to checkpoint 1.3 which explains that the combined effect of checkpoints 1.1 and 1.3 is that a description of the video must be provided both as text, and as a synchronized audio stream. 
I would argue that such clarification is needed irrespective of the proposed "Until most multimedia players [...]" qualification of checkpoint 1.3. 
--Charles McCathieNevile mailto:charles@w3.org 
W3C Web Accessibility Initiative http://www.w3.org/WAI MIT/LCS - 545 Technology sq., Cambridge MA, 02139, USA 
I read past minutes and many post to the list, but I don't understand why important video information available as a text description or audio description is made more accessible by being synchronized with the video. 
However, as Gregg has argued, consistently and persuasively, until such time as multimedia players (that is to say, user agents) can synchronize a spoken rendering of the text equivalent with the audio track of a multimedia presentation, there is no other means available of providing a synchronized equivalent to the video. 
He therefore maintained that this item must have a priority 1 rating, as failure to include a description renders the content inaccessible. 
Whether I buy the book or buy the video, I can usually figure out how to do the complicated task that I bought the book or video for. 
My ability to accomplish the task is usually dependent on my ability to comprehend and/or the authors ability to describe in written or video format. 
I don't know of an example where the synchronization would provide more accessibility. 
This is similar to internationalization issues of translating audio and video information. 
Synchronizing the alternative content should be priority 3. Regards, Phill Jenkins 
Unsynchronised alternatives can lead to a completely different interpretation 
of a video. 
A simple example is to provide captions which imply that speakers 
are taking different positions in a debate to those they are in fact taking. 
Charles McCathieNevile I read past minutes and many post to the list, but I don't understand why important video information available as a text description or audio description is made more accessible by being synchronized with the video. 
However, as Gregg has argued, consistently and persuasively, until such time as multimedia players (that is to say, user agents) can synchronize a spoken rendering of the text equivalent with the audio track of a multimedia presentation, there is no other means available of providing a synchronized equivalent to the video. 
He therefore maintained that this item must have a priority 1 rating, as failure to include a description renders the content inaccessible. 
Whether I buy the book or buy the video, I can usually figure out how to do the complicated task that I bought the book or video for. 
My ability to accomplish the task is usually dependent on my ability to comprehend and/or the authors ability to describe in written or video format. 
I don't know of an example where the synchronization would provide more accessibility. 
This is similar to internationalization issues of translating audio and video information. 
Synchronizing the alternative content should be priority 3. Regards, Phill Jenkins --Charles McCathieNevile mailto:charles@w3.org 
W3C Web Accessibility Initiative http://www.w3.org/WAI MIT/LCS - 545 Technology sq., Cambridge MA, 02139, USA 
interpretation 
speakers 
taking. 
I agree that captions incorrectly synchronized [poorly or mislabeled] with the video can lead to completely different interpretations - just as a transcript of our working groups minutes which are incorrectly labeled as to who is saying what can lead to completely different interpretations. 
I agree "IF" I provide captions with the video they should be synchronized correctly. 
But why priority 1 to *have to* provide a captioned video? 
- when a separate text transcript will do? 
For example, if we were to video record a W3C conference call where some members were present in one room, say at MIT, and others participating via the phone; and we provide the clip on the W3C web site, would it have to be closed captioned to meet the guidelines - or is it just as accessible to have the transcript of the video conference call? 
I can think of more elaborate video conference calls I been in where charts (HTML pages) where shown and mechanical models were displayed, but I could provide all the information in a text description file - and it be fully accessible - without the production of synchronizing captions and video descriptions with the original recorded video. 
Regards, Phill Jenkins 
