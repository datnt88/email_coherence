Patrick, I'm trying hard to understand your position here. 
In as few words as possible, what's your definition of an URL? 
MB 
Though I probably will need to provide a more lengthy explanation... 
In a nutshell: I view a URL as a direct point of access to a digital resource, such that "interaction" with that point of access (whether that be retrieval, storage, query, etc.) involves the interchange of content between two systems -- a server which hosts that point of access and a client which connects to that point of access. 
Thus, a URL (e.g. 'http:') used to denote an abstract or non-digital resource is not a "proper" or "reasonable" URL because it can never meet the above expectations of accessibility. 
A URN can be viewed as an indirect point of access to a digital resource, such that -- as with a URL -- "interaction" with that point of access involves the interchange of content. 
Thus, a URN used to denote an abstract or non-digital resource is not a proper or reasonable URN because it can never meet the expectations of accessibility. 
In the case of a URN, the direct point of access must be determined based on context or other external specification, but otherwise, the interaction of a client with a URN denoted resource is analogous to interaction with a URL denoted resource. 
This does not mean that every URL or URN must always and forever resolve in every context for all time to some digital resource -- only that the original and intended purpose of every minted URL and URN *is* to resolve to a digital resource. 
In my I-D draft-pstickler-uri-taxonomy-00, I define a set of primary distinctions between URI classes based on the denotation 
of authorities/agencies in the URI scheme, such that, for a URL 
both the minting authority and resolution (access) agency are defined by the URL itself. 
For a URN, only the minting authority is defined, leaving the resolution agency open to contextualization. 
Without the distinction between directly resolvable (URL), indirectly resolvable (URN), and non-resolvable (URP) inherent in the semantics of each URI Scheme (and ideally, though not necessarily, organized into a taxonomy of URI classes where significant intersection of semantics occurs) applications are unnable to automatically differentiate between a true access error and an "intentional" access error -- the latter being the case in the use of URLs (or URNs) for denotation of abstract and non-digital resources. 
With regards to resolution, URLs and URNs are closely related, in comparison to URPs -- as both URLs and URNs resolve to digital resources (where URPs do not), and the primary difference between them is simply whether access/resolution is direct or indirect based on whether the resolution agency is specified in the URI itself. 
With regards to named authorities/agencies, URNs and URTs are closely related, with the primary difference between them being whether they denote digital resources or non-digital resources (resolvable versus non-resolvable) -- with both naming the minting authority but not any resolution agency. 
URVs are unique in that they name neither the minting authority nor resolution agency (the latter of course because they are URPs and non-resolvable) -- such that anyone can mint them so long as they conform to the lexical requirements for the URV scheme, and they become completely "free" and "unbounded" digital resources without reference nor tie to creator or resolver. 
Any means to derive a source for a given URV (e.g. analyzing a UUID, etc.) is an artifact of a given URV scheme and not an inherent part of its interpretation. 
Does that help clarify my understanding of URL, URN, etc.? 
Cheers, Patrick 
Should this discussion be moved back on-list? 
It's very relevant, and I'm sure others would be interested. 
Oh my, I was hoping for a couple of sound bites. 
Up front, I want to give warning and apology if any of my responses seem too curt, blunt, or generally insulting. 
In the interest of clarity and avoiding rambling on so as to say things in a politically correct or diplomatic fashion, I've chosen to just say what I think -- and all is said with all due respect and curtesy, honestly. 
But I see that you're using the classical view of URI space. 
I have stated repeatedly, and explicitly, that I subscribe to the classical view. 
The W3C has been fighting for a long time to change this view, and got at least part of the way there with the "uri-clarification" note. 
The "clarification" does not clarify much of anything other than what the classicial and contemporary views are. 
It does not IMO mandate the contemporary view. 
It also lacks any clear discussion of what either view really means for software engineers building URI aware applications -- apart from a single mention of the word 'formal', the significance of which must be guessed at. 
Furthermore, I find that far more people that I encounter, particularly those working on semantic web applications, subscribe to the classical view, particularly software engineers building web applications that use URIs extensively, and who want/need a logical and formal taxonomy of URI classes. 
I see it this way (which is also the way that Tim Berners-Lee, Dan Connolly, and Roy Fielding see it - the three people most responsible for the Web as we know it); 
With all due respect to all three individuals, and many others, I think that they are missing something fundamentally important. 
(Even the gods can be wrong now and then) 
My impression (which may be incorrect) is that they and others in their "camp" subscribe very strongly to a philosophy that is epitomized by Perl where "things are what you use them to be" which I consider to be hacking not engineering and completely unsuitable for many application areas (e.g. eCommerce, authority of knowledge, digital rights, etc.) even given the chaotic and dynamic nature of the Web. 
Don't get me wrong, I like Perl and use it alot, and there are many cases where hacking is appropriate -- but also many cases where it is not. 
I see the "everything is a URI and its meaning is how I use it" as just an extension of the Perl scalar datatype view, which again I find to be poor engineering. 
It's a useful notion for hacking and for one-off applications, but not as a principle of software architecture, particularly where data integrity is important and ambiguity is to be minimized (e.g. the Semantic Web). 
It appears that those who subscribe to the "contemporary" view also tend to hold this "things are what I use them for" view. 
And, BTW, I find the term "contemporary view" to be a *highly* politically loaded and offensive term equating to "if you don't agree with the modern, contemporary view, you're behind the times and your views are passe. 
I see the "contemporary view" as a transient fad that will pass, leaving the classical view to continue on its merry way towards a global semantic web. 
Names are strings that identify something. 
"Mark Baker" is my name. 
URIs are a subset of all possible names, with a specific structure, e.g. "foo://bar-com/baz". 
Every URI is a name because it identifies something, and I can associate meaning with it independant of any further interpretation of that URI. 
A formal taxonomy of URI Classes with consistent semantics is an issue of scalability and economy. 
Sure, you can enumerate all knowledge about every individual URI, but if a large portion of the knowledge about many URIs intersects in a functionally significant way, it is good engineering to capture that intersection, and that's what URI schemes are for, and also what URI Classes are for. 
Otherwise, let's just use UUIDs which are globally and temporally unique, and then add whatever semantics we want about them; which seems to me to represent the distillation of the contemporary view. 
After all, now with the DDDS architecture, we can just create the DNS entries to map any arbitrary string to an IP address -- so why bother even with 'http:' or other URI schemes? 
Just create your names using UUIDs, describe them as you like, and for those that denote web resources, use DDDS to map them to some address. 
Eh? 
After all, a name is just an opaque identifier that "is" what you say it is. 
For example, I can tell you that "http://www.markbaker.ca/James/" 
identifies my son. 
Nobody need ever invoke a GET on that URI in order to associate that name with the meaning I gave it. 
And how then does a software application know that it denotes a non-digital resource and thus, a retrieval error is in fact "correct" and to be expected rather than an indication of some access problem?! 
I never argued that URLs couldn't be (mis)used to denote non-digital resources, only that a formal taxonomy of URI classes based on resolution criteria (direct, indirect, none) is extremely useful for applications -- particularly SW applications which are using URIs to infer things about the universe. 
Furthermore, are the proponents of the contemporary view completely *blind* to the confusion that exists in the larger masses of web users regarding 'http:' and other URLs that don't resolve because they don't denote digital resources (e.g. XML Namespaces, vocabulary terms, etc. etc.) as well as the confusion between vocabulary URLs and schema URLs and the total incompatability with such an approach for multiple schemas using the same vocabulary?! 
It appears so. 
I can do this for more than just markbaker.ca 
URIs. 
You and I can have a conversation about http://www.ibm.com without invoking GET. 
No. You can only have a conversation about the web resource accessible at http://www.ibm.com, which is neither the URI 'http://www.ibm.com' nor the company 'IBM Inc.'. 
You can achieve this fundamental distinction by using URI schemes that embody the key semantics: uri:http://www.ibm.com = the URI for a web resource auth://ibm.com 
= a (semantic) web authority/entity Now, and only now, can we actually discuss these three things in a clear and consistent manner. 
E.g. (apologies to IBM and the IETF for the use of their trademarks in the following examples, as well as to all persons actually named John Doe ;-) Otherwise, your knowledge would be highly ambiguous and for all practical purposes useless. 
E.g. !-- 
Is the publisher its own publisher or just the publisher of the web page, and is John Doe the creator of the web page or of IBM or both? 
-- !-- 
Is this the title of the web page or IBM, or both? 
Does the web page and/or IBM have two titles? 
-- !-- 
Is John Doe the name of the email address or a person, and does the email address have an email address that is itself? 
-- !-- 
Is this the type of the web page or of the URI of the web page, or of IBM? -- I assume the numerous ambiguities and circularities in these second examples are clear, and also clearly demonstrate the critical need for distinctive URIs. 
Now, playing devil's advocate to my own arguments, I will concede that one could have different 'http:' URLs to capture the distinctions provided by my separate URI schemes, but there still remains the problem that in such a scenario URLs would be used for non-digital, non-accesible resources, and thus, the fair and resonable expectation by both a human and an application that a URL provides access to a web resource is violated. 
Again, how is an application (or person) supposed to know that a failure to resolve is intended/expected rather than due to some actual problem accessing a web resource? 
Is "foo://www-markbaker-ca/James/" an URL or an URN? 
You don't know, 
You *could* know, if you said something like Now, every SW agent can *know* that every instance of the 'foo:' URI 
scheme is in fact a URN, and by the defined qualities of a URN, it 
denotes a web resource which is accessible indirectly by that URI, 
and can then look for a definition within its operational context for how such URIs are to be resolved (which protocol or agency). 
Of course, since your son actually *isn't* a web resource, that 
resolution will fail (unless we move to the future or an alternate parallel dimension where you can beam folks on demand from wherever they are ;-) 
but if I say *that* identifies my son, then that's the important thing. 
It's one of the important things, but not every important thing. 
It is essential to keep in mind that the Semantic Web is *not* for humans! 
It is for stupid machines that can't think, and need explicit, well defined, formal symbol systems to do tricks with bits. 
*You* may understand that URI to denote your son. 
And some other human may be able to discern from its mnemonic characteristics that it likely denotes a human, but a computer just sees bits. 
Now, if after I've asserted that, I define a mapping that says; - replace "foo:" with "http:" - do 's/-/./g' on the authority Is it an URN (using your definition of URN, not the contemporary one) or an URL now? 
Obviously, since 'http:' is a URL scheme, you have now created a URL, but that is a *different* URI from the first. 
Hopefully you see where I'm going with this. 
Actually, no, unless you are suggesting that "www-markbaker-ca/James/" is a globally unique identifier in its own right and that the URI scheme prefix simply has to do with the method of interpretation, such that 'http://www-markbaker-ca/James/' and 'foo://www-markbaker-ca/James/' denote the same thing but merely represent different methods of interaction/access/reference. 
I'm going to presume that that is not what you are meaning, as that is contrary to the very basis of URI uniqueness. 
"Identifiers" are the important thing. 
An identifier is a name or a locator in context. 
In the context of resolving an identifer, it's always a locator. 
In the context of talking about it, it's always a name. 
My above examples show that this view is a fallacy. 
We must be able to talk about the identifier, as well as what is identified, and a given identifier can only identify one thing in every context, not different things in different contexts. 
The presently widespread view that e.g. 'http://www.ibm.com' can denote both a web page and the company, or that 'mailto:john.doe@ibm.com' 
can denote both a person and an email address is just dead wrong, and unfortunately, it seems that this is a common view held by those who subscribe to the "contemporary view". 
As I've said before, it may very well be that the *Web* can limp along with the contemporary view, but the *Semantic Web* cannot. 
Yes, thanks. 
Very "traditional". 
8-) 
The "founding fathers" got it right in the first place. 
The contemporary view is a false detour. 
We need to get back on the main road. 
Cheers, Patrick 
That's unfortunate, because now that the W3C and IETF have agreed to use the contemporary view, the nomenclature, and the direction of future work on URIs will follow it. 
Well, I think that there is sufficient contention about the recent "clarification" that both the W3C and IETF will be hard pressed to impose it upon the world at large. 
It may, unfortunately, flavor some impending work, but I thing that there's going to be alot of friction in moving in the classicial view's direction. 
I see it this way (which is also the way that Tim Berners-Lee, Dan Connolly, and Roy Fielding see it - the three people most responsible for the Web as we know it); 
That's certainly possible. 
But when these three agree, I have not yet *ever* found them to be wrong. 
There's always a first time ;-) And I find that the contemporary view (and classical view) disregards any notion of non-resolvable identifier (URP) as well as the need by software (not humans) to differentiate between true access problems and non-accessible resources. 
I.e., the contemporary view does not address the needs of semantic web agents -- which is amazing, since the SW is Tim BL's latest "thing". 
It is doubtful, because all future IETF/W3C work will use it. 
Only if the "customers" of IETF and W3C agree, and there seems to be a growing population who, now that they are beginning to understand the debate, are not too happy with the fuzzy, ambiguous, and high-overhead approach outlined by the contemporary view. 
It seems that the only folks these days who are true proponents of the view are either "the three" or their devoted disciples. 
Hours of discussion at e.g. XML 2001 showed either total ignorance of the issue (just eat what the W3C/IETF feed you) or preferance of the classicial view -- and numerous times folks were "shocked" or "amazed" when I explained what the contemporary view really means for web applications. 
That's right. 
The only issue is that http: as most of the same properties as uuid:, plus it's so well deployed and understood. 
I don't see a reason to go with an alternative that has no advantages over the incumbent. 
Because 'http:' URLs are not temporarally unique. 
It's that simple. 
If you want non-fragile, persistent identifiers, you can't rely on 'http:' URLs. 
Also, it's an issue of whether the resoulution agency is explicit in the URI or whether it is left undefined, for determination at time of interpretation based on contextual information. 
So, those are two very valid and deciding factors for choosing something other than 'http:' URLs for many applications -- and there are other factors besides. 
I'm part of that community. 
There is definitely lots of folks wondering why it is that they're using HTTP URIs, but I've only ever seen one example of people having problems because of it (that was when Netscape removed their RSS DTD and the RSS processors were all validating and didn't cache the DTD - duh!). 
In the XML world, regarding the (perceived) relation between namespace URIs, schema identity, schema location, vocabularies, etc. it is a *huge* mess. 
Likewise, in the RDF world, differentiation between web page, owner of web page, and reification of URIs is a big mess. 
It seems that (and this may be way off base) that most of the participants in the classical versus contemporary debate are working only with browsers -- and that there is little input from folks working in other application areas which have very different (even if partially intersecting) needs. 
I can do this for more than just markbaker.ca 
URIs. 
You and I can have a conversation about http://www.ibm.com without invoking GET. 
In plain english, you and I can presumably manage to agree on what we're talking about. 
I wasn't clear above, but we could have decided upon either of those things you listed there. 
Now, the big issue is how is *software* supposed to know what we're talking about. 
Using a new URI scheme for these concepts is one way, of course. 
The problem with it is that this knowledge has to be hard coded into URI processors. 
Absolutely not. 
That knowledge can be defined externally, by schema (e.g. RDF or otherwise) which can be retrieved and consulted at whatever frequency the application (or human controlling the application) feels is optimal. 
So what happens when we want to make additions or changes to the taxonomy? 
How do we deploy them? 
Do we require that everybody download new software? 
No. Just fetch the latest schema(s). 
What TimBL suggests is that we keep the URI as opaque as possible, and treat any extended information (assertions) about them as just another resource on the Web. 
But without explicit differentiation between URI schemes by common semantics and purpose, such global economy of definition can never be attained -- rather, such knowledge has to be defined for *every* instance of a URI. 
Yes, all of this is quite accurate. 
It's just not practically extensible. 
I completely disagree. 
In fact, the whole point is that it *is* practically extensible and scalable. 
The contemporary view is like saying that the semantics of every XML instance should be defined for each instance, rather than for a document type for which there is a single global schema. 
I.e., it's madness and terrible engineering. 
See my definition of the "Neo-Classical View" posted to the URN and URI lists. 
I think it provides a satisfactory solution for this. 
HTTP response codes say all that needs saying, I believe. 
But only *if* a resource is expected to be retreivable. 
There is no response code I am aware of that says "this resource is not a retrievable resource" -- and even if there were, you would have to define that response for *every* non-retrievable URL, a completely unacceptable and untenable overhead. 
W3C policy on this is reasonable; any w3.org URI used in a specification *must* be resolvable to something that defines what it means. 
But then you are getting something that is *not* the resource itself, and the application cannot know that -- unless it understands what the returned resource says. 
I.e., the contemporary view, and the W3C policy is intended for humans, not for software agents. 
It does not and cannot meet the needs of semantic web agents. 
For others, this is a good policy, because you're right, what if somebody is told that URI means something, but it returns a 404 when resolved? 
There's an inconsistency there, but it is easily resolved by putting a few words at the other end. 
It's quite a cheap process. 
No, it is a terribly expensive process -- as you must then define some standardized ontology that expresses the fact that a non-retrievable resource was not returned, but what was returned was not the resource but another resource that explains the non-retrievability of that first resource -- but then, what if you want an agent to actually retrieve that explaination, but not interpret it as an explaination about the first resource! 
Just define URI Classes for retrievable versus non retrievable resources, and then an application knows right up front, before even trying to resolve, whether that URI denotes a retrievable resource or not. 
*That* is much cheaper. 
Is "foo://www-markbaker-ca/James/" an URL or an URN? 
You don't know, 
Yes. But until you know more about it, what do you call it? 
A URI. And you only know something is an URN if it's in the urn: scheme. 
I don't accept that. 
I can state that any URI scheme is a URN scheme, not only the 'urn:' scheme. 
Neither the W3C nor IETF can forbid the definition of URI schemes that are ascribed the semantics and behavior of URNs. 
No. A resource may be anything. 
But a *web* resource must be digital and accessible. 
Of course, the RFC's do not make this either clear nor consistent, contradicting themselves even in the very same RFC, but the distinction is valid and necessary. 
Right. 
And those bits may express an assertion that he's a human: http://www.markbaker.ca/James/ 
rdfs:subClassOf :Person 
Again, I'm not saying that you can't use a URL to denote a non-digital resource, but you will confuse both humans and applications which expect URLs to be dereferencable to the resource that is named by them, and you cannot (at least for the present) dereference your son from a URL -- only a description about him, or some other resource that is not your son. 
Folks misuse URLs every day, but that is why there are so many problems in areas such as XML namespaces and RDF. Patrick 
