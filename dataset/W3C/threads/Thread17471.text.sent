Let's just look at some of the facts and results rather than the inter-organisational politics. 
The DRC study has put accessibility and websites on the map in the UK Undeniable - it's been on national TV! 
So what if the findings contradict the WAI guidelines by omission or commission - these are guidelines and need modification an adaptation - the fact that there's a version 2 under discussion proves this. 
Maybe the WAI guideline are too loose or too tight - Joe Clark has mentioned this in the recent past and has said they're sometimes unworkable (if it wasn't Joe who said this, apologies) Some of the WAI guidelines are difficult to interpret. 
Do they need changing? 
Maybe. 
I have difficulty with some of them, understanding as well as interpreting. 
Maybe it's the language in which they're expressed. 
No tool like Bobby, Cynthia, A-Prompt or whatever test is going to be 100%. 
You have to have users. 
I'm very, very fortunate. 
At my Uni we have people running the RNIB Rehabilitation Masters course, and I count them as friends. 
Maybe they don't count me so much as a friend as I keep pestering them :) They have provided me with an unending stream of information. 
But no one has said what people SHOULD do from the ground level - only what they're doing wrong. 
I teach web programming from a standards point of view and get students to validate code for standards and accessibility - marked down if they don't. 
As far as I can see no one emphasises this in plain words, apart from webstandards.org by association. 
So please can we - everybody - get off the politics and denial and onto improving information of 'what to do' and not 'what's wrong'. 
John John Colby School of Computing and Information University of Central England Perry Barr Birmingham UK B42 2SU I forgot to mention, this was one of the points being stressed in the interview - you need to get sites checked by people with disabilities and cannot rely solely on the automatic systems. 
It's a shame they don't follow it up by advising on how to get in touch with proper testers. 
Cheers, Julian Voelcker Cirencester, United Kingdom I've heard this argument before, and I still don't agree with it. 
I fail, you see, to understand where you'll get the *extraordinary* amount of people needed to cover all the various groups and accessibility issues. 
Mr. Brown, the old butcher who has just begun to use computers despite his old age and low vision, has quite different issues than Ms. Blue who, despite being blind, has grown up with 'puters of the latest mark all her life. 
Mrs. Wazi the local laywer from India with her university degree but a touch of twiching that makes using the mouse difficult has yet other issues than old Mr. Khaali who has perfect vision but isn't too good with English and really would like some help with all the abbreviations. 
In other words, an elderly immigrant with low vision have different problems in accessing information than has a young, blind, "native" citizen. 
This, for instance, can clearly be seen by the way some suggest that non-latin scripts should be implemented as graphical images because Unicode is "unreliable"[*]. 
You also need more than one tester from each group so as to smooth out any variations due to personal preference and idiocyncrasies. 
You will also have to use the *same* testers for *every* website, in particular when testing a large number of sites in a certain area, say local government, so that you avoid having different testers having different personal preferences and different personal views - they are, after all, not testing compliance against guidelines, but how well the site works for *them* - not anyone else. 
Consider this. 
We don't maintain building codes. 
Instead, we test new architectural designs with disabled people. 
In short, we have a fellow in a wheelchair drive through the doors and see if they are wide enough. 
Grand, that. 
It was indeed wide enough . 
Then we build the place, and along comes old Mr. Smith in his trusty old, and specially built, Permobil which happens to be about twice the width of the modern Chairman 2 Corpus used by the tester. 
This far we've not even *touched* upon the problem of whether to let a tester use his/her *own* setup/system which he/she is accustomed to, OR whether to let them use YOUR system which they ain't - and how *that* will impact the result ... The reason why we have, and agree upon, guidelines can in my view be summed up as this. 
* We cannot test everything using automated systems. 
It's impossible, even if people claim it isn't. 
* We cannot test everyone for everything. 
Still not possible, either in practical or economical terms. 
* So we do the best we can. 
We get together, we agree on guidelines, we ask those most impacted, and we make the guidelines both general and specific. 
Then we revise, take other issues into regard. 
* And finally we test against the guidelines using automated tools and people who are experts in testing. 
Whether they are disabled or not doesn't really matter; what *matters* is that they are able to be objective, perform the same tests time and time again[**], and that they are given solid guidelines. 
'tis not much different from any other area. 
You can't test-crash a new car model with every conceivable size and shape human being; so we make guidelines for the manufacturers to follow. 
It does also help if everyone and his grandmother would stop trying to bloody re-interpret said guidelines to fit their own personal or political agenda. 
But I won't hold my breath on that one. 
NOT my advise, no. 
I'm still trying to find out which "programs" the users probably don't have after being told one should use images of, say, Devangari text instead of Unicode. 
The ability to survive boredom helps. 
- Tina Holmboe Greytower Technologies tina@greytower.net 
http://www.greytower.net/ 
[+46] 0708 557 905 Tina Has it the nail on the head here. 
At the risk of putting myself out of a job, while it is true that automated tools cannot do it all (without a lot of work), For testing against guidelines, you need only people who can test well whether they are disabled or not. 
If however, you are going for usability and have criteria to bump against rather than some veague notion that you need to test for usability, you will need some sort of sampling of either people who understand the issues of the target audiences or from the target audiences them selves. 
I am often asked to look over a site by a tester and comment on it re the guidelines since even if they test well, What is percieved by someone who uses a different environment and or faces different challenges may be different than what the tester percieves and we need that perception if sites are to work. 
People who use screen readers have different spatial issues for instance than do people who may be testing against the guidelines. 
This does not mean that the tester will fail without this perception, but the perception can characterize any need for change that might constitute reporting for change to improve the site re the guidelines if necessary. 
from UK Disability Rights Commission I've heard this argument before, and I still don't agree with it. 
I fail, you see, to understand where you'll get the *extraordinary* amount of people needed to cover all the various groups and accessibility issues. 
Mr. Brown, the old butcher who has just begun to use computers despite his old age and low vision, has quite different issues than Ms. Blue who, despite being blind, has grown up with 'puters of the latest mark all her life. 
Mrs. Wazi the local laywer from India with her university degree but a touch of twiching that makes using the mouse difficult has yet other issues than old Mr. Khaali who has perfect vision but isn't too good with English and really would like some help with all the abbreviations. 
In other words, an elderly immigrant with low vision have different problems in accessing information than has a young, blind, "native" citizen. 
This, for instance, can clearly be seen by the way some suggest that non-latin scripts should be implemented as graphical images because Unicode is "unreliable"[*]. 
You also need more than one tester from each group so as to smooth out any variations due to personal preference and idiocyncrasies. 
You will also have to use the *same* testers for *every* website, in particular when testing a large number of sites in a certain area, say local government, so that you avoid having different testers having different personal preferences and different personal views - they are, after all, not testing compliance against guidelines, but how well the site works for *them* - not anyone else. 
Consider this. 
We don't maintain building codes. 
Instead, we test new architectural designs with disabled people. 
In short, we have a fellow in a wheelchair drive through the doors and see if they are wide enough. 
Grand, that. 
It was indeed wide enough . 
Then we build the place, and along comes old Mr. Smith in his trusty old, and specially built, Permobil which happens to be about twice the width of the modern Chairman 2 Corpus used by the tester. 
This far we've not even *touched* upon the problem of whether to let a tester use his/her *own* setup/system which he/she is accustomed to, OR whether to let them use YOUR system which they ain't - and how *that* will impact the result ... The reason why we have, and agree upon, guidelines can in my view be summed up as this. 
* We cannot test everything using automated systems. 
It's impossible, even if people claim it isn't. 
* We cannot test everyone for everything. 
Still not possible, either in practical or economical terms. 
* So we do the best we can. 
We get together, we agree on guidelines, we ask those most impacted, and we make the guidelines both general and specific. 
Then we revise, take other issues into regard. 
* And finally we test against the guidelines using automated tools and people who are experts in testing. 
Whether they are disabled or not doesn't really matter; what *matters* is that they are able to be objective, perform the same tests time and time again[**], and that they are given solid guidelines. 
'tis not much different from any other area. 
You can't test-crash a new car model with every conceivable size and shape human being; so we make guidelines for the manufacturers to follow. 
It does also help if everyone and his grandmother would stop trying to bloody re-interpret said guidelines to fit their own personal or political agenda. 
But I won't hold my breath on that one. 
NOT my advise, no. 
I'm still trying to find out which "programs" the users probably don't have after being told one should use images of, say, Devangari text instead of Unicode. 
The ability to survive boredom helps. 
- Tina Holmboe Greytower Technologies tina@greytower.net 
http://www.greytower.net/ 
[+46] 0708 557 905 I'm not so sure. 
Unfortunately I have seen too many results by reasonably substantial groups of testers that are as bad as anything an ordinary tool puts out, and many very good tests done by people who rely on experience because they don't have users to do testing with, and don't bother with formal tools. 
I suspect it comes down to the people who are running the testing and how good at it they are. 
The better WCAG gets (and more particularly the techniques, and testing materials such as those being developed by EuroAccessibility, or by Chris Ridpath, and the various tool developers who try to make better testing the reason to buy their software), the easier it gets to do it right... cheers Chaals OK, with your average test group you will never be able to test for every user scenario, but you will be able to do a far better job than just relying on the automated testing tools. 
Charles McCathieNevile Fundaci?n Sidar charles@sidar.org http://www.sidar.org 
I understand your arguments, but in the context of the report, the chairman of the Disability Rights Commission was making the point that you cannot just run your site through Bobby and assume that if it passes all the tests it is Accessible. 
Bobby, and other testing tools cannot test every aspect of a site to ensure that it conforms to the guidelines so some human testing is required and it is best to use people with disabilities because they are better equipped to do the testing. 
OK, with your average test group you will never be able to test for every user scenario, but you will be able to do a far better job than just relying on the automated testing tools. 
Cheers, Julian Voelcker Cirencester, United Kingdom Accessibility experts or disabled people? 
The former are easy to find, the latter extremely difficult even for Jakob Nielsen. 
From: Tina Holmboe [16]tina@greytower.net 
It's absolutely best to test with actual disabled people. 
Quite obviously each person is different; that's a starement of the obvious rather than a counterargument. 
You also need actual disabled people. 
As we know, in most cases it simply won't be possible to run user testing of Web sites. 
When it is possible, people with disabilities should be included. 
It is, however, extremely hard to find them. 
Joe Clark | joeclark@joeclark.org 
| http://joeclark.org/access/ 
Author, _Building Accessible Websites_ | http://joeclark.org/book/ 
Expect criticism if you top-post I don't disagree with your assertion, Charles, but I am interested in how you measure "good" and "right" if the end user experience as reported by selected testers is not the yardstick. 
How do you define "good" as you have used the word here? 
Cheers Ian Anderson zStudio An important question... 
In this case I use the yardstick of good taste - "agrees with me" grin/ . 
This is somewhat moderated by actual experience - my yardstick is a composite of experience with things that cause problems for some members of a wide variety of users. 
In general, the tests I have seen with these problems have been examined by a fairly narrow range of users. 
I agree with Joe - testing with real users provides important reality checks - especially of the guidelines being used (this is also what Tina said). 
But the average group of testers is (in my experience) two or three, which is nowhere near enough. 
Some examples: It is often claimed on the WCAG list that there is no need in the real world for default text in form fields. 
I searched myself for some time to find out if anyone still needed this. 
It turned out that there are in fact a number of Macintosh screen-reader users, and the most used product (Outspoken - very high market share in a small market because it is the only "real" screenreader for Mac OS at the moment) requires this to get around a bug. 
I discovered this through Sidar's user testing, because one of our testers is a blind person who uses a Macintosh. 
Similarly, I have worked with people who find flashing content distracting to the point of making content very difficult to access. 
(This isn't so rare in its milder form - take a group of people to a bar with a TV and there is often one person who cannot follow a conversation if they can see the TV.) Yet disability organisations who do their own reasonably comprehensive testing use flashing images on their own sites - apparently their testing group didn't have a problem. 
There is almost always mileage on these lines in the use of language. 
Checkpoint 14.1 in WCAG 1 is important for many people (see for example the comments of RNID on WCAG2, to reduce arguments about people with cognitive disabilities). 
Having worked for some time on the question of simplifying language, I can often see ways it can be done (although often I can only see that it needs to be done, and if I don't have an instant solution I am prepared to re-read some tortured syntax that I can understand) to make sites clearer. 
This may or may not come through in user testing - it is a good example of where the quality of the testing is more important than whether it is done by people with disabilities. 
cheers Chaals Charles McCathieNevile Fundaci?n Sidar charles@sidar.org http://www.sidar.org 
I don't disagree with your assertion, Charles, but I am interested in how you measure "good" and "right" if the end user experience as reported by selected testers is not the yardstick. 
How do you define "good" as you have used the word here? 
I'd question the use of 'selected' wrt testers. 
In todays climate its possible to have one blind person on a decision making body overrule the survey results from 100 blind users. 
We all have bias. 
Expert or end user? 
I guess it comes down to personal preferences. 
regards DaveP ** snip here ** NOTICE: The information contained in this email and any attachments is confidential and may be privileged. 
If you are not the intended recipient you should not use, disclose, distribute or copy any of the content of it or of any attachment; you are requested to notify the sender immediately of your receipt of the email and then to delete it and any attachments from your system. 
RNIB endeavours to ensure that emails and any attachments generated by its staff are free from viruses or other contaminants. 
However, it cannot accept any responsibility for any such which are transmitted. 
We therefore recommend you scan all attachments. 
Please note that the statements and views expressed in this email and any attachments are those of the author and do not necessarily represent those of RNIB. 
RNIB Registered Charity Number: 226227 Website: http://www.rnib.org.uk 
