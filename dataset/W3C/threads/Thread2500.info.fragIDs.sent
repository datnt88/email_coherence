On the general topic of "is the whole status 100 thing worth having?": 
I've always been neutral on the topic. 
However, several members of the HTTP/1.1 editorial group are firmly in favor of keeping it, as are at least some other members of the full working group. 
As far as I can tell, the consensus of the editorial group is "keep it, but fix it." 
I got stuck with the responsibility to fix it. 
My interest is to try to see that, if we have it, then it is done right. 
To meet (1) above, we could define a new method by which the client can ask the server if an X request with the following headers would be allowed. 
Such a request could look like: ASK-IF-ALLOWED /a/page HTTP/1.1 Is-method-allowed: PUT Authorization: ...... etc. 
I don't think things need to be more complicated than that. 
I don't believe that it's feasible to add a new method at this point, especially since it would not interoperate with existing proxies and servers. 
Koen's ASK-IF-ALLOWED method might have been a good 
design for the original HTTP protocol, but I don't see how to deploy it today, without a lot of complexity. 
Richard Gray added: 
Why not OPTIONS? 
Using OPTIONS is a possibility, but we are still waiting for a formal specification for OPTIONS (everyone seems to agree that RFC2068 doesn't explain enough how to use it). 
Also, can you suggest a way of using OPTIONS that doesn't add round trips to every PUT/POST interaction? 
Richard continues: o If an origin server receives a request that does not include an "Expect" request-header field with the "100-continue" expectation, and the request includes a request body, and the server responds with an error status before reading the entire request body from the transport connection, then the server SHOULD NOT close the transport connection until it has read the entire request, or until the client closes the connection. 
Otherwise, the client may not reliably receive the response message. 
This is excellent advice, but it does expose the server implementer to attacks where the amount of data is *very* large or the datastream is self-defining (e.g. chunked). 
There are, of course, may other kinds of denial-of-service attack. 
But perhaps it would help to add one more sentence to that rule: o If an origin server receives a request that does not include an "Expect" request-header field with the "100-continue" expectation, and the request includes a request body, and the server responds with an error status before reading the entire request body from the transport connection, then the server SHOULD NOT close the transport connection until it has read the entire request, or until the client closes the connection. 
Otherwise, the client may not reliably receive the response 
message. 
However, this requirement should not be construed as preventing a server from defending itself against denial-of-service attacks, or from badly broken client implementations. 
-Jeff 
** Reply to note from "Scott Lawrence" lawrence@agranat.com 
Thu, 17 Jul 1997 10:33:32 -0400 
An observation: I find it interesting that the set of rules to limit use of 100 Continue seems to require such a long specification, given that the original mechanism was so simple... 
Perhaps, as Koen suggested, we should use Occam's razor to cut this from the spec. 
JM o An origin server SHOULD NOT send a 100 (Continue) response if JM has already received some or all of the request body for the JM corresponding request. 
- I think that it is poor design to encourage look-ahead in the data stream to determine whether or not body has been received. 
I agree completely. 
JM ... JM o If an origin server receives a request that does not include an JM "Expect" request-header field with the "100-continue" JM expectation, and the request includes a request body, and the JM server responds with an error status before reading the entire JM request body from the transport connection, then the server JM SHOULD NOT close the transport connection until it has read the JM entire request, or until the client closes the connection. 
JM Otherwise, the client may not reliably receive the response JM message. 
This is excellent advice, but it does expose the server implementer to attacks where the amount of data is *very* large or the datastream is self-defining (e.g. chunked). 
Scott Lawrence EmWeb Embedded Server lawrence@agranat.com 
Agranat Systems, Inc. Engineering http://www.agranat.com/ 
Richard L. Gray chocolate - the One True food group 
I thought Roy explained fairly clearly that OPTIONS is meant to be 
extensible. 
So, you invent a MIME type for the message you want to send, and a format for the body: http/query-authorization METHOD=PUT It's great that OPTIONS is extensible, but if it is going to be used to solve a specific problem (such as the one in question), we need to have general agreement on the syntax and semantics for the specific extension. 
Your suggestion may be fine, but it's the first time I've seen it. 
True it would add round trips, but you have the same problem with the "Expect" header, right? 
No, the nice thing about Expect is that as long as the expectation is met, there is no extra round-trip. 
(And if the expectation is not met, then the client might not even want to retry the request). 
It occurs to me that another workaround would be to issue HEAD against the resource... But, at the moment, we have no generic way of asking, with a HEAD, whether a specific PUT (i.e., one with a specific set of request 
headers) on the same resource would be accepted by the server. 
(as an aside, it occured to me while looking at this, that TRACE and OPTIONS are not listed as idempotent, but I don't see why they are not; did I miss discussion of this somewhere?) Actually, the whole discussion about "idempotent methods" in RFC2068 is probably wrong, and I am planning to create a new "issue" for the current text. 
-Jeff 
Hmm...It seems to me that the only scenario where an extra round trip is unavoidable is a client which is unwilling to wait for a 100 response but which wishes to send a chunked PUT or POST. 
Since both of these features are new in HTTP/1.1 this seems like it would be a very unusual situation, and in this case I'm not sure an extra round trip would be such a bad thing. 
To me, it seems like the real problem is that the server has no way of knowing how much data to expect. 
Accepting a chunked PUT or POST is an all or nothing type of commitment. 
I doubt it's possible in HTTP/1.1, but it seems to me that the server need to be able to indicate how much data it is willing to accept and then allow the client to decide whether or not to attempt to send the request. 
(A client may not know how much data it has to send, but it may know that it will not exceed a certain threshold.) Gregory Woodhouse gjw@wnetc.com 
/ http://www.wnetc.com/home.html 
If you're going to reinvent the wheel, at least try to come up with a better one. 
** Reply to note from Jeffrey Mogul mogul@pa.dec.com 
Thu, 17 Jul 97 14:40:59 MDT 
Understood, just wanted to weigh in on the "I don't really like it" but if we have to keep it let's fix it right" side. 
To meet (1) above, we could define a new method by which the client can ask the server if an X request with the following headers would be allowed. 
Such a request could look like: ASK-IF-ALLOWED /a/page HTTP/1.1 Is-method-allowed: PUT Authorization: ...... etc. 
I don't think things need to be more complicated than that. 
I thought Roy explained fairly clearly that OPTIONS is meant to be extensible. 
So, you invent a MIME type for the message you want to send, and a format for the body: http/query-authorization METHOD=PUT True it would add round trips, but you have the same problem with the "Expect" header, right? 
It occurs to me that another workaround would be to issue HEAD against the resource... (as an aside, it occured to me while looking at this, that TRACE and OPTIONS are not listed as idempotent, but I don't see why they are not; did I miss discussion of this somewhere?) 
I agree, that is an improvement. 
Richard L. Gray chocolate - the One True food group 
Jeffrey Mogul: 
Reading your proposal, I think that overall you have done a good job at fixing the language and at cutting away some of the unnecessary complexity. 
It it now simple enough as far as I am concerned, though I would not mind making it still more simple. 
As far as I can see, a user agent which sends an Expect 100 would have to have time-out code so that it can handle the case that the request is done on an unknown server which turns out to be a 1.0 server, so that there never is a 100 response or an error response, because the server keeps waiting for a request body. 
As this time-out code has to be present anyway, I think we can get away with dropping the requirement that proxies remember the versions of upstream servers, and return error responses to an expect 100 if they know that the upstream server is a 1.0 server. 
We could simply add a note that an expect 100 can only be used successfully over a pure 1.1 (or higher) chain, and that agents can inspect the Via header field and status line of an earlier request to the same server to see if sending an expect 100 could be useful. 
The note should also say that the possibility of having a mesh of proxies including a 1.0 proxy, and of servers simply switching to a lower protocol version if they like to, means that a prediction based on Via cannot be 100% reliable. 
As for my ASK-IF-ALLOWED proposal: I did not use OPTIONS because I did not remember that it could be used for this at the time, but I see no reason why this could not be done with OPTIONS. 
Why would it not interoperate? 
Proxies would simply relay it, like they do with other unknown methods, and origin servers which do not know the method would simply return an error. 
Nothing breaks as far as I can see, and no extra complexity is needed. 
It would even work over a 1.0 chain. 
Koen. 
Date: Thu, 17 Jul 1997 15:47:13 -0700 (PDT) From: "Gregory J. Woodhouse" gjw@wnetc.com 
X-Url: http://www.wnetc.com/ 
To me, it seems like the real problem is that the server has no way of knowing how much data to expect. 
Accepting a chunked PUT or POST is an all or nothing type of commitment. 
I doubt it's possible in HTTP/1.1, but it seems to me that the server need to be able to indicate how much data it is willing to accept and then allow the client to decide whether or not to attempt to send the request. 
(A client may not know how much data it has to send, but it may know that it will not exceed a certain threshold.) 
In general, I've been taught to write programs that don't have arbitrary limits, so I think I would hate to write a server which places a limit on the size of a POST request. 
Perhaps for a search engine, it might make sense to create some restriction on the size of such data; but I think no matter what you do you're open to denial-of-service attacks to some extent. 
