Hello Jonathan, You write, It's my contention that only when WAI is creating graphical sites will we in a position to contribute to this discussion. 
Doyle, Well pictures (graphics) have certain properties. 
A key property of images that are not captured by text is the connectedness of points in something we see. 
This factorial property of image points is reflected in the neural networks where a neuron will connect to thousands of other neurons. 
The sites you reference uses some animation. 
But what is the relationship between text and animation? 
Let's take the attention structure in the eye, the retina and optic nerve have two parallel channels. 
The more evolutionarily recent pathway carries color information and has about ten times the information in that channel as the older magnocellular system that sees motion and 3d. 
If one sees something move in animation the primary quality we see in something moving is the connectedness of points in that surface. 
If I see an animation move such as a circle moving from one side of the screen to the other I 'know' the circle on one side of the screen is the same as the circle that reaches the other side, because that is what seeing motion does. 
But some people can have a disability that injures the motion seeing system so they don't know visually that the circle is whole, and instead they see fragmentation of the circle which they can't construct into a whole. 
That wholeness is what we 'see' when you write, Jonathan, On my system bus is illustrated by a red bus, however my colleague uses a green bus. 
in some instances (where the colleague is to actually catch a bus of a particular color) it will be important that the color is defined. 
In other instances it will be more helpful if the color is left to the user system. 
Doyle, Well here you are referring to the 'arbitrary' nature (Semiotic theory) of conceptual content. 
In terms of vision though we 'see' wholeness in things. 
That is the primary property of seeing motion. 
So if we use graphics we are going to be utilizing connectionist properties of an image. 
To use images without text means to pursue a path like text does, we have to be able to convey two different types of image or grammarize the image because the sensory system in humans has two pathways built in. 
From those pathways we can think of the different functions that need to be done with images. 
You write, My current effort relates to creating a series of 'transparent' royalty free icons to cover a range of popular topics. 
Doyle, Icons arise from prototype processes in neural networks that settle upon a stable output about a given set of images. 
We don't want icons that look like something, we want to find a way to grab a piece of visual phenomenon that we can connect to other things. 
In a practical sense as you cite with HUD (heads up display) is how do we attach a gunsite target icon on a jet flying ahead of us? 
Or in video games, or flight trainers. 
We don't want an icon in my view to look like an object we want an icon to stick to a sparrow in such a way that it touches all birds and we know that. 
That is what written words do. 
They stick to an object they don't resemble the object. 
That resolves what you referred to in the example of the red bus and green bus, is the connectedness issue between expressions such that the green and red refer to the same bus. 
So for example I could see this as a grid super computing (see Ian Foster, share so that for a given surface in the landscape the grid computes prototypes of the surface that connects that surface to like surfaces. 
We want our attention structure mapped and defined so that the sticking of connections between people functions. 
We stick our attention to a seen surface and the grid calculates the prototype structure in the seen surface so that if I use that image in a language like way someone else understands how this cognates. 
Jonathan, perhaps we are really talking about Augmented Virtuality? 
Doyle, Virtuality refers to creating a cave like environment that we can interact with, but how does a virtuality connect to the world? 
That means that I want to be able to find a bathroom using an Augmented Virtuality, but the concept of Virtuality implies that the imagery is not connected but self contained. 
We want to build in a connection process. 
Doyle Doyle Saylor Business Systems Consultant Intranet Hosting Services Wells Fargo Services Corporation Doyle, again, I suggest this is in general better sent direct to the list, EO is fairly quiet. the benefit is that I and others can then find it. 
perhaps we need to change the 'subject' to cognitive disability. 
The issue you are addressing, I know as the 'red bus' problem: I wish to send a message to a colleague, about a bus. 
On my system bus is illustrated by a red bus, however my colleague uses a green bus. 
in some instances (where the colleague is to actually catch a bus of a particular color) it will be important that the color is defined. 
in other instances it will be more helpful if the color is left to the user system. 
There is no way to solve this problem absolutely, ancient examples include the ship load of china freighted from the mainland, with the words rather than the colours they represent, in glaze. 
a couple of quotes from Alan Firminger might be helpful: One of the problems that comes from W3C is that they are committed to universal access by any rendering method. 
That?fails when?the essence of a site is graphic. 
or I have worried about?absent alt text behind the 85 photographs since first putting this together. 
I cannot compose words that describe what is important about?the photographs, singly or together.?How can the message be?translated. 
So I cannot help a blind visitor. 
To provide words accessible to sighted visitors undermines the power of the photographs. 
Everyone seeing a picture wants to read the caption - and so close off?sensitivity to image and debase the picture. 
Observe?couples at the National Gallery,?one will read the caption then?say to the other?"Its a nymph?resting 
by?a stream". 
Phil and I agreed - let the photographs do the talking. 
The solution is a separate piece of writing?about 
Magpie Dance,?like their website. 
But a compelling piece of fiction would be marvellous. 
Consider the press release . 
This is not linked to on the site because it?would be?so damaging to a visitor. 
It's my contention that only when WAI is creating graphical sites will we in a position to contribute to this discussion. 
My current effort relates to creating a series of 'transparent' royalty free icons to cover a range of popular topics. 
??????? Scaleable Vector Graphics is the appropriate W3 technology and the fabled bus is here: http://www.peepo.com/svg/ 
If you don't have an SVG viewer then visit well that together with a graphical interface to enable browsing.... and accessible games, did you follow the milkmaid, cow and splat thread? 
(it has the same topic as yours, the toilet) the cow site would be particularly great if it worked for blind users. 
??????? 
The point being that whereas a sited user would learn mouse skills, the keyboard user would learn tab and enter skills, but also presumably how to navigate accessible drop down lists, mazes, and more. 
The number of activities, rather than web pages that are accessible seems to be very close to zero. 
If you know of any examples, or are interested in developing one, that would be great! 
On practical AR i have seen two excellent examples, both rather a long time ago, one before CDs were commercial, at the Royal Society was a demonstration of a HUD for fighter aircraft showing pylons highlighted. 
The other strangely was at the new air traffic control centre, but when it was still a research centre, this was very subtle, to enable users to remain calm in all circumstances. 
It allowed the user to overlay a large range of plans, with excellent 'transparency' (sorry another sort). 
near collisions 
were for instance not in red. 
peepo follows what I can remember of the color scheme. 
perhaps we are really talking about Augmented Virtuality? did you ever use logitech's ifeel mice? the textures here http://www.immersion.com/showcase/ce/texture.shtml are particularly effective, if you have the kit. 
they gave us some mice to play with, but this has not taken off as a web technique, and W3 seems unaware of the benefits. 
On the text side I am less clear, that's a good sign! over to you. 
best wishes Jonathan Hello Jonathan, Let's talk a little more about attention. 
In a recent discussion with blind engineers concerning how to solve certain kinds of problems of locating one's self in the world whether or not through GPS or using talking signs and what will work, I got this example, will GPS explain to me how to get the nearest bathroom? 
If I am in a restaurant I look around the room and see the restroom sign. 
How do I attach the same information on a web page to that room so that a blind person knows where to go in the room? 
Suppose I am autistic, or dyslexic, or face blind, or schizophrenic? 
In any of these cases, attention structure in the person is being used. 
How does my web page fit their attention structure? 
Which is a related question to how we fit a web page to the landscape in Augmented Realism. 
If I attach an image of where to find the restroom I must understand how each group uses their attention structure to do their daily lives in the same sort of way. 
This is a language question not just in the sense of sharing attention, but clarifying how we attach data to different functional attention structures. 
For example with dyslexia, it is posited that the magnocellular channel in vision is affected. 
Therefore how do we attach that function of information to the persons other attentional structures so they know where the bathroom is? 
In what way do you want me to dilate on the above or my comments below? 
Doyle Doyle Saylor Business Systems Consultant Intranet Hosting Services Wells Fargo Services Corporation -----Original Message----- Doyle, could you elaborate on (offlist for the moment, unless you think relevant) My interest is not exactly the same as yours, i.e. 
I am highly interested in the issue of cognitive disabilities (which I mean to cover more than the narrow focus some people have of the technical term) and accessibility. 
as this is exactly, what I've been working on for more than a few years. 
Jonathan Hi Jonathan, Thanks Jonathan for the much longer commentary. 
Also thanks for clarifying for the public that we are writing for EO (Education and Outreach) not GL (Guidelines). 
My interest is not exactly the same as yours, i.e. 
I am highly interested in the issue of cognitive disabilities (which I mean to cover more than the narrow focus some people have of the technical term) and accessibility. 
You wrote, There is at least as valid a case that we need to address the needs of individuals* and to ensure that our advice is clear and unambiguous. 
Good examples are invaluable, the lack of them continues to make differentiation of the purpose of title and alt ambiguous. 
Doyle, I don't see this as exactly an issue of individuals outside of organizations but how does one understand the networked social structure of IT. 
In other words I don't see in my mind that there is public mind outside what we are doing, but rather how does our structure work to admit any other mind into our work barrier free. 
That Web Accessibility means inclusion of everyone. 
That doesn't say what you write disagrees with that, but I focus on what you say here, You wrote, It is only by inviting contributions from members of the public, that we will fully understand the usability issues that are slowing our progress with this group. 
Doyle, I think it is good for the public to be a part of any of these discussions. 
Let's take Slash Dot as an example where a highly technical subject matter is open to the public for discussion. 
They have about 2 million subscribers in the last count, and a system for free expression. 
But what is missing from that public is the sense of how cognitive impairment shapes barriers in discourse. 
So I don't think of Slash Dot as a place for someone with Cognitive Impairment to go to get the latest about technology in a barrier free way. 
And therefore inviting individuals for participation has virtues but not a solution to the problem that we face with cognitive barriers. 
You wrote, My feeling is that the latter is a far greater proportion ~10:1 perhaps or even 100:1, and one can only expect this ratio to increase as time passes. 
We have perhaps fallen into the trap of believing that all sites are documents similar to those we create, and write our guidance for, whereas many sites in fact serve very different purposes. 
Doyle, In this case you refer to how the public creates their own pages. 
You make for example a crucial point in this comment, You wrote, Given that the site in discussion has 80 images and no text or sound, it would need a great story teller to maintain interest for a blind visitor, the challenge is well worth the effort. 
Do we even speak of story telling at WAI? Doyle, I don't think story telling is the way to approach the idea of Cognitive impairment. 
I prefer in theory Joint Attention theory in Cognitive Psychology as a means of addressing the technical issues of cognitive impairment. 
Any web page anyone makes is meant to share attention space/time with someone else. 
Some cognitive disabilities such as Autism are disabilities around the issue of sharing attention. 
What we don't adequately address in the technology is focus of attention and sharing attention in web pages. 
So if we invited a member of the public with Aspergers Syndrome (high functioning Autistic like symptoms to medicalize for a moment) would we have a means for them to participate in the EO or any other group in a barrier free way? 
Let me be more concrete about this issue. 
In Joint Attention theory, an infant gazes at a parental figure and realizes that the parent looks at them, and looks at other things. 
The child gazes at something the parent looks at and 'shares' attention. 
Essentially in each figures mind shares a sense that when each looks at something similar in mental activities happen, or share 'attention' structure in each persons brain. 
If mom looks at the toy, I am doing the same thing in my head. 
How could the technology possibly address these issues? 
And I would want this theorizing to include blind people who aren't going to share vision with someone. 
Technologically shared attention means that if you look at something I can cognate attention also at something we are sharing in the moment. 
So we are asking ourselves what is the shape and structure of shared attention (not a subset of shared attention like story telling). 
The technology of that is geographic realism (GPS and talking signs). 
We don't have consumer products that can address 'augmented' reality computing, but we have engineering research that points at this area index.php?part=main&amp;main=opener&amp;sub=page&amp;lang=E N. Walking through a landscape and sticking information to the landscape is augmented reality (the U.S. military has some programs in this area) address that issue http://www.media.mit.edu/wearables/ cognitive disabilities meets Web Accessibility. 
So that for an Autistic person as they walk through a landscape a web page is presented to them as they gaze at the landscape in a usable barrier free way. 
For example, if I had a stroke and my frontal lobe was damaged, My attention structure would be greatly altered. 
My remaining living brain structures having spent a life time performing together with what is missing could still perform attention and probably want to share with others my attention. 
Do we have any sense of what that sharing might be like? 
If an average autistic person joins EO do we have a sense of sharing attention with them? 
That is where I think the most profound work lies ahead for Web Accessibility. 
This area lies at the heart of language (where Joint Attention theory is posited as the foundation for language) like use of the web http://citeseer.nj.nec.com/vertegaal99gaze.html. 
For anyone who can't read or write, or does not speak a common language shared attention is the barrier by which we strive to succeed. 
Thanks, Doyle Doyle Saylor Business Systems Consultant Intranet Hosting Services Wells Fargo Services Corporation -----Original Message----- Doyle, (this is eo not gl) in brief the perceived WAI audience is seen to be government, commerce and web specialists, so WAI documents are designed as far as possible to suit this perception. 
There is a somewhat valid argument that as a 'standards' organisation this is appropriate. 
There is at least as valid a case that we need to address the needs of individuals* and to ensure that our advice is clear and unambiguous. 
Good examples are invaluable, the lack of them continues to make differentiation of the purpose of title and alt ambiguous. 
I have invited, Alan Firminger to join IG, though EO might potentially be a friendlier environment, he expresses interest in WAI and believes he has read and understood the guidelines. 
It is only by inviting contributions from members of the public, that we will fully understand the usability issues that are slowing our progress with this group. 
Are stats available that show the bulk relationship between professional and amateur authored pages? 
My feeling is that the latter is a far greater proportion ~10:1 perhaps or even 100:1, and one can only expect this ratio to increase as time passes. 
We have perhaps fallen into the trap of believing that all sites are documents similar to those we create, and write our guidance for, whereas many sites in fact serve very different purposes. 
To give a particular example from http://www.peepo.com. 
We understand that the semantic web offers the opportunity to provide plain English executive summaries. 
None-the-less due to a paucity of online resources, for some topics we only have links to sites which use 'child friendly' illustrations, which some staff and students deem inappropriate for our adult users. 
You can imagine the necessary work; for instance in numeracy ludo is a useful game, the only online version i have found is in chinese, and has child friendly illustrations. 
The use and benefits of alt/title text in general with online games is not well evidenced. 
examples of accessible games could be very helpful. 
It is not clear how alt/title text will work with SVG. 
In a similar way to drop down menus, tooltips are invaluable, yet SVG seems not to have standardised their usage, and there are undoubtedly reasons for this. 
Given that the site in discussion has 80 images and no text or sound, it would need a great story teller to maintain interest for a blind visitor, the challenge is well worth the effort. 
Do we even speak of story telling at WAI? Jonathan *Compare with law which applies to individuals, as well as corporations and indeed government, notwithstanding that it is created with legal advice, and there is only minimal defence that the defendant did not know or understand the offence . 
Hello All, Jonathan asked me to post to the W3C guidelines. 
Jonathan makes a point (below) that the guidelines are unclear in some ways about how to make a site accessible. 
There are areas which leave things up in the air of course. 
In particular defining what it means for someone with a cognitive impairment is not well defined. 
I wonder though about not putting alt text in for images. 
That seems to me to be where the guidelines are most clear. 
Perhaps Jonathan could comment on clarity in more depth. 
Doyle Doyle Saylor Business Systems Consultant Intranet Hosting Services Wells Fargo Services Corporation -----Original Message----- Doyle, Perhaps you could post your comments to the list. 
This person genuinely believes they are following W3C guidelines, and over an exchange of a dozen e-mails has tried to develop the site to meet our understanding. 
You can tell there is a way to go, and much of this is because of a failure of clarity on the part of WAI. with regard to scripts, did you read: Client-side Scripting Techniques for Web Content Accessibility Guidelines 2.0 Jonathan On Wednesday, May 21, 2003, at 10:52 PM, saylordj@WellsFargo.COM Jonathan, When I went to the website below the images had no alt text, and interestingly when I put the site on my scroll bar it bounced back to the front of the desk top over my other work. 
I couldn't stop this behavior which is something I've never seen before. 
I had to close that window. 
Doyle Doyle Saylor Business Systems Consultant Intranet Hosting Services Wells Fargo Services Corporation -----Original Message----- As some of you will know, it has always been my belief that web accessibility will be working well when individuals rather than organisations are creating accessible web pages. 
To that end, I'd like to mention one of the best websites that peepo currently links to http://www.magpol.org/s8/0.html 
(this is a personal view, it's a tough call) The website manager has made changes to the site that don't effect the appearance, but attempt to make it accessible within our current understanding. 
Jonathan In a way I suppose this is a request for more resources designed for the non-profit sector. 
We plainly are not meeting this need currently, and this is a significant sector of the whole market. 
Doyle, whilst this snippet* is still text it has the additional benefit that it is rendered as a specific representation that maybe tested. 
It would be great if you could illustrate some of your discussion. 
We don't want an icon in my view to look like an object we want an icon to stick to a sparrow in such a way that it touches all birds and we know that. 
That is what written words do. 
They stick to an object they don't resemble the object. 
That resolves what you referred to in the example of the red bus and green bus, is the connectedness issue between expressions such that the green and red refer to the same bus. 
Unfortunately this is the nub of the issue, and it is far from resolution. 
People with SLD simply don't generalise or abstract in the way described, one might go so far as to say that this is one definition of a LD. Naturally if we could find an abstract pointer the issue would be resolved, but we can't. 
So this leads to much confusion, little of which is resolved by text based discussion. 
Reality fortunately has many useful pointers, loo signs for instance. 
However these are currently missing in virtuality, and so for the present it is necessary to augment virtuality, before it will help augment reality, the HUD has to highlight the pylon before the pilot can avoid it. 
Sadly peepo is very nearly a lone voice in the area of providing a W3C accessible virtual space, even though in a very limited sense. 
However there are many excellent VRML, flash and other attempts. 
Accessible SVG is also an extremely rare commodity :-( to resolve the red bus problem will also require excellent and transparent authoring tools. 
Perhaps we can use your expertise to create some other useful visual examples with SVG. 
Jonathan *below, please not I've had problems rotating as well as translating, if anyone has a better one thanks: !DOCTYPE svg PUBLIC "-//W3C//DTD SVG 20001102//EN" "http://www.w3.org/TR/2000/CR-SVG-20001102/DTD/svg-20001102.dtd" style="stroke-width:5;stroke:blue;fill:none" cx="60" cy="60" r="60" animate attributeName="cx" values="0;1400" dur="3s" repeatCount="indefinite" onrepeat="advance(evt)"/ 
Hello Jonathan, Well I'm strongly in agreement that we need to consider images in new ways. 
You write, Sadly peepo is very nearly a lone voice in the area of providing a W3C accessible virtual space, even though in a very limited sense. 
However there are many excellent VRML, flash and other attempts. 
Accessible SVG is also an extremely rare commodity :-( to resolve the red bus problem will also require excellent and transparent authoring tools. 
People with SLD simply don't generalise or abstract in the way described, one might go so far as to say that this is one definition of a LD. Naturally if we could find an abstract pointer the issue would be resolved, but we can't. 
So this leads to much confusion, little of which is resolved by text based discussion. 
Doyle, This remark reminds me that with visual dyslexia some people can have a great deal of trouble with seeing depth in the landscape. 
So the integrative part of seeing 'wholeness' is a difficulty for them. 
Jonathan, It would be great if you could illustrate some of your discussion. 
Doyle, I shot a video of walking on a hillside with a dyslexic person. 
They had trouble with navigating the hillside compared to me, and had to stare at the ground as we walked. 
I think this gives us a variety of entry points to consider accessibility and imagery. 
If we constructed something on line one could carry a laptop into the fields where a disabled person might go for a walk and make that usable for the dyslexic person outdoors. 
I'll describe what I think are important features of images used in the real world. 
We need to do the equivalent of googling the frames of images so we can pull up a relevant section of images when needed while walking. 
That also requires some degree of not just geographic notation that identifies a spot, but also orientation of the body in space. 
One can project a movie onto the landscape, but in many ways putting a movie directly on top of the world masks what is in the world. 
So I would prefer to have standard means of attaching a movie to the landscape to the side of what I am looking at. 
Or to be able to see through an image into the real landscape so that the ambiguity between landscape and image are not confusing me. 
Another way I could illustrate this would be to take a blind from birth person who hasn't learned certain visual orientations in the world and I would put the blind person into a parking lot (a common trial for blind people trying to navigate in the world, but a learning disabled person faces similar problems) and I would make websites for them to navigate interactively in the parking lot. 
What I am trying to learn there is how a blind person learns the landscape without experience seeing landscapes. 
And how that would translate into using a image based website that could be accessible in that sort of way. 
Another way I would consider making illustrations is with eye tracking devices that can give a better sense of attention structure that some individual brings to a given set of data. 
When one is in the world with for example some form of attention deficit, that the imagery is not enough but how can that imagery be used by the person. 
So I think there are several areas to explore this way. 
1. Linking the imagery to a specific space, 2. Addressing the imagery ambiguity between the image and real space. 
3. Finding the imagery when needed in real time. 
4. Customizing imagery for the attention structure of a given person. 
All of this could be put on line as a starting place for doing further work. 
Doyle Doyle Saylor Business Systems Consultant Intranet Hosting Services Wells Fargo Services Corporation Doyle, whilst this snippet* is still text it has the additional benefit that it is rendered as a specific representation that maybe tested. 
It would be great if you could illustrate some of your discussion. 
We don't want an icon in my view to look like an object we want an icon to stick to a sparrow in such a way that it touches all birds and we know that. 
That is what written words do. 
They stick to an object they don't resemble the object. 
That resolves what you referred to in the example of the red bus and green bus, is the connectedness issue between expressions such that the green and red refer to the same bus. 
Unfortunately this is the nub of the issue, and it is far from resolution. 
People with SLD simply don't generalise or abstract in the way described, one might go so far as to say that this is one definition of a LD. Naturally if we could find an abstract pointer the issue would be resolved, but we can't. 
So this leads to much confusion, little of which is resolved by text based discussion. 
Reality fortunately has many useful pointers, loo signs for instance. 
However these are currently missing in virtuality, and so for the present it is necessary to augment virtuality, before it will help augment reality, the HUD has to highlight the pylon before the pilot can avoid it. 
Sadly peepo is very nearly a lone voice in the area of providing a W3C accessible virtual space, even though in a very limited sense. 
However there are many excellent VRML, flash and other attempts. 
Accessible SVG is also an extremely rare commodity :-( to resolve the red bus problem will also require excellent and transparent authoring tools. 
Perhaps we can use your expertise to create some other useful visual examples with SVG. 
Jonathan *below, please not I've had problems rotating as well as translating, if anyone has a better one thanks: !DOCTYPE svg PUBLIC "-//W3C//DTD SVG 20001102//EN" "http://www.w3.org/TR/2000/CR-SVG-20001102/DTD/svg-20001102.dtd" style="stroke-width:5;stroke:blue;fill:none" cx="60" cy="60" r="60" animate attributeName="cx" values="0;1400" dur="3s" repeatCount="indefinite" onrepeat="advance(evt)"/ 
Doyle, Should we invest in a couple of pairs of eyetops? 
disabled you get nothing rave review in yesterday's UK Guardian: Jonathan 
