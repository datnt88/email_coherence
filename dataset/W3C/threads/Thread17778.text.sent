The summary conclusion in the minutes includes the statement that 3.1.1 is too vague to be a technique. 
I do not recall this ever being decided by the group. 
I think that at one point it may have been suggested that this was the case by an individual, and it was suggested to me in private converstaion by an individual. 
I do not regard the technique (following the proposed modification which changes the requirement from redundant meansof control to device-independent means of control) as even slightly vague. 
It can be checked explicitly by the following test: For each function provided by the User Agent (changing font, activating a link, selecting text, changing rate of speech, decreasing tolerance of key-bounce, determining how often headers are repeated in linearised tables, etc, as applicable to the User Agent in Question) is it possible for the control to be activated in a device independent manner? 
If there is an API, or a control feature for which the OS always provides alternative access, the answer is yes. 
If there is a hardware-specific mechanism, for which there is no API, the answer is no. 
It is a wide-reaching guideline, which is very important to ensure accessibility of a User Agent. 
It probably should be modified to take account of whether the User Agent makes an API available or whether it is constrained to certain hardware. 
But then, a touch screen information kiosk, with no voice output or tactile feedback, is not accessible. 
Which is not the same thing as saying that it cannot serve a need, merely that in nearly all circumstances it is not a total solution to that need. 
--Charles McCathieNevile - mailto:charles@w3.org 
W3C Web Accessibility Initiative - http://www.w3.org/WAI 545 Technology sq., Cambridge MA, USA I very much agree with Charles here. 
- Ian Ian Jacobs (jacobs@w3.org) 
Agree - I don't believe the group actually decided it was too vague. 
However, it became clear to me that by trying to apply the technique to the HTML document area, 3.1.1 
became too vague. 
3.1.1 was in a section talking about the the browser user interface (menus and toolbars) rather than the HTML document area. 
While you may want to lump it all together as part of the user interface, these are two distinctly different beasts and it was my understanding that the reason this group formed was to help solve problems in the HTML document area and that the browser UI/setup/documentation got lumped into peripheral items/techniques (like 3.1.1). 
I very much agree with Charles here. 
- Ian Ian Jacobs (jacobs@w3.org) 
There was discusion that it may be to vague during the meeting. 
Ian said that this item was being referenced to much by other techniques and therefore may need to be refined. 
When I read it now I think that it is difficult to interpret. 
The way it is written now I don't know when I satisfy it. 
Do I need to provide Braille input and a Braille keyboard device? 
Do I need speech recognition and speech output? 
Do I need a single switch scanning system? 
How much redundency satisfies this requirement? 
Please submit your view and your interpretation to the list for discussion. 
In my view this technique does not fly with the current wording. 
Jon Jon Gunderson, Ph.D., ATP Coordinator of Assistive Communication and Information Technology Division of Rehabilitation - Education Services University of Illinois at Urbana/Champaign 1207 S. Oak Street Champaign, IL 61820 Voice: 217-244-5870 E-mail: jongund@uiuc.edu 
WWW:http://www.staff.uiuc.edu/~jongund 
Actually I think the part where it may be a little vague is with respect to the browser-specific controls, since some of those are only relevant to the browser in certain configurations, and it may not be very important to provide access to them. 
The User Interface includes the means by which the HTML document area is navigated, and parts of it selected or activated, etc. 
Perhaps we should split 3.1.1 
into two parts, one dealing with the browser-specific controls and one with the controls specific to the rendered content, in the same way as we have currently split techniques for dealing with the font colours and the font size, but I don't think so. 
Charles --Charles McCathieNevile - mailto:charles@w3.org 
W3C Web Accessibility Initiative - http://www.w3.org/WAI 545 Technology sq., Cambridge MA, USA Agree - I don't believe the group actually decided it was too vague. 
However, it became clear to me that by trying to apply the technique to the HTML document area, 3.1.1 
became too vague. 
3.1.1 was in a section talking about the the browser user interface (menus and toolbars) rather than the HTML document area. 
While you may want to lump it all together as part of the user interface, these are two distinctly different beasts and it was my understanding that the reason this group formed was to help solve problems in the HTML document area and that the browser UI/setup/documentation got lumped into peripheral items/techniques (like 3.1.1). 
I was basing my statements on the revsed wording which I proposed - device independent control mechanism, rather than redundant means, since I don't see that there is a need for much redundancy, which simply adds bloat to the progams. 
This would mean that you don't need any of the things Jon listed, you simply need some kind of API (or to take advantage of one that the OS can be relied on to have provided already) which allows access to the controls. 
A simple solution would be a menu somewhere which gave access to each command/function which could be carried out by the UA, and to which there was some reconfigurable access mechanism. 
Such a menu used to be part of MS Word - I think it was a precursor to the process of customising toolbars. 
But most functions (mouse-based ones may be more difficult) can be readily provided in this way, and the problem is solved. 
The makers of a single switch interface can then provide, using whatever User Interface they see fit, access to the functions of this browser by means of that interface. 
Charles --Charles McCathieNevile - mailto:charles@w3.org 
W3C Web Accessibility Initiative - http://www.w3.org/WAI 545 Technology sq., Cambridge MA, USA There was discusion that it may be to vague during the meeting. 
Ian said that this item was being referenced to much by other techniques and therefore may need to be refined. 
When I read it now I think that it is difficult to interpret. 
The way it is written now I don't know when I satisfy it. 
Do I need to provide Braille input and a Braille keyboard device? 
Do I need speech recognition and speech output? 
Do I need a single switch scanning system? 
How much redundency satisfies this requirement? 
Please submit your view and your interpretation to the list for discussion. 
In my view this technique does not fly with the current wording. 
Jon That is the fundamental and fatal flaw in your reasoning: you are proposing to substitute apples for oranges. 
A programming interface is not a user interface. 
Device-independent user access to control capabilities, including meta-control capabilities such as profiling the user interface, is an oxymoron. 
You can't give the user access to a verb without an interface device. 
A given software product will support some user interface profiles natively and be adaptable to support other user interface profiles. 
Only in the case where "adaptable to support" capability is claimed does the inteface to the rest of the UA matter. 
But in the case of UI profiles supported "by adaptability" the adaptive add-on forms part of the UA and we have certainly violated the "please, no assembly required" request. 
The rest of the UA, supplied by the add-on, accesses devices to communicate with the user. 
The requirement to support diverse devices for each verb is the fundamental requirement, and it can only be verified in terms of the actual devices accessed by the UA including the add-on components. 
Al I agree in theory that navigation and interaction of the HTML document area is part of the user interface. 
Given the section that it is in and the discussion around 3.1.1, it was intended to refer to menus and toolbars (i.e. the browser container's UI). 
HTML document and the container UI are two distinctly different things and we have guidelines that deal specifically with navigation and interaction with the HTML document between section 4 and 5. Let's keep 3.1.1 
strictly to the container UI and have the rest of the guidelines to the document area as it was intended. 
Actually I think the part where it may be a little vague is with respect to the browser-specific controls, since some of those are only relevant to the browser in certain configurations, and it may not be very important to provide access to them. 
The User Interface includes the means by which the HTML document area is navigated, and parts of it selected or activated, etc. 
Perhaps we should split 3.1.1 
into two parts, one dealing with the browser-specific controls and one with the controls specific to the rendered content, in the same way as we have currently split techniques for dealing with the font colours and the font size, but I don't think so. 
Charles --Charles McCathieNevile - mailto:charles@w3.org 
W3C Web Accessibility Initiative - http://www.w3.org/WAI 545 Technology sq., Cambridge MA, USA Agree - I don't believe the group actually decided it was too vague. 
However, it became clear to me that by trying to apply the technique to the HTML document area, 3.1.1 
became too vague. 
3.1.1 was in a section talking about the the browser user interface (menus and toolbars) rather than the HTML document area. 
While you may want to lump it all together as part of the user interface, these are two distinctly different beasts and it was my understanding that the reason this group formed was to help solve problems in the HTML document area and that the browser UI/setup/documentation got lumped into peripheral items/techniques (like 3.1.1). 
What if an operating system that you are developing a user agent for does not support device independence? 
Does that mean the user agent must create new APIs to handle device independence? 
How does this impact touch screen Kiosks? 
How would this guidelines help them understand Kiosk developers what they need to provide for accessibility? 
Please provide revised working for review. 
Jon discussion. 
Jon Gunderson, Ph.D., ATP Coordinator of Assistive Communication and Information Technology Division of Rehabilitation - Education Services University of Illinois at Urbana/Champaign 1207 S. Oak Street Champaign, IL 61820 Voice: 217-244-5870 E-mail: jongund@uiuc.edu 
WWW:http://www.staff.uiuc.edu/~jongund 
