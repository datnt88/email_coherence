WAI UA Telecon for April 20th, 2000 Chair: Jon Gunderson Date: Thursday, April 20th Time: 2:00 pm to 3:30 pm Eastern Standard Time, USA Call-in: Longfellow Bridge (+1) (617) 252-1038 Agenda Review Action Items (see details below) Announcements none Discussion 1.PR#277: Use DOM level 1 , if DOM level 2 recommendation not ready in time 2.PR#273: Checkpoint 10.9: Why graphical controls only? 
3.PR#271: Checkpoint 4.7: Change to P2 since arbitrary repositioning not a requirement. 
4.PR#260: Guideline 1 checkpoint language unclear. 
5.PR#257: Difficult to know when a UA has conformed. 
6.PR#233: Checkpoint 7.6: What does "structure" mean here? 
7.PR#211: Do we need to say "alt equivs that have been marked up as such" in 2.1 and 2.5? 
8.PR#207: Interpretation checkpoint 2.1 Open Action Items 1.IJ: Draft a preliminary executive summary/mini-FAQ for developers. 
(No deadline.) 2.IJ: Propose split to the list. 
Identify why and issue of priority. 
3.IJ: Propose new 4.15 and 4.16 to list 4.CMN: Propose a technique that explains how serialization plus navigation would suffice for Checkpoint 8.1. 
5.DA: Send name of new organization to list that was mentioned by some from the US Census Bureau 6.DA: Review techniques for Guidelines 7 and 8 7.DA: Get confirmation that the numbers for checkpoint 4.5 make sense 8.DB: Get Tim Lacy to review G+ 9.DB: Review techniques for Guidelines 3, 4, and 11 10.GR: Look into which checkpoints would benefit from audio examples in the techniques document. 
11.GR: Review techniques for Sections 3.7 and 3.8 12.GR: Send to list screen shot of JFW Window list. 
13.MQ: Review techniques for Guidelines 9 and 10 14.MR: Send URI to Micrsoft's implementation of synchronized audio/video slowing down to the list 15.RS: Take notification of focus and view changes to PF as possible DOM 3 requirement. 
Jon Gunderson, Ph.D., ATP Coordinator of Assistive Communication and Information Technology Chair, W3C WAI User Agent Working Group Division of Rehabilitation - Education Services College of Applied Life Studies University of Illinois at Urbana/Champaign 1207 S. Oak Street, Champaign, IL 61820 Voice: (217) 244-5870 E-mail: jongund@uiuc.edu 
WWW: http://www.staff.uiuc.edu/~jongund 
WWW: http://www.w3.org/wai/ua AG:: Suspected typographical error -- I presume you do mean Eastern Daylight Time. 
The idea of a source view has clouded this discussion. 
Let me introduce some ideas about other, better techniques (that are just as easy). 
Technique #1: Anywhere one can issue a "where am I?" request, one can also ask "Whazzat?" 
This is a colloquial grunt for "what is this current item?" 
This request can be issued in case the description in response to "Where am I" was not clear, or if the user just wants to have a description of what is before them, as opposed to what is around them. 
This would result in some combination of a) the TITLE attribute of the currently-at element b) the role of this element (e.g. header, OPTGROUP label) for elements whose function is dominated by such a role. 
c) or [a derivative of] the element type and initial contents for vanilla elements like paragraphs and list items. 
I say "optionally a derivative of" because the best current practice is to say "link" rather than " a element" when one encounters an a element. 
This is a summary description of the currently-at object. 
A second "Whazzat" without any motion in between, or an "Info" or "About" request which may be issues regardless of a prior "Whazzat" or not, would get a more pedantic presentation of the element type and properties of the currently-at object. 
This would be optionally in synonyms for the literal text of the element type name and attribute name-value pairs, but would cover them all and the basic requirement would be met by a structured presentation of the element type name and the set of name-value pairs for attribute nodes associated with this current DOM node. 
Technique #2: There is a user-electable option that the local-context menu such as is accessed by a right mouse click in Windows show the current-node properties listed along with the action opportunities. 
The shipping default could still be that the contents of the context menu is only the actionable items. 
But there is an option to have this recapitulate the properties of the current context as well. 
There could even better be three levels of verbosity in the context menu, with the summary description of the current object as described above as the first-Whazzat response used in the intermediate model. 
Discussion: In the EZ package of interface techniques, model 2.0, there is help for all functions and it is layered, with more verbose help available on repetitions of the help command. 
EZ is a reasonably mature package of functions by now, so this is a pretty good general model for what the user needs. 
Reference: See the implementation guide at EZ Access Interface Techniques The "What's that" request seems like a necessary orientation safety valve when navigating structurally inside a space where the author assembling the space did not comprehent the extreme locality of viewport of the audio browser. 
Having it expandable to cover all attributes is an easy way to ensure coverage of all information, wherever it is lurking, without drowning the user in syntax. 
Another way to see how basic this capability is is to look at the VRML browse model by comparison. 
Inside an HTML page, hierarchical navigation is navigation in a virtual jungle gym where the bars of gym are in the comfortingly regular pattern of a tree. 
In VRML there are two primary modes of interaction: roam and inspect. 
What we have talked about as structural navigation is the 'roam' mode for the virtual-tree navigable space. 
But for document browsing, we need an 'inspect' partner to go with the 'roam' functions of the hierarchical navigation; both so the user does not get lost, and so they have access to the content that is meted out through a localizing filter controlled by the roaming results. 
Just as some people want to read the footnotes and some do not, the information in the markup language attributes is "normally hidden" content that users should have elective access to. 
This kind of "drill-down inspection" method is the most primitive way to get to the leaves of the information set (for which the nodes identified in the DOM1 Core are a sufficient index). 
On the other hand, only a human can tell if the attribute values are human-usable or not. 
The algorithms in the browser have no reliable formal rules that tell what is human-understandable; only what is machine-understandable. 
The way markup languages are used, the attributes are not just one or the other. 
They may have utility in both uses. 
The author cannot be fully trusted to understand the needs and abilities of the user. 
So we stick to letting the author determine what is _normally_ hidden, but not what is accessible-on-request. 
This kind of local "Whazzat?" 
access will let the user gain measured access to the attributes. 
They can that way glean whatever mnemonic or heuristic value is in them without being drowned in either syntax or data. 
Relying on the user's stylesheet to present all information in a processed form is the route that is too complex or cognitively-demanding to be considered realistic. 
Simply exposing the data that is in the document that the styles, if available, will interpret, is going to be more comprehensible to more people, and it is easy for the User Agent to do. 
It is clearly advantageous to the population of partially-impaired people (our large numbers group, including seniors) if this capability is carried out into the User Interface without depending on the application of assistive technologies to expose the full content. 
But it is a policy decision to figure out if this should be "required" through the built-in UI. 
I am trying to clarify the relevant techniques and their UA costs and UI performance in this note, not the ultimate policy question. 
As an example of an attribute which is clearly "for machines" and should not be presented in literal text form exept as a last resort, consider any attribute of type IDREF, such as the FOR attribute on LABEL elements in HTML4. 
Here the format semantics is clear, the value of the attribute is a reference to another element in the same document. 
In presenting this information to the user, the form "Reference to [element summary]" is clearly supported by the definition of the format, and clearly easier to understand than the text of the ID of the referenced element. 
In this case we can specify a formatting of a processed version of the attribute text which is guaranteed to capture all the information in the attribute. 
But these cases are rare. 
If the ID given does not match an element in the document, then the document is broken and the text of the broken ID reference should be provided to the user in lieu of a summary description of the referenced element. 
Machine-interpretable attributes have machine-generated improvements on the text value of the attribute, as how to present the associated property to the user. 
The property still needs to be reported, but it may be amenable to an automatic upgrade in understandability, as in this case. 
This is the basic philosophy: the whole infoset as catalogued in the DOM is the content of the document. 
The user agent may or may not have access to friendlier ways to display this content than just the text values in the structure of the markup language. 
The text values are the floor above which one can go with improvements, but below which one should not fall. 
And it should all be reachable somehow. 
All those attributes are there to encode information, regardless of whether the default view presents them as text or expresses the information as properties on some of the rest of the content. 
Al see comment at MN below: MN: I don't understand the difference in the above two sentences and/or scenarios ??? 
