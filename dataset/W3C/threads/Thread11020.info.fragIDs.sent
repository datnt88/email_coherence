The more I read about BOS, ilink storage strategies, multi-pass XML parsing etc. the more I see a tension between client-side and server-side implementation of XML processing. 
I mean, an XML document - as authored - might perhaps have ilinks spread willy-nilly but that does not mean it has to be served to the client in that form. 
Equally, AF processing could be organised for maximum authoring convenience in the "raw" XML document and then SPAMM'ed to attributes before 
the client sees it. 
The disadvantages of server side processing have already been discussed on this list. 
The advantages, in terms of simplicity, for XML browser tools however, would surely be significant. 
What I am trying to get at is that XML docs as seen by the client can either be "raw" XML or "cooked" XML that simplifies (and speeds up!) client-side implementation. 
Cooked in terms of AFs. 
Cooked in terms of BOS. 
Cooked in terms of ... The transition from raw to cooked - if done at the server side - does not complicate the client. 
Simple client - more complex servers. 
Having said 
that, BOS (I like DJD's term "document working set") or multiple parsing of XML docs, will be, IMO, kinda tough on the client end. 
Analogies abound. 
The first that springs to mind is the difference between a networked database application that downloads records looking for matches and one that sends SQL to the server and retrieves matching records only. 
Whether or not cooked XML is an option seems to me to depend on what client are advised to do with XML docs over an above browsing. 
Are they intended to be thrown away NC style or harvested once for local re-use? 
For throwaway docs, cooked is fine. 
For harvesting, cooked is perhaps, far from fine. 
Sean Mc Grath (Member of the XML-KISS iniative). 
Simple browsers will be useless without any data to feed them. 
Only Gavin has emerged to defend the notion that the server infrastructure of the WWW is likely to change significantly to accomodate XML. 
I don't believe that enough specialized servers (or custom cgi-scripts, for that matter) will be deployed to make XML a going venture. 
For someone who wants to deploy XML in a restricted environment (like Sun's documentation viewers, for instance) it will be easy to create the custom server, and simple client to talk to it. 
But if we want to affect the WWW as a whole, we need to slot XML into as much of the current infrastructure as we can, as a data format like all the others out there, so it can win on its own merits. 
I see nothing that prevents a server from providing custom normalized data streams or fancy address resolution as desired, even if we define 
things in terms of nominal client processing. 
But I see real problems with wide XML acceptance if we make definitions that require specialized server just to put up XML documents. 
I'm also not convinced that the problems we are proposing that clients be able to solve are very difficult. 
To get XML established we need just one of the two big browser vendors to devote their (quite massive) resources to a client implementation. 
The other will then probably have to 
follow suit, and we will be in good shape. 
Even the most ambitious proposals we've made are not beyond Netscape and Microsoft's reach, I think. 
If we factor in the 3-10 significant server platforms as well, we have a real opportunity to slow XML acceptance. 
Why is it hard to keep more than one abstract syntax tree around? 
sounds like a hash table from docnames to pointers to me. 
This is a misleading analogy, If only because of the difference in scale factors between the database example (frequently 1000s-100,000s of records) and the typical document examples (I imagine 1-5 documents as the typical numbers of documents parsed in parallel on almost any reasonable scenarios). 
We're not talking about search, but essentially an author guided form of pre-caching. 
Equivalents to ilink are a standard staple of proposals to extend the web -- I've seen at least 3-5 in the last year and a half, and I don't spend any time looking for them, either. 
Seems to me that the current client-cache model is already "harvesting" and that the XML BOS stuff fits into that pretty nicely. 
But note that nothing prevents a server from cooking documents now (and people do) or in the future, reagardless of how we define things. 
I think the extra work will be worth it because of the power that separately stored links can give -- the other things strike me as easy once you do the work to handle separate links at all. 
For XML to fly at all, the code for all this processing has to be written by someone, anyway, whether this happens at the server, or the client doesn't seem to make that much difference, but... 
I don't see any technical reason that we _have_ to move things to the servers (or that failing to do it now prevents us from doing it later, once XML is regarded as essential by the whole world). 
And I see real practical drawbacks to requiring new code to be deployed on servers _as well_ as clients. 
KISS is good, but if we can't offer benefits over HTML, we may look stupid, since HTML has already got simple all wrapped up (and deployed). 
We already have significant benefits to offer for docuemnt representation, but I think we should offer linking benefits to match them... -- David I am not a number. 
I am an undefined character. 
David Durand dgd@cs.bu.edu \ david@dynamicDiagrams.com 
Boston University Computer Science \ Sr. Analyst --------------------------------------------\ http://dynamicDiagrams.com/ MAPA: mapping for the WWW \__________________________ 
If we had the option of having a smart server universally deployed, we could have made some radically different decisions in the last part of our design of XML. 
RS/RE would irrelevant, because they could be stripped in the server. 
End-tag GIs could be omitted because they would be irrelevant in the communication between two computer processes. 
etc. etc. 
We have always thought of XML as just another MIME type that does not require a special server and should continue to do so. 
If XML becomes the dominant mime type, the king of the mime hill, then we can impose our vision of the relationship between hypermedia client and server at a later date. 
We could even express that vision now: as long as it is optional. 
Paul Prescod 
As I wrote in an earlier message, I doubt that these companies will build XML browsers from scratch. 
I believe they will *extend* HTML, rather than implement XML. 
That is what many users will expect, and what is simplest to implement. 
XML has to co-exist with HTML. 
There are two ways for that to happen. 
One way is that an XML browser is a Panorama-style helper app that gets launched when a non-HTML doc is being fetched. 
Netscape and Microsoft can leave that kind of implementation to others. 
The other way is to create a "native" XML browser, complete with HTTP client. 
But what happens when this native XML browser fetches an HTML doc? 
It has to recognize the semantics of HTML. 
That means the code for dealing with (for example) FORMs and APPLETs has to be built in. 
Now what happens when the XML browser fetches an "XML document" in which the user's intention was to add a few elements to the HTML tag set? 
Does the browser treat the FORM and APPLET tags as generic markup and look for a definition of these tags in a stylesheet? 
If so, how does the user indicate that the default behavior found in HTML is what they want - and in fact are expecting to happen without any additional effort on their part? 
The simplest approach for Netscape and Microsoft is to say: "Our browsers will handle existing tags as they currently do. 
Users, however, can *extend* the base set by defining new tags through a stylesheet mechanism that we provide." 
So I don't see looking to Netscape and Microsoft as the folks who make XML - as currently defined - happen. 
I believe Jon launched this effort largely in fact to head off the foregoing sort of scenario. 
But we also need to *include* the benefits that HTML *already* provides. 
One 
of XMLs main target audiences is supposed to be publishers. 
Publishers commonly use a FORM to request input from users. 
Unless the behavior associated with an HTML FORM can be assumed, a publisher would have to go back and redefine - somehow - the semantics associated with that element for use with an XML browser. 
Since FORMs are used to input queries, they can be considered as a type of hyperlink and so support for them should be included in this discussion anyway. 
I believe though, that support for other HTML semantics (e.g., SCRIPT, OBJECT, APPLET - elements whose be behavior can't be replicated with just a stylesheet) will need to be included as well. 
In other words, an XML browser would default to the HTML-defined content model 
and behavior associated with these elements. 
If you want something else, you have to *override* that behavior, either through a stylesheet or by specifying compliance with an architectural form. 
Regards, Ralph E. Ferris Project Manager, Electronic Publications Fujitsu Software Corporation 
I am hoping that MS participation in this group, and their desire to hotfoot Netscape with standards means that IE will implement XML support -- it's sure easy, and they already have a start on stylesheets. 
Following is a long list of questions amounting to: "How do I easily start with current HTML capabilities, and use XML instead, getting additional capabilities without forgetting what I already know about HTML tags?" 
The answer is that you download the XML version of the HTML DTD, and the default stylesheet that implememts those features. 
Anything you want to leave unchanged, you leave unchanged, and anything you want to change, you change. 
Thus XML does not have to have HTML tags built-in, but we can still make the HTML- XML transition easy. 
The points about form and applet semantics are very good, however. 
We must not forget that these must fit into our stylesheet language somehow. 
But we should stay away from namespace pollution, if we can possibly manage it, though. 
Raging agreement here -- at least as regards goals... 
As I said above, I think this is best accomplished by modifying a working example (the HTML in XML DTD). 
-- David I am not a number. 
I am an undefined character. 
David Durand dgd@cs.bu.edu \ david@dynamicDiagrams.com 
Boston University Computer Science \ Sr. Analyst --------------------------------------------\ http://dynamicDiagrams.com/ MAPA: mapping for the WWW \__________________________ 
I don't consider my proposal to be "namespace pollution." 
I consider it to be method over-riding, in the manner of object-oriented programming. 
The HTML "tags" I mentioned - FORM, APPLET, SCRIPT, OBJECT - are much closer conceptually to method invocations that they are to "conventional" SGML elements. 
I don't believe their behavior can be defined in a stylesheet - unless the stylesheet has a string saying, in effect, "Default: HTML." 
One solution is to define these tags as architecural forms, and make these architectural forms part of a default set that's used by XML. 
The limitation in using architectural forms is that they only allow behavior to be expressed as "conventional comments." 
(SMSL is supposed address this, but SMSL isn't here yet). 
Pre-defined interfaces with over-rideable methods are what make component software work. 
Call these "component DTDs." 
Regards, Ralph E. Ferris Project Manager, Electronic Publications Fujitsu Software Corporation 
Or call them virtual interfaces, or IDLs, or whatever. 
This issue has been raised several times on the list. 
In MID, we set up the xeno element types. 
For XML, we could use arc forms. 
Whatever: o Should XML spec an API? o Should we adopt the object/embed conventions? 
o OLE/COM or Corba? 
Kick all anyone cares to, but OLE/COM works very nicely in VB4. 
An Active-X control is wonderful thing. 
It would be reasonable work to use the VB tree control to do the sorts of things P. Murray-Rust is doing for CML/XML. 
We seem to be dancing around this issue: no helm control, mr sulu. 
When will draft proposals for the hyperlinking of XML be available? 
All I have seen so far is Eliot's proposal. 
len bullard 
This sounds like a good approach, as long as the XML spec also mandates some form of declaration to enable specific architectures. 
IOW, predefined element types are OK, but 
we should make sure that documents are only interpreted with predefined semantics if the author explicitly asks for that to happen. 
This may not seem like a big deal if there is only one predefined element type ("use any GI you like, as long as it's not ALINK") but if, as I suspect, there end up being many different XML sub-architectures each with its own collection of forms, protecting authors from unforeseen nameclashes will be important. 
--Joe English jenglish@crl.com 
As I wrote in an earlier message, I doubt that these companies will build XML browsers from scratch. 
I believe they will *extend* HTML, rather than implement XML. 
That is what many users will expect, and what is simplest to implement. 
1. 
It's also the simplest to sell to the users: "look, this is HTML with bells and whistles on"... XML has to co-exist with HTML. 
There are two ways for that to happen. 
One way is that an XML browser is a Panorama-style helper app that gets launched when a non-HTML doc is being fetched. 
Netscape and Microsoft can leave that kind of 2. One way would be if such XML browsers started that way, as a demonstration of the possibilities, and grew into fully-fledged HTTP browsers so good that they made MSIE and Netscape look sick :-) implementation to others. 
The other way is to create a "native" XML browser, complete with HTTP client. 
But what happens when this native XML browser fetches an HTML doc? 
It has to recognize the semantics of HTML. 3. It switches to "rough-parse" mode, hacks what sense it can out of such markup as there is, and puts up a nice little icon that says "non-HTML file", and hands it _to_ MSIE or Netscape for display :-) That means the code for dealing with (for example) FORMs and APPLETs has to be built in. 
4. The above scenario avoids that problem. 
Now what happens when the XML browser fetches an "XML document" in which the user's intention was to add a few elements to the HTML tag set? 
Does the browser treat the FORM and APPLET tags as generic markup and look for a definition of these tags in a stylesheet? 5. Yep. 
If so, how does the user indicate that the default behavior found in HTML is what they want - and in fact are expecting to happen without any additional effort on their part? 
6. 
By the style-sheet definitions for these elements being absent (or indeed the stylesheet being absent). 
In which case the XML browser either does the form using default formatting (if capable) or sticks up the above flag and hands it to a non-XML browser. 
The simplest approach for Netscape and Microsoft is to say: "Our browsers will handle existing tags as they currently do. 
Users, however, can *extend* the base set by defining new tags through a stylesheet mechanism that we provide." 
7. This is probably what they will do anyway, whether or not we define XML. 
So I don't see looking to Netscape and Microsoft as the folks who make XML - as currently defined - happen. 
8. Right. 
GOTO #2. 
But we also need to *include* the benefits that HTML *already* provides. 
One of XMLs main target audiences is supposed to be publishers. 
Publishers commonly use a FORM to request input from users. 
Unless the behavior associated with an HTML FORM can be assumed, a publisher would have to go back and redefine - somehow - the semantics associated with that element for use with an XML browser. 
Since FORMs are used to input queries, they can be considered as a type of hyperlink and so support for them should be included Ping. 
Form _submission_ is a type of hyperlink. 
I'm not sufficiently well up in hypertext theory to say if the data transferred can be considered as "part of" a hyperlink. 
in this discussion anyway. 
I believe though, that support for other HTML semantics (e.g., SCRIPT, OBJECT, APPLET - elements whose be behavior can't be replicated with just a stylesheet) will need to be included as well. 
In other words, an XML browser would default to the HTML-defined content model and behavior associated with these elements. 
If you want something else, you have to *override* that behavior, either through a stylesheet or by specifying compliance with an architectural form. 
But I thought the point about AFs was that -- among other things -- they can be used to define the semantics of specific [read: expected] actions which can be associated through a DTD with certain elements. 
So AFs of class "info-to-be-sent-somewhere" or "element-to-be-filled-by-received-info" (aka transclusion, *gasp*) or "perform-processing" (aka PI) can be mapped to FORM, ISINDEX, APPLET, EMBED, OBJECT, etc. You're right, though: the XML browsers will have to exhibit smarts about what to do with streams of data that walk like HTML and quack like HTML. 
///Peter 
A formalism for declaring a document's derivation from an architecture or architectures is defined in the forthcoming HyTime TC (largely as documented for the architecture processing support in the latest releases of SP). 
Unfortunately, the full form of these mechanisms depend on the use of data attributes ( !ATTLIST #NOTATION archname ... ), which means that XML documents cannot use the full form unless we add notation attributes to XML. 
However, the minimal part of the declaration simply uses a processing instruction to indicate which architectures are in use, e.g.: !DOCTYPE MyDoc [ ] Where the name "ArcBase" is effectively normative as XML doesn't allow SGML declarations, which is where you would change the name of the PI (don't you love indirection?). 
A full architecture processor then expects to see notation declarations corresponding to the architectures named (e.g., !NOTATION MyArc PUBLIC "..." ) with notation attributes defining the document-specific values for the architecture control attributes. 
The architecture control attributes are needed to do renaming, specify options used, and so on. 
However, since these attributes can all have default values, you could always derive an XML-specific version of your architecture that set the default values to something appropriate for XML use, following the XML philosophy that no options are good options. 
Thus the notation attribute declarations would be superfluous because the architecture engine for each such architecture would know what its base default values are because they would be built in. 
Thus, I could have: !DOCTYPE MyDoc [ !NOTATION XML-Link PUBLIC "-//W3C::SGML ERB//NOTATION XML Link Architecture//EN" !NOTATION XML-MyArc PUBLIC "-//ME//NOTATION My Architecture, XML Profile//EN" !NOTATION XML-InfoMaster PUBLIC "+//ISBN 0-189773::IBM//NOTATION InfoMaster Architecture, XML Profile//EN" ] It would conform to the ISO/IEC 10744 requirements and fit within the XML constraints. 
The notation declarations could be considered superfluous in this case as the PI is sufficient to identify the architectures as long as the names used are normative. 
In the general case, you can use whatever name you want because the architecture is actually identified by the external ID of the notation you declare. 
However, we tend to expect the notation names to be used consistently. 
Or, you could consider the names in the ArcBase PI to imply notation declarations with omitted system identifiers if no notation declaration is present, at which point things like catalog lookup come into play and you could put the name-to-public ID mapping in an external catalog if necessary (which it's probably not 99.99% of the time). 
Cheers, E. W. Eliot Kimber (eliot@isogen.com) 
Senior SGML Consulting Engineer, Highland Consulting 2200 North Lamar Street, Suite 230, Dallas, Texas 75202 "Rats in the morning, rats in the afternoon...if they don't go away, I'll be re-educated soon..." --Austin Lounge Lizards, "1984 Blues" 
Sorry, but I'm going to have to blow the whistle on this thread. 
Our charter as a W3C activity is to develop a language for a class of applications that HTML isn't designed to handle. 
It is *not* to design a replacement for HTML or to extend HTML (certain unfortunate statements in the trade press to the contrary notwithstanding). 
As some people have put it, we are working on SGML--, not HTML++. 
When we get done, we will have a media type text/xml that will be used for certain things on the Internet and a media type text/html that will be used for certain other things on the Internet. 
Under the current charter for this activity, these media types are not competing in the same problem space. 
All things change, and in the fullness of time, our charter may expand to allow the discussion of XML as an alternative to HTML (or even allow us to discuss ways in which they might fruitfully interoperate). 
But under the current terms of our activity, discussions like this one are out of order. 
If you wish to continue it, you will have to do it on some other list. 
I will be pleased to provide the email addresses of the current WG members (as I have on a number of occasions in the past) if anyone wishes to form unofficial lists for the discussion of topics that are outside the current scope of this activity. 
Jon 
