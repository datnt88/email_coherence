I've put up a server that (I think) understands HTTP/1.2 features keepalive and Transfer-Encoding. 
(Because I haven't seen an official copy of the forthcoming draft, I can't be sure.) It's at and serves content identical to the normal www.research.att.com server. 
Here's what you can try: 1) If there's a Connection: keepalive request header, the server will hold the connection open for 10 seconds. 
2) If - there's a Connection: keepalive request header, - the protocol version in the Full Request line is HTTP/1.2, and - the request is a GET on a CGI the server will use Transfer-Encoding: chunked to send the output. 
Try 3) The URL http://www.research.att.com:8000/digest-test refers to a resource that is protected by Digest authentication. 
The user is "protected". 
Password is "try-me-out". 
The nonce expires after five minutes. 
Try it out. 
Bug reports are welcome. 
Dave Kristol 1) If there's a Connection: keepalive request header, the server will hold the connection open for 10 seconds. 
This might be a bit short. 
My trace-based curves show a fairly sharp "knee" in mean requests/connection at somewhat higher timeouts, around 1-2 minutes. 
I assume you're closing idle connections as necessary when your total connection count exceeds a threshold. 
If not, then the 10-second timeout is probably necesary. 
I can't remember if we've discussed this on the group-wide mailing list, but I've suggested to some people that the keep-connection header include the IP address of the client or proxy that generates it. 
This ensures that requests made via an old-style proxy are not help open (which would effectively delay the response). 
It does require that proxies supporting the persistent-connection model have to rewrite this header, but that seems relatively benign. 
-Jeff As you mentioned in your paper there are two sources of such requests: requests for inlined images and subsequent hits on links by a user. 
I'm shooting for the first batch, I admit. 
In the future, with authentication and payment additions to HTTP, the short keepalive will address a larger proportion of the same-server traffic. 
Do you have any measurements for which of the two sources produces more of the same-server hits? 
Dave Kristol There's a slight syntactic difference between your implementation and the one we've done between Spyglass and NCSA. 
Just as an FYI: here's a copy of a mail I sent recently which explains how our implementations work. 
I'm also exchanging mails with Alex Hopmann to try and resolve the syntactic differences there as well. 
Both your implementation and Alex's draft specify a multipart response as an alternative to an accurate Content-length. 
That's fine -- we just have implemented it yet. 
Here's how current implementations work. 
NCSA Mosaic 2.6, NCSA HTTPd 1.5, and Enhanced Mosaic 2.1 all support this and interoperate together, and all implementations were done independently. 
We didn't share code with NCSA at all. 
Information on the NCSA implementation is at If the client wants the connection kept alive, it sends the following header with its request: Connection: Keep-Alive If the server recognizes this and wants to leave the connection open, it sends back: Connection: Keep-Alive It may only send this header back if the it also sends back a Content-Length header which the client may assume to be accurate. 
If the connection is left open, then the client may send more requests along the same connection. 
Any time the Connection: Keep-Alive header is sent and received back, then the connection should stay open. 
The NCSA 1.5 server implementation also sends back Keep-Alive: timeout=n, max=m but Enhanced Mosaic 2.1 ignores these. 
Eric W. Sink Senior Software Engineer, Spyglass eric@spyglass.com 
All opinions expressed here are my own. 
Okay, I changed my server to behave as below: I'll accept this from HTTP/1.0 clients. 
I'll return this. 
Right. 
My variant remains: if it's CGI output and client says protocol is HTTP/1.2, I'll chunk the output (Transfer-Encoding: chunked). 
Okay. 
But there's a potential problem here. 
If the server sends the response header, then encounters some kind of problem, it may be forced to close the connection, thus "lying". 
I'll add this later. 
Not there yet. 
Dave Kristol Fine. 
I forgot to mention: Either client or server can close the connection when necessary, with the other side being required to cope. 
Eric W. Sink Senior Software Engineer, Spyglass eric@spyglass.com 
All opinions expressed here are my own. 
As you mentioned in your paper there are two sources of such requests: requests for inlined images and subsequent hits on links by a user. 
I'm shooting for the first batch, I admit. 
In the future, with authentication and payment additions to HTTP, the short keepalive will address a larger proportion of the same-server traffic. 
Do you have any measurements for which of the two sources produces more of the same-server hits? 
I did not break down the traces by file name, so I don't have explicit results for inlined images vs. subsequent clicks. 
But in the paper I plot "requests arriving for already-open connections" vs. idle timeout. 
Generally, a large fraction of the gain (almost half) comes with timeouts greater than 10 seconds. 
This implies either of two things: (1) Many clients were delaying ca. 10 seconds before retrieving inlined images. 
(2) there were a lot of subsequent hits in the 10-100 second range. 
Hypothesis #1 seems rather unlikely, so I'd bet on #2. -Jeff If the connection is left open, then the client may send more requests along the same connection. 
Any time the Connection: Keep-Alive header is sent and received back, then the connection should stay open. 
Okay. 
But there's a potential problem here. 
If the server sends the response header, then encounters some kind of problem, it may be forced to close the connection, thus "lying". 
The basic rule for a persistent-connection HTTP has to be that either client or server (or proxy, for that matter) is allowed to close any connection at any time. 
This isn't "lying", this is life. 
The word "should" (as in "should stay open") in IETF-speak usually has the meaning "do this unless you cannot". 
I think we need to word the spec using "may"; neither side can compel the other to keep a connection open. 
-Jeff ] From: Jeffrey Mogul mogul@pa.dec.com ] Subject: Re: HTTP/1.2 stuff: try it out! 
] Date: Wednesday, August 23, 1995 1:56PM ] But in the paper I plot "requests arriving for already-open connections" ] vs. idle timeout. 
Generally, a large fraction of the gain (almost ] half) comes with timeouts greater than 10 seconds. 
This implies ] either of two things: ] (1) Many clients were delaying ca. 10 seconds before retrieving ] inlined images. 
] (2) there were a lot of subsequent hits in the 10-100 second ] range. 
] Hypothesis #1 seems rather unlikely, so I'd bet on #2. 
A third hypothesis -- that the previous entity requested took more than 10 seconds to transmit thru the network, thus delaying the arrival of the following request by that amount. 
Is this taken into account by the timeout mechanism in your implementation -- i.e., does the timeout period start when the TCP stack returns to the server from the server's send() call, or when the last byte leaves the server? 
Paul 
