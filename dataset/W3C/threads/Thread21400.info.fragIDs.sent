Hello, I am looking for an annotation system for adding annotation to multimedia documents and I wonder if annotea may be suitable for this task. 
The protocol specification only discusses annotating HTML documents and uses XPointer for the a:context property. 
Why is this defined in the protocol? 
Is this this property restricted to XPointer or may I use also another method instead (e.g. timestamp for video)? 
Am I right, that on the other side it's also possible that the Annotation itself may be something different than a XHTML document, e.g. an audio file? 
Thanks, Daniel 
"Daniel Eschle" d.eschle@web.de 
wrote in message news:b19ior$o1p$1@main.gmane.org... 
Yes, I already send a few annotations of images to an annotea service where the body isn't a html document, but another RDF document (I keep the bodies seperate) at the moment I just say the context is the whole image (the seperate RDF doc provides more context info) but yes you could provide any type, my snufkin interface is also happy with other types providing a link to the Annotation if it's not a type it can render. 
Jim. 
Hi Daniel, you can use any kind of pointer you like for the annotation in principle - it isn't specified in the protocol. 
At the moment Amaya expects an annotation to be an Xpointer, so may not understand any other kind, but examples of what is currently possible include a plain text description or some RDf describing what you are pointing to. 
In particular it is possible to annotate an SVG image using an Xpointer, or a 
SMIL file. 
So you could take an audio file, provide a SMIL wrapper that 
effectively marks particular time points, and then use Xpointers to those points in the SMIL as the context of your annotation. 
(Amaya doesn't play audio files, but you could use some other software to fetch the annotation and then give you a user interface to work with it). 
I believe that work has been done on annotating parts of an SVG image using Amaya, and that this is possible, but I haven't yet checked it carefully. 
Remember that the protocol is in development so details may change. 
But I think it will suit what you have described (I have done some thinking about how to use it for similar things, but not yet had time to do it, let alone write it up as examples). 
Note also Marja-Riitta Koivunen's post to this list on extending the context property: cheers Charles McCN 
Post: 21 Mitchell street, FOOTSCRAY Vic 3011, Australia or W3C, 2004 Route des Lucioles, 06902 Sophia Antipolis Cedex, France 
Hello Daniel, You have an interesting project. 
There are two points to be solved: 1. Have some kind of expression identifying the section (instant, region,. 
..) of the multimedia presentation that has been annotated. 
2. Storing this information in the annotation. 
For 1, we haven't done any such work ourselves. 
You could try to inspire yourself from SMIL or from the Timed Text WG, which Dan Brickley cited not so long ago[1]. 
For 2, the current Annotea RDF schema has a property called context which is used for binding an annotation with a document. 
The value of this property is a literal. 
So far, we have only been using XPointers. 
Marja has started worked so that the semantics of the context can be better specified. 
I see this as having any kind of context that can be described with a string and an extra property pointing to the place that defines that particular context semantics. 
We could then use XPointer, an SVG template for graphics, something that points to a given instant of an audio or video stream, or something for multimedia documents. 
The work on the extension has just started. 
Marja published a first draft not so long ago[2]. 
Comments are welcome. 
Hope this answers your questions. 
[1] http://lists.w3.org/Archives/Public/www-annotation/2003JanJun/0013.html [2] http://lists.w3.org/Archives/Public/www-annotation/2003JanJun/0010 -jose 
