During the ERB meeting of 5 June 1997, the ERB voted unanimously to change the rules for white-space handling in section 2.8. 
Present: Bosak, Bray, Clark, Connolly, DeRose, Hollander, Magliery, Maler, Paoli, Sperberg-McQueen, Wood; absent: Kimber. 
In particular, the paragraph An XML processor which does not read the DTD must always pass all characters in a document that are not markup through to the application. 
An XML processor which does read the DTD must always pass all characters in mixed content through to the application. 
It may also choose to pass white space occurring in element content to the application; if it does so, it must signal to the application that the white space in question is not significant. 
will be changed more or less as follows: An XML processor must always pass all characters in a document that are not markup through to the application. 
An XML processor which reads the DTD must distinguish white space in element content from other non-markup characters, and signal to the application that white space in element content is not significant. 
Rationale: eliminating the optional behavior of suppressing white space in element content eliminates the potential inconsistency among XML processors in the counting of pseudo-elements (this topic came up as a digression from the discussion of pseudo-element counting for CHILD, NEXT, PREV, etc.). 
Since the Technical Corrigendum to 8879 will provide a KEEPALL keyword for the SGML declaration which will specify that all white space should be passed to the application, the exception for element content is no longer necessary for the sake of compatibility with 8879. 
Downside: the new rule does mean that existing SGML parsers will need to be modified to retain all white space (e.g. using a run-time switch), but the parser makers in the group considered this to be a relatively simple surgery to perform on existing code. 
That afternoon, when this was announced at the joint conference of the Association for Computers and the Humanities and the Association for Literary and Linguistic Computing, David Durand was crowned with a victor's wreath. 
At least, he would have been if Kingston, Ontario, had had any olive trees. 
He settled for a paper crown instead. 
Other decisions bearing not on XML-lang but on XML-link will be reported separately. 
-C. 
M. Sperberg-McQueen Irrespective of the merits of the decision, which it will take some reflection to absorb, please define the technical terms for all the flavors of XML processors the spec defines and use *only those technical terms* elsewhere in the spec (just like the BNF). 
That means that "An XML processor which reads the DTD" should be emended to "a validating XML processor", "any XML-compliant processor", or "any XML processor", depending on what is really meant. 
The target audience for this spec shouldn't have to figure out what kind of XML processor reads DTDs, because half the time he'll get it wrong. 
Regards, Terry Allen Electronic Publishing Consultant tallen[at]sonic.net 
Davenport and DocBook: http://www.ora.com/davenport/index.html T.A. at Passage Systems: terry.allen[at]passage.com 
On Tue, 10 Jun 1997 23:38:58 -0400 (EDT) Terry Allen said: Point taken. 
I had thought the following was clear enough from the spec, but perhaps it's not: - XML is designed to allow processors to skip reading the DTD, if there is a DTD and they choose to skip it; if the RMD in the XML declaration is correct, such processors can reliably know whether skipping the DTD will have any effect on the grove they produce. 
- Validating processors must always read all the DTD. - Non-validating processors need not read the DTD. - A processor may read the entire DTD and still not be a validating processor (I might read the entire DTD so as to be able to produce the absolutely correct grove, and still not get around to checking against content models) -- such processors are unlikely to be very very common, but that's irrelevant to the fact that they are logically possible and should be legal. 
So the difference between processors which read the DTD and those which don't is not validating vs. non-validating, and not conformant vs. non-conformant. 
It's just processors which read the DTD vs. those which don't. 
The former is a superset of validating processors. 
-C. 
M. Sperberg-McQueen [... concerns which I share deleted ...] I think there is a real danger of this. 
Agreed. 
But if they do/not they may 'pass different output to the application'. 
Is this optional behaviour intended? 
The MythicalGradStudent may not have got round to writing a validator in the week, but can still produce the grove :-) Under '5. Conformance' the spec says: 'Conforming XML processors fall into two classes: validating and non-validating'. 
This implies only two modes of behaviour. 
But the 'non-validating' now fall into at least two subclasses 'those that read the DTD and those that do not'. 
And there is ample scope for subclassing in those which 'read the DTD' and vary in action according to whatever the MSG author thinks is reasonable - they are only allowed a week to work it out. 
What does a reader/non-reader do with: !DOCTYPE FOO [ ] Although it might seem unreasonable, a non-reader could fail to read the entity declaration and presumably (4.4) its only option is to throw an error - i.e a non-reader has ipso facto a lower conformance level than a reader. 
In similar fashion the non-reader will fail to insert the BLORT attribute in the output - is this really acceptable behaviour? 
In fact I can see little justification for non-reading processors at all. 
The only justification could be that the MGS couldn't work out how to implement PEs, but I gather that is not longer a problem for the MGS. 
P. Peter Murray-Rust, domestic net connection Virtual School of Molecular Sciences We are still struggling with this on xml-dev. 
May I suggest an alteration to the parsing/reading philosophy? 
2.10 rightly identifies three areas where knowledge of the DTD is required to pass 'correct' output to the application. 
#1 is default attribute values; #2 is entities. 
*IF* these are declared in the DTD I cannot see that it's reasonable for a processor/parser to ignore them. 
The spec states that RMD="NONE" is allowed only if such declarations don't exist; otherwise it's an error, but a non-DTD-reading parser (or one blindly following NONE) can never flag this error. 
Therefore the only course that seems reasonable to me is: All XML processors must read the DTD(s) The problem seems to arise with #3, the analysis of whitespace :-( The appropriate treatment of this depends on: "reading and analysing the element content" and I suggest that a phrase like this should is what is intended by "reads the DTD". 
(I think it only occurs in this context). 
(Whether it is possible to analyse the whitespace problem without validating the content at the same time anyway I don't know.) The consequences of this - if accepted - are that all parsers have to be able to deal with any construct in the DTD, including PEs :-). 
So my final analysis - shoot it down - is: 1. all parsers must read the DTD or DTDs if present and process them including: - substitution of parameter entities - handling of multiple ATTLIST declarations 1a. all parsers must add default attributes to start-tags in the document 1b. all parsers must expand entities in the document as in 4.3.1 and 4.3.2 2. a parser is validating or non-validating. 
2a. a non-validating parser may/must/must_not[1] analyse an element's content and may/must/must_not apply the current rule for whitespace insertion or deletion. 
3. [2] 4. [3] [1] to be determined by the ERB [2] error recovery in validation of a WF document, to be determined by the ERB [3] error recovery in WFness of a non-WF document, ditto. 
P. Peter Murray-Rust, domestic net connection Virtual School of Molecular Sciences [Peter Murray Rust] If XML processors must read the DTD(s) then XML'97 == SGML'97. 
(Tongue semi-wedged in cheek). 
The statement "XML is easy to parse" is getting increasingly unbelievable. 
Sean Sean Mc Grath sean@digitome.com 
Digitome Electronic Publishing 
