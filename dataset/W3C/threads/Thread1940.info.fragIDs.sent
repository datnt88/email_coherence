I was very pleased to see the new HTTP draft; it's a major improvement on previous versions! 
Here are some comments on the new draft which I hope will be useful. 
I am writing these from the perspective of an implementer of software for a reasonably general-purpose HTTP server, so I am especially looking for a definition of the HTTP which a) allows a server to be implemented using the definition (and referenced documents) and specifically without reference to specific clients or other implementations 
b) makes it absolutely clear what is required for a server to be stated as conforming to the definition. 
Most of these comments therefore seek clarification in these two areas. 
I'm sorry I won't be able to attend the IETF meeting next week--a long-standing commitment has me on the wrong coast of the USA. 
Mike Cowlishaw IBM Fellow, IBM UK Laboratories, Winchester, UK 
2.1 The '#' rule implies that no whitespace is allowed after (or before) the commas in a list. 
Is this correct? 
For example, in the example in 7.1 there is a space after each comma (which certainly aids readability). 
2.2 linear-white-space rule: I didn't understand the comment "CRLF = Folding". 
I think this rule allows whitespace (but non-null) lines in headers etc.? 
3.1 Header fields: (a) "However ... use of comments is discouraged". 
This seems rather outside the scope of a definition such as this; at most it should be a informational note, and explain why the note is there (historical or client incompatibility, performance, reduced net traffic?). 
(b) [nit] the second open quote in the comment rule should be a close quote. 
(c) The ctext rule seems to be missing some characters (there's an open quote, followed by an open single quote, but neither is closed). 
Also, shouldn't LF be excluded too? 
3.2 Object body: (a) This is my 'biggest' question -- I don't understand from the second paragraph how to determine when to stop reading the data on a request. 
If the headers are only 'similar' to those defined by MIME, then the MIME definition may or may not be relevant. 
Moreover, a "heuristic function of the Content-Type and Content-Encoding" would appear to be unimplementable, as new Types (especially application/xxx) seem to spring up daily. 
It would seem to be appropriate that the HTTP protocol specify that Content-Length, in bytes, be Required--at least for Requests. 
(b) Does the server have to read the headers (and data, if any) on a request? 
For example, if the customizing filter/script doesn't need the information in order to determine the response, is the server permitted to leave the data unread, or could this embarrass some client(s) or TCP/IP stack(s)? 
4.1 Date/Time stamps: (a) I'm a little disturbed that time is only permitted to be specified to the second, given that most server hardware will be able to handle many more than one request per second, and network transit time is often sub-second. 
If this is a limitation of RFC 1123, perhaps an additional HTTP header for sub-second time information should be specified. 
(b) Since this is a new standard/document, surely it should specify a single Date/Time format, and only mention the others for compatibility/historical information? 
(c) [aside] I wish, oh wish, that Longitude/Latitude information were a recommended header. 
4.2 Multipart types: From the text, I infer that a server/script is not Required to respond with a multipart type when a client has indicated that it can accept them. 
It might be worth an explicit statement to that effect. 
4.3.1 
Date Header Field: (a) [nit] should refer to RFC 1123 rather than 822, or both? 
(b) It's not clear what time the header should refer to. 
For a response, is it the time when the request was accepted, or when the response line was generated, or when the first line of the header was transmitted, or when the 'Date:' header line was generated? 
(c) [nit] 'of' is missing between 'creation date' and 'the enclosed'. 
4.3.3 
Message-ID: [suggestion] Although the example shows a unique ID, it might be nice to encourage via the example a form of ID that includes the port number (if not 80), and even follows URL format. 
Perhaps: Message-ID: http://info.cern.ch:8080/9411251630.4256 
4.3.4 
MIME version: It is not at all clear why this is useful and strongly recommended if it is not an indication of full compliance with MIME. 
One might argue that it should *not* be included unless MIME-compliance of the remainder of the header and data is guaranteed? 
5. Request: The 0.9 requirement here (Simple Request must have Simple Response) is somewhat onerous on a server. 
Is it possible to relax or remove this requirement yet, or are there still 0.9-only clients in use? 
I've noticed that at least some Simple Responses will not go through some proxies transparently. 
5.2 Method and 5.2.2 Head: I'm surprised that the HEAD method *must* be supported, as it is ill-defined. 
5.2.2 simply says that there must be no Object-Body; it seems that the header may or may not be related to the header that would be sent if the method were GET, and in particular, HEAD may as well just return an empty (null) header. 
Further, in many cases the cost of determining, building and sending the header is going to be the major part of many transactions, so should clients or proxies be encouraged to use this Method? 
5.2.1 Get: [nit] The first paragraph should have the suffix: "(unless that is the produced data)." 
5.2.3 Post: (a) Some clarification seems to be needed here; there's an assumption that Form data is used by some gateway program rather than the server/script directly, but in the latter case the specification (the paragraph starting "If the URI does not refer to a gateway...") implies that the Form data must be retrievable at some later date. 
(b) Can the URI returned via a URI-header be a partial URI as described in 5.4? 
Or does it have to be a full URI? [I infer the latter.] 
5.2.3.1 [nit] Change 'references' to 'refers to'? 
5.3 HTTP Version: Given that this definition is more rigorous than earlier documents, and hence must be more constraining, it would seem to be necessary to change the version number (perhaps to 1.1) to reflect the stricter conditions for compliance. 
If the version number is not changed, then the date of the relevant HTTP 1.0 document would have to be specified at every reference. 
5.4 URI Note 1: What's 'default escaping'? 
What characters may be 'considered unsafe'? 
The "should" (probably meant to be "shall"?) implies that a server must comply with these conditions, but they do not seem to be well defined. 
5.5.2 If-Modified-Since: This section implies that servers *must* implement this feature. 
However, the last-modified-date might be unavailable, unreliable, or not applicable for some URIs. 
In these cases (or indeed in any case), is the server permitted to return the object, despite the presence of the I-M-S header? 
5.5.4 Authorization: UU-encoding: if defined by RFC 1421, then this should appear in Section 13 (References), and Appendix 15 should go away (as it does not appear to apply, in any case)? 
6.3 Status Codes and Reason Phrases: The rule for Reason-Phrase does not allow spaces, but several of the phrases specified later do include a space. 
6.3.1 201 Created: Also possible following PUT, presumably. 
6.3.1 202 Accepted: "delay header line" is what? 
6.3.1 204 No Response: Allowed for POST, too? 
(For a Form.) 
6.3.2 301 &amp; 302 Moved: Allowed for POST, and others, too? 
6.3.3 401 Unauthorized: [nit] change first 'a' to 'an'. 
6.3.3 404 Method Not Allowed: is this only for the defined methods, or should this also be used for a misspelled or unrecognized method name? 
6.3.4 500 Server Error: 502 (twice) and 504 call this "500 Internal Error". 
All should say "Server Error"? 
6.3.4 503 Service Unavailable: Does this imply that a server is not permitted to refuse to accept a connection? 
[Presumably not, though it could be read that way.] 
6.4 paragraph 1: [nit] change 'a Object-Body' to 'an ...' 
6.4.2 Version: since this refers to an object and not the server, shouldn't it be in section 7? 
7.2 Content-Length Note 2: [nit] 'wherever' has only three 'e's. 
7.4 Content Encoding: (a) [nit] this heading (and 7.5 too) needs a hyphen. 
(b) [nit] change 'method' to 'mechanism' in the first paragraph to avoid confusion with use of the term elsewhere? 
7.5 C-T-E: The rule omits the token and colon before the type. 
7.7 Expires: Are there any constraints on the Date and Time specified? 
Specifically, may they refer to a time earlier than or the same as that in the Date: header? 
7.9 URI First example: [nit] Change close quote to open quote. 
7.9 URI Second example: [nit] Semicolon missing. 
7.12 Title: "isomorphic" here implies that the Title follows SGML syntax, and hence depends on the HTML DTD (including the Declaration), and is allowed any valid entities and shortrefs within, etc. 
This probably isn't intended (I hope!). 
7.13 Link: [nit] both examples have unmatched quotes. 
'//' missing after 'mailto:'? 
8 Neg. 
algorithm para 4: [nit] change 'between 0 and 1' to 'in the range 0 through 1'? (0 and 1 are allowed values.) 
8 Neg. 
algorithm 'bs' definition: [nit] change 'send' to 'sent' 
9 Authentication, paragraph 1: Here is perhaps the strongest statement in the document about conformance. 
Yet, surely, if the server would never return "401 Unauthorized" (because all its data are public) there is no need for it to implement the Basic Access Authentication Scheme? 
9 Authentication, fourth bullet: [nit] change second 'a' to 'an'. 
11.3 Abuse, para 1: While I strongly support the intent behind the last sentence here, this document is a definition of the HTTP protocol, not people using it. 
It cannot impose requirements on, or define, people. 
(Does my server become non-conforming because someone using my server abused his or her collected data?) 
Also, am I (as the writer, and hence provider, of a server) responsible for the actions of other people *using* my server to provide data? 
Thin ice... Perhaps it should read something like: "People using the HTTP protocol to provide data are responsible for...". 
11.3 Abuse, final para: This reads as though the user must be prompted with the From field to be sent before sending every request. 
Probably not the intent. 
16 Server Tolerance, para 2: Time to make this a Requirement? 
17 Bad servers: The first paragraph here sounds like a Compliance statement. 
As such, it should be in the body of the document, not an appendix? 
The document certainly needs a Compliance section. 
17.1 Back compatibility, para 2: This doesn't seem to reflect current practice (inline img href="xxx" requests for .GIF 
files do seem to appear as images, not as HTML documents). 
mfc/29 Nov 1994 
Thanks, these comments are definitely useful. 
Unfortunately, they refer to the pre-Internet-Draft version, so I'll try to point out any differences in the section numbering to avoid confusion. 
That's the ideal case, yes, but there is still no substitute for experimentation. 
In fact, I was tempted to put in a section on "how to experiment with the protocol", but had no time for that. 
Maybe I should write a book. 
;-) 
Yes. Unfortunately (or fortunately, depending on how you look at it), almost all of the protocol is optional, and thus all the strict conformance areas must be surrounded by lots of IFs, HOWEVERs, and UNLESSes. 
But, getting it right is still the goal. 
One major problem with the augmented BNF used by RFC822 (and MIME) is that it allows any amount of linear white space between tokens, but never specifies that in the rule definitions (it is treated as a general assumption for all rules). 
I can understand why -- it is much easier to read the rules without the extra clutter -- but it runs against my desire for formality. 
What do people think? 
Define a new rule, e.g. ESP = 1*( [CRLF] LWSP-char ) and insert it everywhere that zero or more linear-white-space is allowed? 
Or, just stick with the current method but add an explanation in 2.1. 
The comments will be clarified. 
Yep, will do. 
That's a bug in FrameMaker's smart-quote feature. 
I really should replace all the smart-quotes in the BNF with normal double-quotes. 
Hmmm... should comments be allowed to fold (i.e. extend over multiple lines)? 
If so, then CR should not be excluded. 
If not, then LF needs to be excluded. 
Henrik asked me to explain that as well, but I ran out of time. 
It goes something like this: a) If message includes Content-Length, use it. 
b) If message uses an as-yet-undefined packetized Content-Transfer-Encoding, then that encoding may define an EOF marker. 
c) If message uses an as-yet-undefined packetized Content-Encoding, then that encoding may define an EOF marker. 
d) If message is of type multipart/*, the effective object body ends when the boundary close-delimiter is reached. 
e) If the connection closes, the object body has ended. 
Part (b) is along the lines of Dan Connolly's www-talk proposal of 27 Sep 1994 (Message-Id: 9409271503.AA27488@austin2.hal.com ). 
Question for HTTP/1.1: 
Should we attempt to extend MIME C-T-E to be something useful, or just change Content-Encoding to be an ordered list of encodings rather than the current single-token? 
I'd rather not go that far, but we may have to for HTTP/1.0. 
The Request-Headers must be read, though implementations may want to optimize and assume that if the Request-Headers have not completed within the first read buffer, then the rest are not important. 
Since that is only a problem for SOME BROKEN CLIENTS, most servers could successfully pretend to be conformant while implementing the optimization. 
Obviously, if there is any data in the request, the server had better read it (unless the request line has already errored-out). 
Leaving request data unread will not be a problem for the client, though it may cause a problem for the server. 
Simon could explain that better than I. 
Not a limitation of 1123, but a limitation of many operating system date routines. 
Besides, there is no useful purpose for that level of granularity in an application-level protocol. 
The document has a bit of history associated with it, but perhaps a stronger statement should be made. 
I didn't want to be too forceful, however, since I am biased about the date format and wanted to test the water first. 
[aside] it's too inefficient to include that in every response. 
A standard URL for site info is more appropriate. 
Hmmm, I guess that sentence (4.2.1) could be misinterpreted. 
I'll clarify it. 
No, the semantics are defined in RFC 822 -- RFC 1123 just updates the format (and other things unrelated to origin-date). 
That is implementation-specific and, in any case, is assumed to be all within the same second (+/- 1). 
In theory, it is the moment just before the status/request-line is generated (i.e. it is the time at which the origin made the determination of what the request/response should be). 
In practice, it makes no difference. 
AFID (Already fixed in the I-D) 
The above is not a valid syntax for Message-IDs (no "@"). 
Even with it, the primary purpose of the Message-ID is to enable messages (particularly POSTs) via gateways. 
Using the same format as many (most?) E-mail and USENET postal services can be very handy. 
I share that opinion, but then we run into legacy issues. 
I believe proxies require Full-Requests. 
Ari? 
I do not believe it is possible to remove that requirement, though perhaps we should require that HTTP/1.0 clients never generate a Simple-Request. 
The definition of all the request methods need fleshing-out, but support for HEAD will still be required. 
That only reflects the cost for the server. 
The cost to the rest of the network is significantly less, and that is what is important here. 
Hmmmmmmmmmmm.......I'll think of some other way to clarify it. 
I think the confusion lies in the term "gateway", which in this case is referring to a mail or USENET gateway, rather than a CGI script. 
Many people have requested the former, but I have yet to see an implemented example of it. 
Now that I have separated the URI-header definition from Location, we could define it as being allowed for URI but not for Location. 
okay 
That is a philosophical issue that will be discussed in San Jose. 
If necessary, a subset of this spec will be assigned "HTTP/1.0" and work will continue on HTTP/1.1. 
That decision will have to be made eventually, but not right away. 
This section needs work, and may end up as separate sections for describing HTTP URLs, relative URLs, and URI's. 
Yes, but proper implementation (where appropriate) of the conditional GET protocol will be strongly recommended and required for all new servers. 
The reference to 1421 was removed from the I-D version, as uuencoding does not appear to have anything to do with that RFC. 
However, I agree that what is now appendix A should be rewritten to specify the uuencoding of a string, not a file. 
Hmmmm, I could have sworn that I has changed "1*token" to "phrase". 
In any case, the augmented BNF allows spaces between any tokens. 
AFID 
AFID 
AFID 
AFID 
AFID 
Only for methods implemented by the server, but not allowed for the object requested. 
doh! Actually, I think I'll change it again to "Server Internal Error". 
BTW, these are only recommended phrases, and may even be translated to regional (human) languages, if desired. 
No such implication was intended. 
AFID 
AFID -- wow, your version must be at least two days old. 
;-) 
doh! 
AFID 
AFID 
AFID 
No constraints. 
AFID 
AFID 
Yes it is, though no translation is performed by the sender -- it is assumed to have already been performed (or just ignored) by whatever process is getting the metainfo. 
AFID, and there is no "//" in mailto URIs 
okay 
okay 
Right, the requirement should only apply to user agents. 
AFID 
okay 
will be clarified. 
Nope. 
Hmmmm, seems a bit overboard to me. 
Henrik? 
This applies only to unexpected Simple-Responses, but perhaps should not require any default and just allow the client to use a heuristic. 
In any case, it doesn't belong in the appendix. 
Thanks again for the comments, ......Roy Fielding ICS Grad Student, University of California, Irvine USA 
There is a fairly strict rule, if there is a loss of backwards compatibility then the major version must go up. 
Hence HTML 2.0 because it is incompatible in some areas with HTML 1.0. 
BUT this does not imply anything about product certification ie:- 1) A server claiming to be HTTP 2.0 compliant must also be able to accept HTTP/1.0 requests [and HTTP/0.9 requests] 2) A client claiming to be HTTP 2.0 compliant must only generate HTTP 2.0 requests. 
The backwards compatibility requirments are:- 1) A HTTP 2.0 request must be an allowed HTTP 1.0 request 2) A valid HTTP 1.0 request must be an allowed HTTP 2.0 request The difference between allowed and valid being that the header Foo: quark is allowed in HTTP 1.0 but has no meaning so is not valid. 
This may at first appear to be indicating an equality but in fact it does not, basically a HTTP 2.0 server must tolerate a HTTP 1.0 request. 
I think that going to HTTP 2.0 would be a good thing, it is after all what was done with HTML. 
I also have some comments on the BASIC authentication scheme which I will prepare offline together with the code. 
The problem is that BASIC involves sending passwords in the clear which is very very bad and can compromise systems besides those used by the party setting BASIC authorisation (dimwits sharing passwords between secure and insecure systems). 
SHTTP/SHEN is still not ready for release and in any case has severe legal problems. 
I have suggested a quick hack that gives what I call "reasonable security" ie not on the public key level or distributed trust model of Shen but good enough for many applications and not creating security holes for other users. 
I'd very much like to drop this into the spec as soon as I've finished integrating the code into the multithreaded library. 
The wider stuff is not yet mature enough. 
Phill. 
There are certain cases where it ranges from impractical to impossible to know the actual content-length of data being returned in an object-body. 
In particular, some CGIs that generate their own HTTP response headers may have trouble determining the length of their generated replies, especially if the replies are generated on the fly and returned piece by piece (to stdout, for example.) 
By the time the content-length is known, the header portion of the response is long gone. 
For responses from the server, it seems to be sufficient for the connection close to indicate the end of the object-body, and everyone seems to support this now. 
The real problem is with object-bodies being sent as part of a client request, since it is inappropriate to signal the end by closing the connection. 
In THIS case, it may be appropriate to make the content-length header field mandatory. 
So, the mandate for content-length may not be symmetrical, since servers have a much harder time determining this value than clients. 
(Of course, new clients with plug-in components a la CGI could present the same problems that currently afflict servers with regard to calculating content-length.) 
I agree with this approach. 
It is difficult to determine when request-headers end if you don't assume that the first read buffer contains the "meat" of the request. 
The only reason to continue beyond the first read is if the method indicates additional data is on the way (POST, PUT, etc.) Unfortunately, there isn't an easy way to codify this in a standard that describes primarily syntax. 
I'd like to throw in my $.02 here, too. 
I agree that a single date/time format is much easier to deal with. 
The last thing I want to waste my time on is implementing a bunch of code to parse 3 different formats. 
Given the purpose of the Message-ID, its structure and semantic interpretation should be transparent to both clients and servers. 
The only important point for the software is that the ID be unique. 
It's interpretation is only for the benefit of humans. 
As with UseNet, it matters little what the actual format is the Message-ID is as long as the generator of the ID could work backwards from the value to find the Hence, there is no need for "smart numbers." 
In short, as an implementor, if you'd like to return URL info as part of your Message-ID, there doesn't appear to be anything in the standard that precludes it and existing software certainly doesn't care. 
Requiring a specific format is inappropriate, because not all hosts can guarantee uniqueness using the same techniques. 
For example, on non-Unix hosts, things like process IDs may not even exist. 
So requiring them as part of any unique ID generated would be inappropriate. 
Examples in the standard are fine for this header. 
A required format is unnecessary and undesireable. 
It does provide some indication that the headers aren't MIME version 2 or 3 or 4 headers. 
:) Seriously, I see that as the major value and not an indication that the entire message conforms to the MIME standard. 
And www-url-encoded-form format? 
Why required? 
There is no way to validate that this feature exists or is supported by a server by exercising a server remotely. 
I could write a server that modifies a document before every transmission or generates all documents on the fly. 
The effect would be the same as if the server completely ignored the if-modified-since header, since the document is always modified. 
From a client's perspective, you have no way to determine why the document is always returned. 
I think this is one case where "required" is too strong a word (I also have qualms about HEAD being "required", but that one can be validated remotely. 
I only question HEAD's usefulness for most implementations.) Strongly recommended is fine. 
Chuck Shotton cshotton@oac.hsc.uth.tmc.edu "I am NOT here." 
That's why there are so many `strongly recommended' ;-) 
Roy and I discussed this and I think that are argued for the current model. 
However, an explanation in 2.1 is a good idea. 
The only place where this is a problem is in RequestLine and StatusLine where linear-white-space isn't allowed. 
Maybe this is not pointed out clearly enough! 
As there is no current implementation I know of using comments it could actually be left out - especially when we discourage usage of comments. 
The current spec is a compromise that I am quite happy with - that is comments are allowed but not on multiple lines. 
I don't think this field is sufficiently important in HTTP to actually do anything about it. 
It is unfortunately not always possible to get the content-length before transmission and at the same time preserve a reasonable performance. 
An example is when a proxy is handling a FTP request and returns the body to the client using HTTP. 
I fully agree - if the headers are not read then we are close to go back to HTTP version 0.9! 
The CERN proxy talks HTTP 1.0 (almost) with proxy clients even if it receives a 0.9 response from the origin server. 
I don't know how many 0.9 applications are still around, but I think that at least this spec must have the notation documented. 
I think it can be taken out in futue releases. 
For some types of applications it can be useful, however whenever possible a conditional GET should be used instead! 
Sounds like a good idea! 
We have focused a lot on keeping the document in accordance with existing implementations so I think that 1.0 would be appropriate. 
Roy has a mail macro saying: "completely unacceptable this will break existing implemtations!" ;-) 
The note is taken from RFC 1630 and is meant to indicate that escaping should be kept at a minimum. 
Unsafe characters are described in 1630. 
Refer to earlier note on HEAD! 
Misspelling etc are followed by a 400 code 
I my opinion, the specification itself should not consider `bad' applications. 
Especially when so little is actually required in order to be a HTTP 1.0 application. 
These things belong in an appendix. 
-- cheers -- Henrik Frystyk frystyk@W3.org + 41 22 767 8265 World-Wide Web Project, CERN, CH-1211 Geneva 23, Switzerland 
I occurs to me that one current use of the Simple Request is in the hack that allows links to HTML documents to be served up for WWW clients on gopher servers. 
These are gopher links that are defined something like: 
Type=h Path=GET http-path-here Host=host Port=port ie. becomes gopher://host:port/hGET%20xyzzy.html 
(This currently seems to work for text/only web pages but not for pages with in-line images. 
There is some support for this hack in the gopher community.) 
CERN proxy handles any combination of HTTP1 and HTTP0; it always speaks back to the client using the same protocol version that the client used, that is, up- or downgrades the protocol when necessary. 
If I recall, someone reported problems with HTTP0 servers though, but that's something in the network layer (ECONN_RESET or something like that for remote socket when it manages to close before the proxy writes all the headers). 
I wouldn't hurry with that one. 
There are a good number of visitor counters and other gadgets that just spit out the plain file, sometimes even *without* any reaquest, just a connection to the correct port will trigger the response... :-). 
I know that's misbehaviour, but since it works, don't break it. 
We've got better things to do than to preach about some minor abuse like that. 
Since the code is already there it doesn't even require anybody's time to support it anymore. 
-- Cheers, Ari -- 
Oh 0.9 support on server side is very useful. 
You wouldn't believe the number of complaints I had at the time the proxy always spit out HTTP1, regardless of the request version. 
There are scripts/utils/wanderers/foobars that want to contact a server and not bother with parsing the header, and a Simple-Request is an easy way to get rid of the header in the first place. 
Every server should support both 0.9 and 1.0. 
Clients are another story. 
-- Cheers, Ari -- 
Ref posts from: Roy T. Fielding and Henrik Frystyk Nielsen Many thanks for the rapid responses. 
Just a couple of follow-ups: 
[aside] Odd: the version I have proclaims itself "This document is an Internet-Draft". 
Problems with document control somewhere! 
How will the Real Internet-Draft be identified? 
I'm happy with the situation for responses (connection closes is quite good enough), but still very unhappy with this definition for the data (object body) for requests (PUT and POST). 
The steps you just outlined are not defined sufficiently well to be implementable (and requiring every server to implement the rather gawky multi-part stuff just in case data comes in that way seems unnecessary). 
Is not Content-Length essentially always present, in current practice, for PUT and POST? 
In which case, why require more that this, or alternatives, unless truly necessary? 
[aside] Maybe, but Long/Lat is more useful to the user than date/time of server response, and there *is* no standard for site info. 
Excellent suggestion. 
Please do. 
Mike Cowlishaw 
If the document is modified before each response, or just has no last-modified date (as is the case for scripts), then the correct behavior is to send the document as if it were a normal GET. 
If the document does have a valid last-modified header, then it most certainly can be verified by exercising a server remotely -- I have done so many times. 
The conditional GET protocol MUST be supported because its implementation is required for efficient caching, and the need for caching far outweighs the needs of an individual server implementation. 
HEAD exists because it allows programs that are only interested in metainformation and link validity to make requests without retrieving the object body. 
Like IMS, its purpose is to reduce network load and thus must be supported in order for HTTP servers to be "good net citizens". 
Besides, it is trivial to implement once GET has been implemented. 
......Roy Fielding ICS Grad Student, University of California, Irvine USA 
That was a draft of an Internet Draft. 
;-) The real I-D has the filename draft-fielding-http-spec-00.ps in the upper-left corner of the first page. 
Sorry again for the confusion. 
The intention is to move away from "connection closes is quite good enough" so that future versions of HTTP can support a connection keep-alive. 
Multipart types have always been possible to implement -- its just that server and client authors have neglected (in the past) to read the MIME spec and thus understand that these things exist and how they are implemented. 
Including these descriptions in the spec is a way to prod people into implementing something that should have been supported long ago. 
Whether they stay in the spec, get moved to an appendix, or get shoved off to HTTP/1.1 is a question for the group to decide. 
......Roy Fielding ICS Grad Student, University of California, Irvine USA 
Mike Cowlishaw writes in 9412011958.AA00957@hplb.hpl.hp.com : 
Content-Length will only be essentially present when PUT and POST deal with pre-existing forms and files. 
Doing a PUT or POST with large amounts of data created on-the-fly does not lend itself well to use of Content-Length as documented better by others than myself on this list. 
I really hate to restrict the possibilities for future Web applications by making the multi-part stuff optional (or leaving it out entirely). 
What is so particularly gawky about the multi-part stuff? 
From my viewpoint, you either have to deal with fragmentation (UDP) or with message boundaries (TCP with multi-part messages). 
If you have a better idea on handling multiple bodies of data, I for one would sure like to hear it. 
Mark Fisher Thomson Consumer Electronics fisherm@indy.tce.com 
Indianapolis, IN "Just as you should not underestimate the bandwidth of a station wagon traveling 65 mph filled with 8mm tapes, you should not overestimate the bandwidth of FTP by mail." 
It's actually better to ignore the IMS header and have the cleint cancel if the date doesn't match. 
s 
IT MOST CERTAINLY IS NOT BETTER TO DO THAT!!!!!!!!!!!!! 
The point is to save network traffic, NOT make life slightly easier on server implementors. 
Supporting IMS is TRIVIAL and has already been done on all major servers -- not supporting it is reprehensible and deserving of public abuse. 
......Roy Fielding ICS Grad Student, University of California, Irvine USA 
My words exactly since a boldface font is not available. 
Servers are already facing problems with TCP kernel bugs, and intentionally dropping connections from the client side would only make things worse. 
Yes; even proxies do it (at least both that I've written), and it was doable even then, although slightly more complex (with all the combinations of incoming and outbound requests). 
But the benefits far outweigh the complexity. 
Cheers, Ari Luotonenhttp://home.mcom.com/people/ari/ 
Netscape Communications Corp. 650 Castro Street, Suite 500 Mountain View, CA 94041, USA 
Looking at IMS on a packet by packet basis, in the presence of possibly large headers greater than 512 bytes, having the client cancel will save 2 packets in the best case, and be no worse in the worst case. 
I sent a message on tis to www-talk during chicago with more analysis. 
my hands aren't up to recreating it at the moment, and I think the message dissapeared in transit. 
i'll see if i can find it again. 
s 
BOX-Line: From luotonen@neon.mcom.com 
Fri Dec 2 12:54:34 1994 Received: from cuckoo.hpl.hp.com by hplb.hpl.hp.com; Fri, 2 Dec 1994 20:52:46 GMT Received: from http-wg (list exploder) by cuckoo.hpl.hp.com (1.37.109.8/15.6+ISC) 
id AA24980; Fri, 2 Dec 1994 20:53:52 GMT From: Ari Luotonen luotonen@neon.mcom.com 
Message-Id: 9412022054.AA15651@neon.mcom.com 
Subject: Re: Comments on HTTP draft [of 23 Nov 1994] Date: Fri, 2 Dec 1994 12:54:15 -0800 (PST) http-wg%cuckoo.hpl.hp.com@hplb.hpl.hp.com Sender: http-wg-request@cuckoo.hpl.hp.com 
Looking at IMS on a packet by packet basis, in the presence of possibly large headers greater than 512 bytes, having the client cancel will save 2 packets in the best case, and be no worse in the worst case. 
I sent a message on tis to www-talk during chicago with more analysis. 
my hands aren't up to recreating it at the moment, and I think the message dissapeared in transit. 
i'll see if i can find it again. 
Well, did you monitor the impact on the server's TCP kernel when that is constantly happening? 
Basically what you're suggesting is very ugly anyway, and I don't like it one bit even if it wasn't expensive for the network. 
Gee, it's a few lines of code to do it cleanly. 
It's like smashing your car on a signpost because you don't feel like hitting the brakes. 
-- Cheers, Ari -- 
Good luck. 
Given that a typical IMS request message is 64 bytes + length(URL) + user-agent (if any) and a 304 Not Modified response is typically 98 bytes, I haven't got a clue as to how you could come up with such figures. 
That means (aside from the connection packets) one packet for the request and one for the response. 
In contrast, a normal request will generally buffer 16 packets before the client even has a chance to read the response -- cancelling at that point is useless. 
......Roy Fielding ICS Grad Student, University of California, Irvine USA 
Roy - slow start buildup is exponential from 1. s 
