Dear Len, I think you are correct. 
I guess that is part of what I am rebelling against: that rather than being "device independent/neutral", focus really has been defined to mean "keyboard focus". 
This is a shame. 
Is it unrealistic to hope that if there is an HTML 4.02 (I am guessing that there will NOT be) that this would get corrected? 
Also (now don't laugh) there can be interfaces with two pointing devices. 
There was work on that at Xerox Parc some years back I believe, for two handed interfaces which were really rather cool. 
That sounds very intriguing. 
After all, when at a physical work bench, most people use two hands -- so why not two mice! 
Seriously, this could be a significant improvement. 
I don't know about you, but my computer workstation was apparently designed for someone with THREE arms. 
I keep two hands poised over the home row of my keyboard and my third hand rests on the mouse. 
Very efficient. 
Cheers, Bruce B. After looking at Charles' response and thinking about what he and Bruce are saying, I've got a proposal for a more general concept of focus. 
(which is probably not original... see the P.S.) First point: "focus" is really keyboard focus. 
"mouseover" is really mouse focus. 
Here's why. 
What does it mean for a object to get what we call "focus"? 
It means it will respond to keypresses on the keyboard. 
So a better name would be "Keyboard focus". 
And what does it mean for an object to get mouseover? 
It means first of all that the object will respond to a keypress on a key on the mouse. 
(I mean the actual buttons on the mouse, not their keyboard equivalents). 
So a good name would be "Mouse focus". 
Now you might say there's more to mouseover that just mousefocus... it can trigger some other event like a popup. 
But the same holds true for keyboard focus. 
For example, receiving keyboard focus could trigger a prompt appearing somewhere (which I haven't noticed on the web, but which I remember from dumb terminal interfaces in the late 20th century). 
So "focus" is really keyboard focus and "mouseover" is really mouse focus They are strictly analogous and independent. 
So we need a way to change mouse focus independently of keyboard focus. 
And without actually moving a mouse. 
For example, we could define "mouse tab index" for element which would step mouse focus through all elements with those indices defined. 
Furthermore, we should keep this general. 
Current computers mostly have just two independent devices with keys... a mouse and a single keyboard. 
But you could have, say, an extra numerical keypad, and I could imagine situations where it would be convenient for the keypad focus to be different from the focus of the main keyboard. 
Also (now don't laugh) there can be interfaces with two pointing devices. 
There was work on that at Xerox Parc some years back I believe, for two handed interfaces which were really rather cool. 
So there we have it: we need a general concept of focus(device) where device can be one of some arbitrary number of devices. 
Some devices may have keys... others would not. 
And it must be possible to move any of the focuses independently to any object that responds to them, and with or without vision. 
Len p.s. Now that I've said all this I have a distinct feeling of deja vu... that I've just reconstructed an old input model... maybe an old SunOS ...except that I've added the need for a keyboard equivalent... if someone recognizes this please speak up so we can give it it's proper name... bruce. 
keyboard handlers are much more inclined to be get attable than pointing device handlers by accessability modalities. 
Of course, this may not be always the case but when we looked at ways to make things interoperable, we found that everything has a keyboard of sorts and not much has a mouse. 
Hands-On Technolog(eye)s ftp://ftp.clark.net/pub/poehlman 
voice 301-949-7599 end sig. 
This depends on the disability group being targetted - for some group the first thing that is removed is the keyboard. 
Charles McCN bruce. 
keyboard handlers are much more inclined to be get attable than pointing device handlers by accessability modalities. 
Of course, this may not be always the case but when we looked at ways to make things interoperable, we found that everything has a keyboard of sorts and not much has a mouse. 
Hands-On Technolog(eye)s ftp://ftp.clark.net/pub/poehlman 
voice 301-949-7599 end sig. 
W3C Web Accessibility Initiative http://www.w3.org/WAI Location: I-cubed, 110 Victoria Street, Carlton VIC 3053 Postal: GPO Box 2476V, Melbourne 3001, Australia There will be development of HTML as XHTML 2.0, and there is an opportunity to improve things. 
The implementation of the Docment Object Model (DOM) specifiation could also lead to a big improvement, as the Web moves from just HTML to more and richer XML. 
Cheers Charles McCN Dear Len, I think you are correct. 
I guess that is part of what I am rebelling against: that rather than being "device independent/neutral", focus really has been defined to mean "keyboard focus". 
This is a shame. 
Is it unrealistic to hope that if there is an HTML 4.02 (I am guessing that there will NOT be) that this would get corrected? 
[snip] I'm glad to hear there's a chance for a more general input model in XHTML 2.0. 
A few thoughts... 
There are lots of input devices commecially available today that go beyond the mouse and keyboard model. 
For example, game controllers crawling with buttons; or spatial input devices, used in virtual reality, that can sense position and orientation (x, y, z, pitch, roll, yaw). 
And still more that never got beyond the research stage (e.g. a touch screen I developed a while back that sensed normal and shear components of any number of simultaneously applied forces). 
We want to maximize the opportunity to provide accessible alternative inputs. 
So a general input model should support, at a minimum, 1. an arbitrary number of input devices 2. each device can send events and status for zero or more discrete variables and zero or more continuous variables 3. at any time, a given input device I can send events to any user interface object O (e.g. field, menu, 3D lever, etc); we then say that that O has focus from I . 
4. The software may respond to the events and status information in (2), and acquisition or loss of focus described in (3). 5. Software "event transformations" would be available to change events from one or more input devices to the equivalent of events from any other device. 
(This is a generalization of "serial keys" and "mouse keys"). 
This would give us the maximum chance to provide an alternative inputs. 
(Plus it's just plain good software engineering I think). 
Len p.s. A more general approach would be to bypass the normal inputs and go directly to the underlying data but that's beyond this the scope of this discussion. 
Leonard R. Kasday, Ph.D. Institute on Disabilities/UAP, and Department of Electrical Engineering Temple University 423 Ritter Annex, Philadelphia, PA 19122 kasday@acm.org 
(215) 204-2247 (voice) (800) 750-7428 (TTY) 
