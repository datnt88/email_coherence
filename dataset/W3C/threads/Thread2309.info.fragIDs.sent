In few last messages regarding charsets, I was to notice that many troubles could be handled via some character remapping mechanism. 
How this should work is as follows: 
-let's suppose that browser cannot accept document charset, then document should be translated into charset which is supported by browser, but lest likely to loose some characters (Example: with CP-1250 and iso-8859-2 there are only some swapped blocks of chars, says Dave, so then there should 
never be a loss in conversion, but we don't need to have both, duplicate versions of documents -- one for UN*X machines, and one for Wind*ws CEE [and still more for other platforms ...] 
- conversion mechanism is simple transliteration, different codes are being assigned for the same characters Mirsad Todorovac 
Not only swapped blocks. 
In ISO 8859-2 positions from 129 to 159 are not used. 
CP1250 uses all 256 characters. 
This is an implementation question and does not belong here really. 
However, I think it's good to point out these things from time to time because some (most?) implementors don't know about it. 
Life is a sexually transmitted disease. 
dave@fly.cc.fer.hr dave@zemris.fer.hr 
RFC1345 actually provides specifications for doing such simple transliteration, with fallbacks. 
keld simonsen 
