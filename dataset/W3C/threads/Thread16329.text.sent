Accurately describing picture content is necessary for accessibility considerations, especially LONGDESC/D-Link. 
However, giving good and useful picture descriptions is not as easy as it sounds; there is a certain art to it, and you can improve with practice. 
I recently went on a trip to Rome to speak at the E-Commerce Summit (http://www.e-commerce-summit.com/) and the day before the summit started, I went on a commercial tour of Rome and took many pictures of what I was seeing. 
I would like to make these available on the web, and, as a practice exercise, I'd like to see if anyone (who can see my pictures) would be interested in helping to describe these pictures or at least evaluating the descriptions that I or someone else has provided. 
Anyone game? 
Kynn Bartlett kynn@idyllmtn.com http://www.kynn.com/ 
Chief Technologist, Idyll Mountain Internet http://www.idyllmtn.com/ 
Next Speaking Stop: New Orleans, 9 Dec 99 http://www.builder.com/live/ 
CC/PP Builds the Future of the Web -- learn more at http://www.ccpp.org/ 
I would love to try. 
But I have some questions relating to blindess, and I suppose visual impairment. 
I am sighted, so these questions are very basic, but are nonetheless important for sighted developers who are trying to build accessible pages. 
These questions assume the person in question has been blind their entire life: 1. Color. 
Is color important if you're blind? 
How do you know what "red" is if you've been blind your entire life? 
I assume people who are color blind will understand shades - correct me if I'm wrong. 
2. Shapes. 
How do I describe a classic Greecian column? 
Can geometic shapes be used (cylindrical, columnar, etc.)? 3. Distances. 
I imagine distances, either in feet or inches or miles or yards visually. 
I know the drive from my house to work is five miles. 
It takes me 30 minutes to bike it - that's the meaning of five miles to me. 
I can envision the lenght of creek along the route, the 1/4 mile long row of cottonwoods, and the horrible 2 mile stretch along a busy road. 
4. Metaphors. 
Describing something visual to a sighted person who hasn't seen it is tough enough: we use other visual metaphors to make it easy, and make it work. 
What metaphors exist for the sighted to use when describing something to the blind? 
5. Finally: sound. 
If we can't easily describe sound to a deaf person, how can we describe images/pictures to a blind person? 
Sorry for all the questions...and they may seem strange in light of my agreement to try and describe the pictures...but I think this is a huge barrier in accessible web design. 
In my experience, most of my fellow webmasters can easily understand accessible web design, and like the idea, with a few minor caveats. 
But we have a real hard time understanding how to convert a visual meaning into a verbal (written) meaning. 
Thanks! 
Get Your Private, Free Email at http://www.hotmail.com 
Kynn, Please send me the URL and we will give it a try. 
Thanks. 
Jeff Pledger Yes Please Kynn. 
Post them on the web somewhere, I'll mail you a description. 
I'm a reader with rnib, and would like to learn a little more. 
I've also recently received (informed by this group) a copy of the US 'howto' manual. 
Interesting to see how the UK / US compare :-) regards, DaveP Kynn, How academic an exercise do you want this be? 
Most descriptions I have come across (which includes the CAM stuff) is very short and functional -- this include descriptive video. 
Now, a static web page does not have real time constraints, but aren't most of your friends and colleagues (including those who happen to have vision impairments) interested in why YOU took a particular photo, who is in it, and what were your impressions at the time? 
Seems to me, only the photographer can answer these questions! 
Take a look at the ultrasounds I posted for MY friends and relatives. 
I got good feedback from my friends who are blind, and much to my surprise (I should have predicted this, but I didn't), family who were sighted liked the descriptions too! 
(They appreciate the help with knowing what they were looking at.) I latter learned that most people did not realize that the ONLY reason I bothered with descriptions (of course I would have included ALT text) was for the benefit of my blind friends! 
(This also proved to me that _I_ am still learning lessons about the importance of universal access.) Photos can be found at URL: A picture may be worth a thousand words, but sometimes it is nice if someone tells you -- Just what the Hell is that? 
-- Bruce Bailey Agreed in general. 
An exception might be at an art exhibition. 
We recently had audio descriptions done professionally, with mood music, artist background material on top of fairly fine detail. 
That was really impressive for most viewers. 
Now, a static web page does not have real time Nice addition. 
?Similar to background about a painting? 
What made you take this picture? 
Who was with you? 
Were you sightseeing etc. Brings out the picture from being one of those family snaps that we tend to bore the relatives with? 
regards, DaveP If you go to an Art Gallery exhibition you can look at pictures. 
At many galleries you can also get an audio "guided tour" (usually just a cassette tape, but sometimes a real and knowledgeable person). 
And many exhibitions also have a catalogue, which has pictures of the pictures, and an awful lot of words about the pictures. 
I think there is a message in that somewhere. 
I guess it is the same as the one Bruce is describing - Universal access is often surprisingly useful to the people who could survive without it, despite the fact tht it is critical to only a few people (and a particular aspect may equally be completely unusable for an equal number of people - an audio description helps people who cannot see just as much as it excludes people who cannot hear. 
The goal is to provide the redundancy to cater for both groups, and the benefit spreads to many people in neither group. 
Charles McCN Kynn, How academic an exercise do you want this be? 
Most descriptions I have come across (which includes the CAM stuff) is very short and functional -- this include descriptive video. 
Now, a static web page does not have real time constraints, but aren't most of your friends and colleagues (including those who happen to have vision impairments) interested in why YOU took a particular photo, who is in it, and what were your impressions at the time? 
Seems to me, only the photographer can answer these questions! 
Take a look at the ultrasounds I posted for MY friends and relatives. 
I got good feedback from my friends who are blind, and much to my surprise (I should have predicted this, but I didn't), family who were sighted liked the descriptions too! 
(They appreciate the help with knowing what they were looking at.) I latter learned that most people did not realize that the ONLY reason I bothered with descriptions (of course I would have included ALT text) was for the benefit of my blind friends! 
(This also proved to me that _I_ am still learning lessons about the importance of universal access.) Photos can be found at URL: A picture may be worth a thousand words, but sometimes it is nice if someone tells you -- Just what the Hell is that? 
-- Bruce Bailey --Charles McCathieNevile mailto:charles@w3.org 
W3C Web Accessibility Initiative http://www.w3.org/WAI MIT/LCS - 545 Technology sq., Cambridge MA, 02139, USA Such audio tapes can provide an interesting perspective, but I am glad I don't have to depend on someone else's "opinion" as my only source of information. 
I don't know of a better alternative, but when I see the high prices for "art" with cow dung spattered on the canvas - I rather not have an audio description of the piece even if provided by the "artist". 
How often do you agree with the descriptions written by art aficionados who claim to know what the artist was feeling or attempting to create? 
Much of the modern and impressionist painting is not worth the cost of the canvas and the paint it took to create the graphic images. 
Realistic graphical images that convey exact "visual pictures" can be described without dissenting opinions. 
For example, "how to change a spark plug". 
3-D engineering renderings would be another example of "exact visual images" that would be superior to only a body of text. 
Descriptions that require interpretations should only be written by the person who creates the images. 
All other descriptions are OPINIONS and may or may not convey the true meaning of the visual images. 
That is my opinion and with three dollars you can buy a cup of coffee at Starbucks. 
Claude Sweet Educational Technologist quote Such audio tapes can provide an interesting perspective, but I am glad I don't have to depend on someone else's "opinion" as my only source of information. 
unquote which is why, when i go to a museum, i like to gather together at least 2 and optimally more friends whose aesthetic judgement i trust, and get all of their opinions and perspectives... there's no doubt about it -- when you're blind, the more information you're able to get, the better your experience of a visual object will be... what would really be interesting, kynn, would be to have you describe the photos from your point of view -- including the reason why you took the picture, the mood that you were in when you did so, what you were attempting to capture on film, and what you actually captured -- and then allow visitors to add comments or describe the scene from their perspective... now that's a site i would bookmark, gregory. 
A book is a mirror: if an ass peers into it, you can't expect an apostle to peer out. 
-- Lichtenberg Gregory J. Rosmaita unagi69@concentric.net 
WebMonster and Minister of Propaganda The Visually Impaired Computer Users' Group of New York City (VICUG NYC) What would be interesting is to use some metadata tools to provide bits of metadata about the photos. 
That way you can find out who made what statements about them, and then get the descriptions from the person you trust. 
Charles McCN quote Such audio tapes can provide an interesting perspective, but I am glad I don't have to depend on someone else's "opinion" as my only source of information. 
unquote which is why, when i go to a museum, i like to gather together at least 2 and optimally more friends whose aesthetic judgement i trust, and get all of their opinions and perspectives... there's no doubt about it -- when you're blind, the more information you're able to get, the better your experience of a visual object will be... what would really be interesting, kynn, would be to have you describe the photos from your point of view -- including the reason why you took the picture, the mood that you were in when you did so, what you were attempting to capture on film, and what you actually captured -- and then allow visitors to add comments or describe the scene from their perspective... now that's a site i would bookmark, gregory. 
A book is a mirror: if an ass peers into it, you can't expect an apostle to peer out. 
-- Lichtenberg Gregory J. Rosmaita unagi69@concentric.net 
WebMonster and Minister of Propaganda The Visually Impaired Computer Users' Group of New York City (VICUG NYC) --Charles McCathieNevile mailto:charles@w3.org 
W3C Web Accessibility Initiative http://www.w3.org/WAI MIT/LCS - 545 Technology sq., Cambridge MA, 02139, USA Well, I am sighted, and until you put these pictures on the web, we can take one of your existing photographs. 
I took the liberty of picking your nice Kynn-Cam image tongue2.jpg, 
available from your website at and using The vOICe Learning Edition software I turned it into a slow-motion MP3 soundscape (32K MP3 audio file) Note: if your browser is not properly configured for MP3 files, it may try to show the contents of an MP3 file as text inside the window, which gives binary nonsense and no sound at all. 
In that case, you may have to first save the MP3 file directly to your disk and "run" the file from there. 
Furthermore, it is recommended to set your MP3 player to autorepeat, such that you will have all the time to mentally focus on the various details in this complex soundscape. 
The image shows a frontal close-up of Kynn's face, with both shoulders showing in the lower part of the image to the left and right side of the face. 
Kynn's face is just about in the middle of the image and the upper part of the scalp touches the top edge of the image. 
Kynn is looking straight ahead towards the camera, mouth wide open and tongue sticking out (sorry Kynn, but I couldn't resist this one; after all, you did publish this nice photograph on the web, and your comfort here is that there is a similar very famous photograph of Albert Einstein doing the same tongue act, so I think you are in good company). 
Now you will hear a kind of low-pitched rhythm on the left and right side in this stereo sound. 
These are the vertical stripes of the shirt covering Kynn's left and right shoulder. 
The high-pitched tones in the middle of the soundscape are the reflection of the ceiling light on Kynn's hair and scalp. 
The smoother sounds on the far left and right are from the more or less uniform bright background parts. 
On the right side, from the viewpoint of the camera, Kynn is holding up his hand showing palm and fingers, but that is here very difficult to hear out unless you know exactly what to listen for. 
Now we can hear some more details of Kynn's photograph if we zoom in (pressing F4 in The vOICe Learning Edition), and the resulting MP3 sound can be downloaded from the URL Sighted readers can compare this soundscape to the corresponding zoomed-in JPEG image to judge for themselves to what extent the soundscape matches the image content. 
Readers who still lack an MP3 audio player can instead of downloading the above MP3 audio file, download the equivalent but much larger WAV file (176K) from the URL A fairly brief tone with a clear pitch standing out in the left (that is, first) half of the soundscape is from Kynn's white teeth in the upper jaw. 
If you listen carefully, you can even hear some sort of irregularity within this sound, caused by the boundaries between the individual teeth. 
Also, if you concentrate, you can at the very same moment that you hear the teeth, also hear a soft higher-pitched woosh, which happens to be Kynn's nose wich is of course above the teeth. 
On the lower right there is the low-pitched rhythm of the stripes of Kynn's shirt. 
Simultaneously, there is a rather loud higher pitched noise from the bright background that shows between Kynn's face on the left and his hand on the right - again as seen from the camera viewpoint. 
I hope you had some fun from this description. 
Since Kynn took the snapshot using his QuickCam PC camera, the "Kynn-Cam", he should be able to listen to live images for himself using his camera and The vOICe Learning Edition software. 
Also, he could import his existing image files through the "Sonify image files" option in the File menu (or use the Control O keyboard shortcut to the file requester) and play with the various controls for zoom (F4 and arrow keys, and Shift F4 for still more zoom) and slow motion (F3 or Control Alt F3 for very-slow motion) or inverse video (F5). 
For those who are unfamiliar with the rules of image to sound mapping: there are three simple rules in the general image to sound mapping of greyscale camera images, each rule dealing with one fundamental aspect of vision: rule 1 concerns left and right, rule 2 concerns up and down, and rule 3 concerns dark and light. 
The actual rules of the game are 1. Left and Right. 
Video is sounded in a left to right scanning order, by default at a rate of one image snapshot per second. 
You will hear the stereo sound pan from left to right correspondingly. 
Hearing some sound on your left or right thus means having a corresponding visual pattern on your left or right, respectively. 
2. Up and Down. 
During every scan, pitch means elevation: the higher the pitch, the higher the position of the visual pattern. 
Consequently, if the pitch goes up or down, you have a rising or falling visual pattern, respectively. 
3. Dark and Light. 
Loudness means brightness: the louder the brighter. 
Consequently, silence means black, and a loud sound means white, and anything in between is a shade of grey. 
All of this means, for example, that a straight bright line on a dark background, running from the bottom left to the top right, sounds as a tone steadily increasing in pitch: ooiieep. 
Two bright lines give two tones. 
Three distinct bright dots sound as three short beeps, and so on. 
Although the rules are simple, real-life images like the photograph of Kynn often give very complex sounds, because there is so much to be seen. 
The direct download URL for the evaluation version of The vOICe Learning Edition executable voice.exe, available for personal use, is while the on-line description of this software can be found at the URL link given below. 
Have fun playing! 
Peter Meijer Soundscapes from The vOICe - Seeing with your Ears! Sure an approach would be very helpful to anyone, but especially to someone who has no vision. 
Having one or more sighted individuals validate descriptive text (audio) is ideal, but such assistance is the exception, not what generally occurs in the real world. 
I would like to target in on an individual who has vision problems and is attempting to access an Inter or Intra net page that uses graphics to convey information. 
Would we normally expect someone with full vision to be assisting the individual who has vision problems? 
The question is "Would this level of effort be expected by everyone who is creating descriptive text to define and explain the use of EVERY graphic image on a web site?". 
To be an effective tool, simple and reasonably objective text must be produced so the non visual user will achieve a level of communication equal to the benefit experienced by a sighted person viewing the same information. 
Is this possible to achieve 100% effective communication 100% of the time even with the best trained observer, most experienced html programer, and very creative web page designer? 
I have been told that the ability to visualize images from descriptive text depends on when the lack of vision occurred - at birth to some period later in life after the individual has had a chance to acquire language skills and associate actual visual images with descriptive words. 
How can a sighted person measure the effectiveness of their efforts to write triple A descriptive text? 
Claude Sweet Education Technologist "Each day provides a another opportunity to acquire new knowledge and perspectives." 
assume as much public media does a 3rd grade level education when writing your descriptions. 
There are many opinions, but the fact is that if you keep it generic and don't refer to in jokes or leave the reader hanging with coloquialisms unless pertenant, it is doable. 
I will dug up urls where this has been done quite well. 
Let's get on with the experement. 
What matters more than whether or not a person had sight is how much of what people talk about and they read about they are able to assimilate into something that at least for them has meaning. 
Thanks! 
Hands-On Technolog(eye)s Touching The Internet: Voice: 301.949.7599 ftp://ftp.clark.net/pub/poehlman 
Dynamic Solutions Inc. Best of service for your small business network needs! 
---sig off--- Several people reported problems in downloading and playing my MP3 files. 
It turns out to be a server problem specific to MP3 files. 
While I will report this to my provider, you can in the mean-time get the two MP3 files by downloading and unpacking the zip file (53K file size) and play the resulting two MP3 files in your MP3 player. 
These are the same files that I had posted direct links for. 
I'm sorry for any inconvenenience caused. 
My original posting can if necessary be reread from the W3C archive at the web page but again, the MP3 file links there are likely to cause problems, so please use the above zip file instead for now. 
Best wishes, Peter Meijer Soundscapes from The vOICe - Seeing with your Ears! Hi. Has anyone played with these "sound scapes" Peter talks about here? 
I've tried listening to a few from his web page, but having never seen (not even light), I have a hard time making any kind of sense out of anything but the simplest of "images" (one straight line). 
How useful is this to those of you with limited vision, or with no vision but prior visual experiene? 
Some may argue that given enough training, this can become a viable way of "seeing." 
I think the learning process would be very painful, slow, and frustrating. 
What do you-all think? 
Rich Hi Rich: I think this is a very innovative idea, but I too could not make sense of much of anything beyond simple straight lines. 
I think that an SVG or XML approach still provides the best means of getting information such as what objects are on the screen and how they are connected. 
In order for the soundscapes approach to really work would take RI AI (Real Intelligent Artificial Intelligence) pattern recognition. 
I don't think the eye-brain system of humans works by scanning one bit stream at a time but I'm talking outside my area of expertise here. 
P.S. slightly off topic: I've heard about a manual that is produced by either APH (American Printing House for the Blind) or LOC's NLS/BPH Library of Congress National Library Service For the Blind and Physicall Handicapped. 
Does anyone know if this is online anywhere or available to NLS members on audio cassette? 
-Thanks in advance for any info on this. 
-Steve Steve McCaffrey Information Technology Services New York State Department of Education Rich Caloggero rich@accessexpressed.net 11/22/99 01:26PM Hi. Has anyone played with these "sound scapes" Peter talks about here? 
I've tried listening to a few from his web page, but having never seen (not even light), I have a hard time making any kind of sense out of anything but the simplest of "images" (one straight line). 
How useful is this to those of you with limited vision, or with no vision but prior visual experiene? 
Some may argue that given enough training, this can become a viable way of "seeing." 
I think the learning process would be very painful, slow, and frustrating. 
What do you-all think? 
Rich I played with the sound scapes recently and a while ago. 
Anything but the simplest geometric shapes was just noise to me. 
I think the technology may have promise for real time use (where the user is controlling the up/down left/right component), but products that work that way (for navigating the real world) are already available. 
By the time AI is sufficiently advanced to process these sounds intelligibly, we would already have better automated pattern/graphic recognition! 
This is well beyond my area of expertise, and the idea is novel and interesting, but I don't see the real world application. 
On Monday, November 22, 1999 1:15 PM, Rich Caloggero even the Some I much appreciate the valid comments given by Rich, Steve and Bruce. 
Your constructive criticism and feedback is very useful, as it helps me to better understand where I should focus my attention. 
I'll try to go into some of your comments, and we will see to what extent we can find further common ground. 
I am aware that technology is not even half the story here, and we are rapidly approaching the point where we do have a powerful new accessibility option and tool from a technical perspective, but still need to find out and decide for ourselves what we can do or would want to do with it, if anything. 
Indeed there is a need to find better and more convincing answers to Bruce's legitimate questioning of any real world applications. 
Yes, to really learn to see with sound could be painful, it will be very slow, and it might be frustrating at times. 
Moreover, we do not know yet how good people can get at it in the end. 
On the other hand, the process of learning a foreign language is also often painful, boring, very slow, and frustrating. 
I have no experience learning to read Braille, or learning to use the cane for safe travel, but I imagine that that too is by no means great fun until after you have mastered it to a certain degree. 
Dots of Braille do not make any sense to me, nor does the Spanish language. 
Somehow we or you work on mastering some of these things, because we think it pays off one way or the other. 
Will learning to see with sound pay off for you? 
I don't know, I cannot promise that. 
Depending on one's personal background, attitude, expectations or interests, it could also be fun for those who had no prior vision, getting an exciting "hands-on" exploration of vision by using a cheap PC camera, experiencing the effects of visual perspective, occlusion, parallax, visual texture, and so on and so forth, but it definitely won't be easy if you want to fully master the interpretation of arbitrary soundscapes. 
Would it be possible to view and treat it more like playing a game? 
The technology has only during the last two years become affordable, through the use of standard PC's and PC cameras, and with worldwide availability of software and information through the Internet. 
We don't have any convincing success stories from users to tell yet. 
The technology is there all right, it provably preserves a lot of visual information in the soundscapes while meeting several key parameters known to limit human auditory perception, it is technically reliable through the use of mass-produced hardware components, it is affordable through cheap $50 cameras and it provides unprecedented access to visual information, but all that information is certainly very dense, and presented in a way that no human being has ever had access to before in history. 
We don't know if the human brain, your brain, my brain, can learn to cope with that, or rather to what extent it can learn to do that, and whether it is really worth all the trouble. 
Now how do we proceed - if we do? 
Ideas are welcome. 
You are quite right, Steve, from the perspective of accessing structured information on the screen. 
This technology was actually developed and meant for accessing arbitrary (unprepared, untagged) visual information, going well beyond the screen, specifically for gaining access to the visual information from our real-life local environment by using a camera. 
There is no XML describing my room, my house, my neighbourhood, or XML describing the architecture and art in the city of Rome. 
Now if (and indeed stressing the big "if") we can learn to interpret that arbitrary visual information through sound, we will as a bonus also be able to interpret whatever shows on the screen without additional tagging, just like sighted folks interpret images on web pages. 
For the moment, I can only demonstrate that many things are "audible" within soundscapes, not that they are "understandable". 
How could I show that the Chinese language makes sense and can be learnt? 
Unless you already know Chinese, you probably take it for granted, because many people apparently speak that language, but without such a priori historical evidence available, how does one go about proving things? 
I hope that Kynn will have some nice photographs of buildings or architecture, such that I can discuss how that translates into certain rhythms and sweeps for rows of gates, pillars and such plus the effect of visual perspective on that. 
Again, these soundscapes of complex scenes will currently not make sense to you without my explanation, but with an explanation, the various visual items should at least appear audible, thus illustrating the principles while hopefully adding an element of plausibility to the whole soundscape approach. 
For specific restricted environments such as the graphical user interface of the computer, dedicated solutions will always work much better and easier, just like O C R with synthetic speech for printed text is a lot faster and a lot less painful than trying to figure out printed text from the corresponding soundscapes of printed words. 
So in a sense my use of screen items to illustrate the soundscape technology may be a poor or perhaps even confusing choice, because I'm not proposing to use soundscapes for that, but merely wish to illustrate the generality of visual access offered by jumping into anything visual, even while better solutions do exist for a limited number of specific domains. 
What products are you referring to here? 
GPS systems? 
Electronic compasses? 
Talking signs? 
Even if this became feasible, and machine vision is far away from understanding anything but the simplest of scenes in very restricted environments, there would still remain the fundamental problem of getting either machine censorship to decide for you what is relevant or interesting to mention, or else allow for five minutes to hear all items in a single scene listed. 
With soundscapes, you get the raw uncensored visual information of a scene in one second, today, but the big burden of interpretation is indeed on you, the user. 
After all this "heavy" stuff, it may be useful to note that there are some easy applications of the software as well. 
For instance, it can act as a cheap color identifier: pressing function key F10 lets the software speak the color name of anything in the center of the view, be it a camera image, an imported image file or an image from your TWAIN scanner. 
There is also a built-in accessible graphing calculator for function plotting under function key F8. Sorry for this long-winded reply. 
Not everything is hard... Best wishes, Peter Meijer Soundscapes from The vOICe - Seeing with your Ears! Steve, what manual are you talking about here? 
Rich A free national library program of Braille and recorded materials for people with disabilities is administered by the National Library Service for the Blind and Physically Handicapped, Library of Congress. 
Their website url is I believe you are referring to the "Tape Recording Manual" produced by the National Braille Association, Inc. 
The manual provides instruction on procedures and techniques for producing high quality recordings and is an excellent reference manual for use during recording sessions. 
The manual can be obtained by emailing the Library of Congress or by writing: Volunteer Tape Recording Manual national Library Service for the Blind &amp; Physically Handicapped Library of Congress Washington, DC 20542 Cynthia D. Waddell ADA Coordinator City Manager Department City of San Jose, CA USA 801 North First Street, Room 460 San Jose, CA 95110-1704 (408)277-4034 (408)971-0134 TTY Steve, what manual are you talking about here? 
On Monday, November 22, 1999 2:31 PM, Steven McCaffrey Printing Rich Yes, that is the one I was thinkinng of. 
Thanks, Cynthia. 
-Steve "Waddell, Cynthia" cynthia.waddell@ci.sj.ca.us 11/23/99 01:22PM A free national library program of Braille and recorded materials for people with disabilities is administered by the National Library Service for the Blind and Physically Handicapped, Library of Congress. 
Their website url is I believe you are referring to the "Tape Recording Manual" produced by the National Braille Association, Inc. 
The manual provides instruction on procedures and techniques for producing high quality recordings and is an excellent reference manual for use during recording sessions. 
The manual can be obtained by emailing the Library of Congress or by writing: Volunteer Tape Recording Manual national Library Service for the Blind &amp; Physically Handicapped Library of Congress Washington, DC 20542 Cynthia D. Waddell ADA Coordinator City Manager Department City of San Jose, CA USA 801 North First Street, Room 460 San Jose, CA 95110-1704 (408)277-4034 (408)971-0134 TTY Steve, what manual are you talking about here? 
On Monday, November 22, 1999 2:31 PM, Steven McCaffrey Printing Rich Anything but the simplest geometric shapes was just noise to me. 
That is unavoidable in a general image-to-sound mapping, just like hearing a foreign language does not seem to make any sense at first. 
Still, I have now added a few more simple shape images to The vOICe Sonification Browser web page at These GIF images can be heard by first activating the sonification user agent dialog of The vOICe Learning Edition software by pressing Control U. Next, the above URL can be entered into the dialog, and pressing "Enter" will then parse the web page for image references and page links, which you can subsequently individually select and activate by again pressing "Enter" from another edit box within the same dialog. 
This procedure may take some getting-used-to, but it does allow you to hear any images on the web. 
If you already happen to know the exact URL of an image, you can also enter that image URL directly instead of the URL of a web page. 
The added example images on the above web page now include several variations of squares and circles, but also a photograph of the United States Whitehouse. 
The direct URL for this photograph is so you can also paste this URL directly into the sonification dialog to skip the page parsing and image selection procedure. 
Obviously, you will now not get the ALT-text description that you get from the user agent after it has parsed the HTML page. 
Can you hear out the six pillars at the center of the Whitehouse photograph? 
The sky is bright in this photograph, thus adding a high-pitched noise to the entire soundscape, while the pillars stand out near the center as six very brief noise bursts of somewhat lower pitch. 
Hardly a "real world application", I agree, just an illustration of how one can independently access visual information to at least some extent without a sighted person interpreting things for you. 
Best wishes, Peter Meijer Soundscapes from The vOICe - Seeing with your Ears! 
