Many of you may already have read this (or similar) reports, but nevertheless... 
A shame really, Patrick Patrick H. Lauke Webmaster / University of Salford Firstly, I realise Ian can stick up for himself, but I believe his comments were along the same theme as mine. 
That the RNIB could have achieved much more, and should have considering their market is not only blind users. 
So they could. 
Now I will address in a civil manner accusations levelled at Made For All's comments. 
XHTML does contain much inherent accessibility. 
The very first I am glad you choose to address these items - not accusations - in a civil manner. 
That benefits us all. 
I would be willing to wager that on the vast majority of occasions where a developer chose not to worry about accessibility but conform only to XHTML, her document would be far more accessible that someone who took neither into consideration. 
Good standards based development takes into account good Very well. 
Let me then set up a hypothetical situation. 
An author writes a document. 
He does not take into account any accessibility issues in particular, but he _does_ follow the grammar and spec of (a) HTML 4.01 Strict (b) XHTML 1.1 Our author now publishes both documents on the WWW. 
In both cases he conforms to good standards-based development guidelines, and the specifications in question. 
Would you still say that alternative (b) is, in terms of accessibilty, better than alternative (a) for the vast majority (and minority) of users ? 
XHTML does contain inherent benefits to accessibility. 
I'm sorry, but I have yet to see the proof for this. 
I know that XHTML contains *difficulties* with accessibility when done utterly right, i's dotted and t's crossed, but I have not seen a proof that it has an inherent *benefit*. 
- Tina Holmboe Greytower Technologies tina@greytower.net 
http://www.greytower.net/ 
[+46] 0708 557 905 I think the only accessibility difference between using valid HTML versus valid XHTML is that XHTML conforms to standard well-formed XML rules and could therefore be used and displayed by /any/ XML parser. 
The "accessibility" benefit doesn't necessarily relate to people with disabilities but instead just refers to "access for all". 
Of course, as someone else on the list has previously brought to our attention, XHTML causes problems with SGML-capable parsers so the benefits might be outweighed depending on your audience. 
I'm personally leaning toward support of newer XML parsers than SGML ones though. 
Cheers, James Such as what, though? 
XHTML also has the drawback that, if there is a single error, it will not display in any XHTML browser or XML parser. 
Note: If you have an XHTML document with an error -- say you forgot to close a tag -- and your browser displays it anyway, your browser is in VIOLATION of the XML standard. 
Any standards-compliant XHTML browser will reject invalid XML, if you declare your document as XHTML. 
HTML is more forgiving and thus more appropriate for general Web use. 
Why would you want to use XHTML in such a situation? 
--Kynn PS: Converting from valid HTML to valid XHTML (and thus being usable by any XML parser) is trivial. 
C.f. HTMLTidy. 
Kynn Bartlett kynn@idyllmtn.com http://kynn.com 
Chief Technologist, Idyll Mountain http://idyllmtn.com 
Author, CSS in 24 Hours http://cssin24hours.com Inland Anti-Empire Blog http://blog.kynn.com/iae 
Shock &amp; Awe Blog http://blog.kynn.com/shock 
Today, there's not much direct accessibility benefit, since most modern ATs are designed to work with HTML 4. (Personally, I think that HTML 4.01, its ancestors and error-ridden code are going to be with us for 5 years or more, but that's no reason to prolong it.) However, the benefits of XHTML continue to accrue over time. 
XHTML allows transformation using XSLT, which makes repurposing content more convenient. 
It can be built with profiles, such as XHTML+SMIL, or XHTML+MathML+SVG, which presents the opportunities for richer, more customizable interfaces than HTML alone. 
It'll be easier to embed metadata (including accessibility claims) into XHTML than using a zillion meta tags, as we do in HTML. 
So? Same's true of HTML 4.01 Strict: Amaya refuses to render invalid Strict content. 
But the other browser makers (rightly) assume that it's better to accommodate the user by working around errors in authored content than to punish them. 
m Where's the requirement that SGML-based HTML should not display an invalid Strict document? 
--Kynn Kynn Bartlett kynn@idyllmtn.com http://kynn.com 
Chief Technologist, Idyll Mountain http://idyllmtn.com 
Author, CSS in 24 Hours http://cssin24hours.com Inland Anti-Empire Blog http://blog.kynn.com/iae 
Shock &amp; Awe Blog http://blog.kynn.com/shock 
You're right, there is no MUST NOT clause in the Conforming User Agents section of the HTML 4.01 spec.[1] 
Nor is there one in the XHTML 1 spec.[2] In fact, they're pretty much identical in terms of recovering from elements and attributes they don't understand. 
The XHTML spec says that it has to parse the document as XML, but doesn't say thou shalt not render if it fails. 
[1] http://www.w3.org/TR/html401/appendix/notes.html#h-B.1 
[2] http://www.w3.org/TR/xhtml1/#uaconf 
From your reference [2]: A conforming user agent must meet all of the following criteria: 1. 
In order to be consistent with the XML 1.0 Recommendation [XML], the user agent must parse and evaluate an XHTML document for well-formedness. 
If the user agent claims to be a validating user agent, it must also validate documents against their referenced DTDs according to [XML]. 
From the reference [XML] above: well-formedness constraint [Definition: A rule which applies to all well-formed XML documents. 
Violations of well-formedness constraints are fatal errors.] 
Okay, so if an XHTML document is not well-formed, that's a fatal error. 
What should a user agent do with a fatal error? 
Let's see what else [XML] says: fatal error [Definition: An error which a conforming XML processor must detect and report to the application. 
After encountering a fatal error, the processor may continue processing the data to search for further errors and may report such errors to the application. 
In order to support correction of errors, the processor may make unprocessed data from the document (with intermingled character data and markup) available to the application. 
Once a fatal error is detected, however, the processor must not continue normal processing (i.e., it must not continue to pass character data and information about the document's logical structure to the application in the normal way).] 
Read the final "i.e." statement carefully. 
A browser is _not_ allowed to "recover gracefully" if it detects a problem (lack of well-formedness) in an XHTML document. 
At best, it can dump the source code in some way, but the XML parser is specifically _forbidden_ from trying to pretend as if it has a structured document. 
--Kynn Kynn Bartlett kynn@idyllmtn.com http://kynn.com 
Chief Technologist, Idyll Mountain http://idyllmtn.com 
Shock &amp; Awe Blog http://shock-awe.info 
Author, CSS in 24 Hours http://cssin24hours.com Inland Anti-Empire Blog http://inlandantiempire.org Following the robustness principal is NOT sloppy. 
Depending on it is. 
Maybe I missed it - what's the robustness principal? 
(principle?) Geoff Geoff, If it was defined, I also missed it. 
I'll try to provide one. 
If anyone feels they can do better, go right ahead. 
You won't hurt my feelings. 
LOL A general principle of robustness: be conservative in what you do, be liberal in what you accept from others. 
Under this principle, validators and programs that produce code should be as conservative as possible; user agents, since they accept code, should be as liberal as possible. 
Regards, Larry Following the robustness principal is NOT sloppy. 
Depending on it is. 
Yep, it was the principle that allowed Geoffrey to know I meant "principle" when I mis-typed it "principal". 
This doesn't *necessarily* mean that browsers should render broken XHTML though; that is one possible policy that would attempt to follow the basic principle, but there are other times when reporting an error is the best aid to the robustness of the whole system. 
One of the main reasons for the approach taken to the robustness principle with HTML4.0 and earlier was that it allowed HTML specs to be forward-compatible with later specs, and experimental extensions. 
The use of XML namespaces gives us mechanisms which allows us to do this in a somewhat more reliable way - at least a browser can tell when you are doing something it doesn't understand from when you are doing something it does understand but doing it wrong, so there is less need for that approach with XHTML. 
The other reason is that generally it's the best you can do when you have a possibly non-technical user on the opposite side of the world from a server whose contact information he can't obtain (because it keeps sending incorrect data). 
Personally what I would like browsers to do when they encounter broken XHTML is to report the error clearly, explain that what they are showing is a best-attempt to render and may contain inaccuracies, and then parse as text/html. 
The error message would be vital to developers and would help prevent disasters caused by the buggy code (which might lead to an important piece of information not rendering). 
The best-attempt rendering will allow users to continue with what they are doing as best the can in the circumstances. 
To my mind this gets the best of both worlds in such a scenario. 
Automated user-agents have different requirements in such scenarios. 
In general I would have them just consider the entire page to have failed. 
