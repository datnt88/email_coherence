Jonathan mentioned some facts about vocabulary and page complexity. 
E.g. people whose vocabulary is less than ~2k words. 
Are there lists of these words. 
Perhaps the evaluation tool could do a count of words outside the list for its ratings. 
Or, getting a bit more sophisticaed, if there's a list of probabilities that words are outside a persons vocabulary, then the measure could be the statistically expected number of words outside the vocabulary. 
There are various automated reading level measures around. 
Would any of those help? 
And I wonder if it would be possible to automate a measure of layout complexity? 
I remember there were measures like that in the old literature associated with forms on dumb terminals. 
Going further with this, how about measures of site complexity? 
Anyone know of any literature here? 
Len Leonard R. Kasday, Ph.D. Universal Design Engineer, Institute on Disabilities/UAP, and Adjunct Professor, Electrical Engineering Temple University Ritter Hall Annex, Room 423, Philadelphia, PA 19122 kasday@acm.org 
(215} 204-2247 (voice) (800) 750-7428 (TTY) Numerical measures are by their very nature unreliable, unfortunately. 
For example, what if you introduce a new word *and define it*, then use it lots of times? 
But more to the point, being told that "Your document has a rating of 12.0" is not at all helpful (as I find out when I type things into Microsoft Word and use its built-in grader). 
It's like saying "Your website is rubbish" without giving any indication of how to make it better. 
Maybe what we need is a spellcheck-like tool that helps with simplification where this is possible. 
Eg. on that sentence it could highlight 'simplification' and suggest 'making it easier' (among perhaps two or three others), or 'is possible' - 'can be done'. 
All we need is the database. 
(Of course, it would be harder to do if you wanted it to be possible in languages other than English as well....) Regards -- Silas S Brown, St John's College Cambridge UK http://epona.ucam.org/~ssb22/ 
"Do not put your trust in nobles, nor in the sons of earthling man, to whom no salvation belongs." - Psalm 146:3 measurement is the basis of science. 
I understand what you mean but you really do have to be careful that you're measuring what you really want to measure. 
You may prove anything by figures. 
And I'm not convinced that a simple word-counting algorithm can reliably say how easy it is to understand a page. 
Eg. the word 'incomprehensibilities' has 21 letters but most English people know what it means. 
But the word 'wan' has three letters and I'm surprised how many people don't know it (or at least have to think). 
And what about this: "One day Tanya went for a walk", etc etc (story mentioning Tanya hundreds of times). 
Suppose Tanya is not considered to be one of the words in the limited vocabulary, and the author gets told off for using it so much? 
That kind of thing would be enough to put me off using such a tool. 
I can see that there would be a loose correlation between the understandability of a document to a particular group of people and its statistics, but this does not mean that a statistics tool can label a document "guaranteed readable" or "guaranteed unreadable" with 100% accuracy. 
There is a danger in that authors might make changes to decrease their difficulty level according to the tool, but in so doing actually render the document harder to understand because they are using an unreliable tool. 
You can't have science without measurement, but there are so many variables here. 
You wouldn't be able to do much science if the only instrument you had gave you a single reading, being the average of temperature, pressure, current, voltage, weight etc. 
But if you had lots of instruments and you don't understand science, you'd be bewildered. 
I think the best test of "is a page easy to understand" is to try it out on someone. 
Regards -- Silas S Brown, St John's College Cambridge UK http://epona.ucam.org/~ssb22/ 
"They get caught by the ideas that they have thought up" - Psalm 10:2 Let me describe my experience with the grammar checker in Microsoft Word. 
Most of the time I don't use it. 
But as you may have noticed, I do have a great capability to write things that are hard to understand. 
When I do use the grammar checker, I find that the majority of warnings are things that I ignore. 
On the other hand, I feel that the minority of warnings where I go back and re-write are valuable enough so that using the checker was worth the time I put into it. 
The tool helps me find gratuitous roadblocks I have left in the reader's way. 
It is a lot like Bobby. 
The _best_ test of "is a page accessible" is to try it out on someone, but I would not want to waste people's time doing live evaluations of sites that had not been Bobby-checked first. 
Al If I remember right (don't have all books with me here in Boston). 
There was something on this in Helanders book by Tullis Helander, M. (ed, 1988) Handbook of human-computer interaction. 
Amsterdam: Elsevier Also I think Edward Tufte has written something on this, but I would need to do more research to find the exact references. 
The measurings were based on how much white space the page had and how it was distributed to form groups. 
The interfaces were mostly alphanumeric. 
This naturally is just the tip of the iceberg. 
There many important things that simplify the presentation of data but are hard to measure in a scale. 
Marja For pointers to several flavors of "Easy English" word lists see: www.hd.uib.no/corpora/1998-3/0211.html At one time, military manuals were to be constrained to such limited vocabularies -- 500 to 2000 words, no multi-meaning words, simple action verb, active voice, short sentences, etc. 
At that time Flesch-Kincaid readability measures were required to be low enough grade-level that soldiers needing to learn from such manuals would have the appropriate vocabulary to understand them. 
Another important use was for international air traffic. 
Simple, unambiguous english was used world-wide, except for a while in Quebec. 
Likewise, all ATA manuals were written in that simple english, so mechanics of many natural languages need only learn that small English vocabulary to understand what to do to maintain the aircraft. 
I note that Readability scores are available in Microsoft Word '97: Flesch Reading Ease, and Flesch-Kincaid Grade level score. 
Another terse page comparing a variety of readability scoring methods is www.writepage.com/writing/gramchek.htm 
I certainly feel 'white space' is critical to understanding, at our site we have 9 rather small icons each centred in a box of a large 3x3 grid. 
I would be very pleased to discuss this further especially with reference to particular sites. 
jay 
