[In response to Tim] I should note again that I actually sympathise *strongly* with the hard-minimalist side, because I have also argued from that perspective more than once. 
However given the history of such things in Asia, and especially Japan, I will tell you that it will cause more problems than most are aware. 
In the short term, it clearly ridiculous for XML to try to support all these. 
In the hard-minimalist world, everybody has to do exactly the same thing, whether they're operating in ISO-Latin1, EUC, or 11-bit reverse-polarity Ojibway: 
I have never argued that all XML parsers needs to support all encodings. 
I have only said that we should give XML parsers freedom to support the encodings they choose to (I could even go as far as to say that we might perhaps require that all XML parser be able to at least *accept* data in UTF-8 and UCS-2, though that would also prescribe certain implementation details, which I feel to be undesirable). 
I would argue that at the moment, UTF8 is the clear favorite in terms of a format that you'd want to build universal converters to and from. 
Except that it bloats data size for certain languages... 
But the gains in simplicity, robustness, and performance that are going to come from a programmer being able to address an XML byte stream directly, particularly a byte stream on which we can use the tools we have today, are immense. 
I suspect such programmers will have enough real input problems dealing with disk files and socket feeds and OODBMS blobs and RDBMS tuple sequences - let's not make it any harder. 
It's not any harder, just different. 
We can write an SGML declaration to support 10646/UTF8. 
We can also write one to support 10646/UCS2. 
Can we get away with having 0xfffe at the front of the file and still be SGML-compliant? 
This is a red herring. 
I have always said that we should fix the document character set to ISO 10646. 
I am far from convinced thatthe consequences of going with "XML is UTF8" are serious at all. 
(In practical terms, the consequences of not supporting ISO-Latin-X and JIS are much more serious, but (sorry Gavin) we are probably heading in that direction.) 
If we follow this route, I will guarantee that people will build non-conformant systems, and use them (witness the WWW). 
We should recognise this up front, and give people the flexibility to build such systems in a conformant manner, with a warning that they face incompatability in using anthing other than UTF-8 or UTF-16. 
5. Network problems of self-labelling (Ref. 
design principle #1) 
This is a red herring. 
There are standards that are in place. 
Standards are meant to be conformed to. 
Finally, emailing XML is going to present some problems anyhow - but clearly will be a desirable thing to do - having one hardwired encoding will simplify this. 
How? I 
VRML2 is UTF8, period. 
Java is (supposed to be) UTF8, period. 
VRML2 is UTF-8, yes. 
I argued against this, and some sites in Japan already have data that use iso-2022-jp. 
Java is not UTF-8, nor ever was. 
Java is UNICODE based (the char in JAVA is 16 bits, and character classification takes place via UNICODE). 
However, JAVA also has the notion of "localised input streams", which basically are an I/O streams with a X - UNICODE converter on them. 
I should note that there are a number of efforts to "localise" JAVA in Japan (ie, to make SJIS versions). 
7. Problems of external entities (Ref. 
design principles 1 and 3) 
Given correct protocol-level labelling (as is in HTTP 1.1, and MIME) this is a non-problem. 
If I'm going to write a program for processing XML, I'm going to use the tools I have on the computer that sits in front of me. 
They can deal with UTF8 today. 
Thus, I'm going to write a pure UTF8 program, with callouts to converters for interchange with various other facilities. 
I'm going to write a *proper* application that does the following: StorageObject object = network.fetch(entity.get_system_id()); 
InputStream stream = new InputStream(object.get_stream(), object.get_encoding()); 
InputStream::InputStream(InputStream stream, String encoding) m_decoder = Decoder::resolve(encoding); m_stream = stream; m_decoder.initialise_stream(stream); 
What if we were to: a) require parsers to accept UTF-8 input b) recommend supporting UCS-2 input c) permit supporting any other encoding as input d) require parsers to be able to write out a UTF-8, structurally equivalent, canonical XML for their input (they may provide any other output/API forms they want, but this one would be required) Some big wins from a canonical form, especially one that is in a specific character set and encoding: 
a) Once you've parsed an XML document once, all further parses must produce an absolutely byte-identical copy of the XML document that came back from that first parse. 
I believe the right term for this is "idempotence". 
This makes parser conformance testing trivial. 
b) Authenticating parser output becomes a reliable way to authenticate the data. 
A recipient can tell if it got the right information, even if the sender expressed it somehow differently but it reduces to the same thing (even if we eschew all minimization, we'll probably allow multiple spaces between attribute values, and other non-information-bearing alternatives). 
c) It forces us to enumerate exactly what aspects of the *representation* consitute information, and what aspects do not. 
For example, if SGML had a canonical form in which spaces around the "=" in attribute specification lists were gone, it could easily state that no process may depend upon such spaces to make some processing distinction: all it need state is that "processig semantics must be driven only by information in the canonical form". 
digression type="nerd.linguist" 
(c) is almost exactly like Chomsky's early insistence that semantics be determined at the level of deep syntactic structure, and that syntactic transformations do not change the formal meaning of sentences. 
This proved untenable in natural language for discourse and other reasons, but it can easily be maintained in formal languages (like all computer languages). 
/digression Steve 
We can write an SGML declaration to support 10646/UTF8. 
We can also write one to support 10646/UCS2. 
Can we get away with having 0xfffe at the front of the file and still be SGML-compliant? 
I'm not presently taking sides on this issue, but I do want to answer Tim's question. 
Yes, you can have 0xfffe at the front of the *file*, but not in an SGML *entity*. 
(Remember, an entity needn't be the only thing in its storage object.) 
You could also, using the FSI mechanism, define appropriate XML encoding attribute(s) that would allow the XML encoding choices (whether two or many) to be specified for any storage manager. 
Charles F. Goldfarb * Information Management Consulting * +1(408)867-5553 13075 Paramount Drive * Saratoga CA 95070 * USA International Standards Editor * ISO 8879 SGML * ISO/IEC 10744 HyTime Prentice-Hall Series Editor * CFG Series on Open Information Management 
I wouldn't write anything like that. 
If you're writing a program to handle UTF-8 data and it does any non-trivial manipulation of the data (such as displaying it), the first thing you typically do is combine the bytes representing each character into a single integer (usually a wchar_t). 
The program then processes this stream of wchar_t's just as a non-Unicode program would process a stream of char's. 
The conversion from UTF-8 to wchar_t is quite complicated and expensive. 
The conversion from UCS-2 to wchar_t is very simple. 
In fact, it is often a noop (if your wchar_t is 16 bits and bytes don't need to be swapped). 
So what I would end up doing would be in effect converting everything to UCS-2 or UCS-4. 
That's why I think UCS-2/UTF-16 has just as much right as UTF-8 to be considered the canonical way of encoding Unicode/ISO 10646. 
James 
I have no problem with a canonical form, so long as it doesn't stop people using other forms. 
This would necessarily take 2 passes for validation: Pass 1: Resolve entity references etc. convert to UTF-8, generate document. 
Pass 2: Parse document, generate document, compare results. 
Though things like empty elements and RE/RS complicate this no end. 
