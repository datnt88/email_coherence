Andrew C. Bulhak suggested: 
When embedding a font in a document, the font per se would not be embedded; rather, a table of common digraphs and trigraphs (two- and three-character sequences) in the text is built up. 
For each polygraphic sequence, the respective characters are ligatured automatically, using kerning information, into a synthetic glyph. 
That way, most if not all characters in a document can be displayed using these glyphs, which are in an encoding unique to the document. 
To pirate the font, as with the random encoding, the pirate would have to extract the outline data into an editable format and use an editor to manually pull apart the characters, which would be rather laborious. 
However, this would not impede searching; the text can be stored in standard ASCII, and converted into the ligated encoding within the browser. 
Since there is no one-to-one mapping, the font cannot easily be automatically broken up into a normal font. 
That's a really interesting idea. 
But don't confines on the size of a character set (commonly one byte) limit the space for these multigraphs (polygraphs?) If the basic principle is that a document which makes no use of the paragraph mark could rely upon the substitution of an "nn" digraph for this character (for instance), wouldn't the transmission of a single document featuring the full character set defeat this sort of protection, by indicating no "free" glyphs? 
Also, I don't think it's mathematically possible to dissect even the most rudimentary English into enough digraphs to no longer require the presence of discrete glyphs. 
Still an intriguing prospect, though. 
Jonathan Hoefler The Hoefler Type Foundry, Inc. www.typography.com 
This is somewhat along the lines of the randomised-encoding idea floated here, only more amenable to searching of text. 
When embedding a font in a document, the font per se would not be embedded; rather, a table of common digraphs and trigraphs (two- and three-character sequences) in the text is built up. 
For each polygraphic sequence, the respective characters are ligatured automatically, using kerning information, into a synthetic glyph. 
That way, most if not all characters in a document can be displayed using these glyphs, which are in an encoding unique to the document. 
To pirate the font, as with the random encoding, the pirate would have to extract the outline data into an editable format and use an editor to manually pull apart the characters, which would be rather laborious. 
However, this would not impede searching; the text can be stored in standard ASCII, and converted into the ligated encoding within the browser. 
Since there is no one-to-one mapping, the font cannot easily be automatically broken up into a normal font. 
Just my $0.02; -- acb acb@dev.null.org -- Mumbles 
[The Hoefler Type Foundry] 
Since the encoding is worked out at document creation time, not 
necessarily. 
If one wants to send t e x t l i k e t h i s, glyphs for "t h" can be generated and such. 
If one wants to 
send complete alphabets with various bozotic spacings, they just make for a bigger document. 
And if they want to send a document consisting of one character per line, then they're probably up to no good... ;-) 
Perhaps; but if you have half a dozen discrete glyphs here and there, that doesn't jeopardise the purpose of the encoding method, being to make piracy bloody hard. 
It may be possible to design the glyph mapping algorithm to skew the probabilities so that certain characters predominate among the discrete glyphs, making the "collect-enough-documents- to-extract-a-complete-font" approach even less plausible. 
acb@dev.null.org -- Mumbles 
But you have no idea where the line breaks are until the document is formatted on the user's scren. 
It depends on the window size in pixels. 
So you can't really include spaces unbless they are no-break nonpaddable spaces. 
Well, most HTML browsers right now can't even do full left &amp;right justification (or quadding, call it what you will), but I am sure they will do so before long. 
Actually MSIE probably does already, now they have style sheets, but I haven't checked. 
I really don't think this approach is worth it. 
The bandwidth used by the Web is already large, and if it takes even longer to download a page than now, embedded fonts won't get very far. 
That's a bit of a dangerous argument, since inline images became popular awfully quickly in 1993/4 despite complaints of modem users. 
But I still don't think there's any reason to be this extreme. 
It also doesn't help. 
There is a trivial algorithm to undo it. 
If you have bitmaps for [hi] and for [i], you can subtract the [i] bitmap from the right hand edge of the [hi] bitmap. 
If you have several letter pairs, you can also recover the kerning pairs this way. 
If you have [hi] and [in], you can overlap them until the first set bit in each column in [in], counting from the left, exactly corresponds to the last unset bit in [hi]; at that point, you have a bitmap for [hin], and can now invert the [in] bitmap to erase all of the [i] pixels. 
Any competent C programmer can do that in under a day. 
If they are outlines instead, it's even eaier. 
Scrambled encodings with a clear document actually have a similar problem, but don't waste bandwidth, so I suggested it as a simple step so that the outline font on its way to the printer can't usefully be reused directly. 
Of course, the font should have a normal encoding vector, so it's really scrambled character definitions. 
Neither proposal is sufficient to protect fonts over the web, though. 
Lee 
