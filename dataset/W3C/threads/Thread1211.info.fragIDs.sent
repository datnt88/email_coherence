FYI: this Last Call seems to be under current IESG discussion. 
My personal opinion is that it should have gone Informational. 
Harald A 
From: The IESG iesg-secretary@ietf.org SUBJECT: Last Call: UTF-16, an encoding of ISO 10646 to Proposed Reply-to: iesg@ietf.org 
Date: Mon, 23 Aug 1999 07:12:18 -0400 Sender: scoya@cnri.reston.va.us 
The original Last Call notice was incorrect in that it stated the intended status as Informational. 
This document will be considered for Proposed Standard. 
The Last Call expiration date is unchanged. 
The IESG has received a request to consider UTF-16, an encoding of ISO 10646 draft-hoffman-utf16-04.txt as Proposed Standard. 
This has been reviewed in the IETF but is not the product of an IETF Working Group. 
The IESG plans to make a decision in the next few weeks, and solicits final comments on this action. 
Please send any comments to the iesg@ietf.org 
or ietf@ietf.org 
mailing lists by September 13, 1999. 
Files can be obtained via 
Harald Tveit Alvestrand, EDB Maxware, Norway Harald.Alvestrand@edb.maxware.no 
If we ever get to the point of putting XML-based protocols on standards track *and* we want to allow those protocols to use UTF-16/LE/BE (because this is allowed by the W3C's XML standard), then I think the UTF-16 document should be on standards track. 
I could certainly see a world where we want XML-based protocols where UTF-16/BE/LE are prohibited; that would be a good world. 
But if we want to allow interoperable UTF-16 in standards track documents, I think this should be on standards track. 
--Paul Hoffman, Director --Internet Mail Consortium 
Standards-track documents *can* refer to informational documents. 
I can certainly see placing XML-based things on the standards track with language that says "MUST use either UTF-8 or UTF-16; SHOULD use UTF-8". 
Weakened beyond that, I start feeling unhappy about the XML-based spec, not about the sanctity of the references. 
There's a reason why we have humans to make these judgment calls. 
Harald A Harald Tveit Alvestrand, EDB Maxware, Norway Harald.Alvestrand@edb.maxware.no 
Hi folks, I agree with Harald's judgment that Informational and *not* Proposed Standard is appropriate. 
The IETF has done a good job of updating core IETF protocols to prefer or require 
UTF-8. 
Over the wire, UTF-16 has a long list of drawbacks and no visible advantages. 
It shouldn't be 'legitimized' by IETF Proposed Standard designation. 
My two cents, - Ira McDonald High North Inc 
I think the distinction is not that important in this case, I could live with both. 
But it would be great to see this getting done soon. 
It has been a long time. 
Regards, Martin. 
#-#-# Martin J. Du"rst, World Wide Web Consortium #-#-# mailto:duerst@w3.org 
http://www.w3.org 
With that sentiment, I fully agree. 
Harald Harald Tveit Alvestrand, EDB Maxware, Norway Harald.Alvestrand@edb.maxware.no 
I wouldn't really object to Informative instead of PS, but would like to hear more about that "long list of drawbacks". 
My own list is rather short and parts of it are related to C string and ASCII-thinking and will disappear over time. 
I also have a (short) list of advantages. 
Fran?ois Yergeau 
My list of disadvantages: - No compatibility with cstrings due to NULL 
- Inability to represent characters outside Planes 0-16 
- VERY bad expansion factor for characters outside Plane 0 (100% overhead) 
- No ability to mix ASCII and UTF-16 elements in a simple viewer 
- Two incompatible byte orders 
My list of advantages: - Does not require conversion between UCS-2 and UTF-16 when only Plane 0 characters are used in the UTF-16 
Note that the single advantage may be listed as a disadvantage if there turns out to be lots of applications that "support" UTF-16 the way they currently "support" Unicode - by throwing away the high-order bits.... Harald A Harald Tveit Alvestrand, EDB Maxware, Norway Harald.Alvestrand@edb.maxware.no 
Plus mine makes three. 
Hi folks, Harald did a good job of concisely listed disadvantages of UTF-16 over the wire and one (possible) advantage. 
Since Informational has a long history of being used to publich 'for the benefit' of the Internet community' standards from some other standards body or vendor, please let's move forward and register it as Informational. 
I'd be delighted to see the sense of Harald's list of disadvantages captured in the actual IANA charset registration, so that implementors are sure to see the 'BEWARE'. 
In a local file store, UTF-16 has some questionable advantages. 
Over the wire, it just decreases significantly the probability of interworking. 
The IETF and the UNIX operating system community had it just right when they chose to standardize on UTF-8 based interfaces. 
I also agree with Martin's sentiment that we should just get this done and published as an RFC. 
There is a lot of ambiguous XML leaking into the real world by unsafe interfaces. 
Cheers, - Ira McDonald PS - I think that Harald's point about having terrible expansion for characters outside of Plane 0 (BMP) is very important over the wire. 
Unicode 3.0 has come markedly closer to *filling* the spare space in Plane 0. 
I concur with some of Harald's list of disadvantages for UTF-16 as an interchange format, but find myself puzzled by some of the others: 
This is an obvious problem for interworking with API's that use 8-bit character sets. 
But I agree with Fran?ois that this issue will disappear over time as people create appropriate interfaces to work with 16-bit strings. 
The real issue is not the NULL's but the datatype difference. 
WG2 and UTC are converging on a point of view that characters outside of Planes 0-16 should *never* be assigned. 
This may be formally written into 10646. 
The rationale here is that nearly all 10646 implementations are following the Unicode Standard, by necessity, to achieve interoperability in areas that are left unspecified by 10646. 
Formalizing this convergence by constraining the code space range that could ever be assigned standard characters would close down this nagging issue of incompatibility between the Unicode Standard and 10646. 
In that case, UTF-8, UTF-16, and UTF-32 would *all* have the exact same representational capability, and would all be completely interconvertible forms. 
This claim I do not understand at all: scalar valueUTF-8UTF-16UTF-32 0..7F124 80..7FF224 800..FFFD324 10000..10FFFD444 The only size advantage for UTF-8 is for ASCII values, and UTF-16 has the clear size advantage for East Asian data. 
This is a very important transitional and developmental advantage for UTF-8, absolutely. 
Also an admitted problem for UTF-16 and UTF-32, but not significantly more complex that defining interchange formats for any datatype that has to be expressed in machine words larger than a byte wide. 
UCS-2 is a dead issue in any case. 
All Unicode implementations should at this point formally be UTF-16 implementations, whether they are actually supporting the interpretation of surrogate pairs or not. 
If they are claiming conformance to Unicode 2.0 or higher, then they are UTF-16. 
--Ken 
Ah, this is what I had in mind with my "C string and ASCII-thinking". 
It's real, but of limited scope. 
There's a corresponding advantage when you think "Java and Unicode" instead of "C and ASCII". 
In other words, it's not an intrinsic disadvantage or advantage, it depends on the programming environment. 
Real but very theoretical. 
In addition to what he wrote, Ken Whistler should have mentionned his calculation of when those planes will fill up if we maintain the current allocation rate (unlikely, most things of import are already done or in the pipeline). 
I don't remember the target date offhand, but I think it was 23rd century. 
Oops! There's not much size difference between a 4-byte UTF-8 character and a 4-byte UTF-16 character. 
It's no harder to mix ASCII with UTF-16 than to mix ASCII with any other charset. 
You just transcode to your favorite encoding of Unicode and you're done. 
That one is really, really real. 
Plus the size advantage in plain text for many languages, some of them important in practice. 
As Ken pointed out, UTF-8 is denser only for ASCII. 
That said, I will concur with Martin, Harald and Ira: the important thing at this time is to get this out the door, not whether it's Info or PS. Fran?ois Yergeau 
See http://www.unicode.org/pending/pending.html It's entirely possible that all commonly used scripts will be encoded in Plane 0 (if those who fight for traditional Chinese and more precomposed characters give up), but I don't think it's likely that ISO will abandon Plane 1. 
Yes. My mistake; I didn't count properly. 
Harald Harald Tveit Alvestrand, EDB Maxware, Norway Harald.Alvestrand@edb.maxware.no 
Harald, 
I think we may be talking at cross-purposes here. 
*I* am responsible for maintaining the content of http://www.unicode.org/pending/pending.html, by the way. 
UTC and ISO/JTC1/SC2/WG2 *both* are committed to allowing encoding in Planes 0..16. 
The voting on ISO/IEC 10646-2 is already underway, with encoded characters 
in Plane 1 (Etruscan, Gothic, Deseret, Byzantine and Western musical 
symbols, mathematical alphanumeric symbols) and in Plane 2 ( 47000 more Han characters for Vertical Extension B) and in Plane 14 (language tag characters). 
Other than a few technical details here and there that may change, it is quite likely that the entire collection will pass ballot and become part of 10646 (and shortly thereafter, Unicode 3.1 or 4.0). 
What Planes 0..16 give us are: Plane 0: BMP 49194 characters assigned 6400 private use 2048 surrogate codes 65 control codes 2 not characters 7827 still assignable code points Plane 1: SMP ~1600 characters (alphabets &amp; symbols) under ballot ~64000 still assignable code points 
Plane 2: SIP ~47000 Han characters (Vertical Extension B) under ballot ~18500 still assignable code points 
Plane 3: SIP2 65534 still assignable code points (probably for more Han) Planes 4..13 655340 still assignable code points Plane 14: SPP 97 language tag characters underballot 65437 still assignable code points Planes 15..16 131068 private use As Fran?ois pointed out, we are running out of characters to encode. 
Even the IRG, busily culling the vast history of Han character usage throughout East Asia, has put the bulk of its remaining backlog into ballot for Plane 2 (the 47000+ for Vertical Extension B). 
After that, Han will come in relative dribs and drabs and get more and more obscure. 
The standards committees are already getting deadlocked about how to proceed with the historic scripts -- particularly the relatively large ones like hieroglyphics -- so after the publication of 10646-2, the script additions will slow down dramatically. 
It will take another decade at least to fill Plane 1 will the candidates we already know for encoding (and that includes *all* of the big hieroglyphic dead scripts like Egyptian, Sumerian, Hittite, Mayan, and Indus Valley). 
So that big gap in planes 4..13 looms unused and effectively unusable. 
Nobody in the professional character encoding community has any candidates to put there that would really count as characters. 
There are various bizarre schemes that could eat numbers, but as long as 10646 and the Unicode Standard remain *character* encoding standards, it is quite likely that those 10 planes will simply be held in reserve. 
This is enough engineering slack on the character encoding to last through this upcoming century easily, even if the World Congress on Universal Orthography decides to invent and impose a new world orthography each and every decade. 
:-) That is why the UTC and WG2 just want to formally close the books on this. 
16 bits turned out not to be enough for everything that somebody wanted to encode as characters. 
But all projections are that 21 bits *is* enough, and we can hold the line there. 
Nobody needs 31 bits for character encoding. 
--Ken 
Oops....apologies; I managed to read your 0..16 as "0". 
That's my second stupid error this debate.....my brain must be rotting.... 
[haring off on an unrelated topic] one thing I'm not connected enough to have found out: Is this large set *new* characters, or are parts of the set used for rolling back the unifications that created so much tension in and around the IRG, for people who want that? 
I read you. 
And see no reason to disagree. 
A pity that 21 is not a power of 2.....but that's well beyond the ability of standards comittees to accomplish. 
Harald Harald Tveit Alvestrand, EDB Maxware, Norway Harald.Alvestrand@edb.maxware.no 
Even Japanese textbooks for junior high school chemistry require "traditional Chinese and more precomposed characters". 
Non-BMP characters are absolutely necessary. 
Makoto Fuji Xerox Information Systems E-mail: murata.makoto@fujixerox.co.jp 
This will start heated discussion and will cause significant delay. 
I would like to see UTF-16 registered without further delay. 
Makoto Fuji Xerox Information Systems E-mail: murata.makoto@fujixerox.co.jp 
FWIW, I agree too. 
Get the thing out the door. 
As Informational. 
Harald Harald Tveit Alvestrand, EDB Maxware, Norway Harald.Alvestrand@edb.maxware.no 
Ditto. Ned 
Hi folks, I agree. 
Let's get this registration and RFC out the door as Informational. 
And thanks to Paul and Francois for their excellent efforts to write up a (politically) difficult charset registration. 
Ship it! 
Cheers, - Ira McDonald PS - I've just unsubscribed from my old (soon to die) Xerox email address and resubscribed from my new email address at Sharp Labs America. 
Please send me notes in the future at: imcdonald@sharplabs.com. 
