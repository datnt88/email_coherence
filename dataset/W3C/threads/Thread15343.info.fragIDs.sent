Ian Jacobs, 06 Oct 2002 The provisions of this checkpoint are not verifiable. 
Instead, these design goals are XAG design goals and should be manifest in that specification (though in more concrete terms). 
Perhaps this is the checkpoint that should read "Use formats that conform to XAG." The requirements of Checkpoint 5.3 require device-independence, inclusion of accessibility features, require publicly documented interfaces for accessibility, and require the use of the operating system for certain applications. 
I'm not an expert on XAG, but my concern is that XAG is only a supporting specification of the WCAG that deals with XML and some of the other standards. 
Standard markups and CSS do not fall within the XAG area of responsibility. 
If a developer is not using XML they would have no reason to look for information inside XAG for specifications or requirements. 
Requiring a developer that is only working with HTML and CSS to meet the requirements of XAG will only chase people away because they would consider the information "not relevant" to their particular needs. 
Sun (via Earl Johnson), 27 Oct 2002 How about, "Choose technologies that programmatically support, expose, and make possible building content that meets the WCAG." Although, it is hard to tell exactly what this checkpoint applies to. 
Perhaps it would be better to put the jist of this feedback (structure and content must be programmatically available to an AT) into Guideline 5's wording or into 5.1 or 5.4 IBM (via Andi Snow-Weaver), 29 Oct 2002 This is an important consideration but should not be a checkpoint. 
If you meet all the checkpoints, then you have obviously done this. 
If you haven't, then what difference does this make? 
SAP (via Audrey Weinland), 31 Oct 2002 *The baseline AT needs to be defined. 
Otherwise it's too difficult to figure out which AT to support. 
*minimum level #1 subpoint #3: Not sure what this means. 
What are publicly documented interfaces? 
*minimum level #1 subpoint #5: Not sure what this means. 
Please clarify. 
Sun's recommendation provides some insight into issues that would otherwise be left open. 
I recommend we use their wording, "Choose technologies that programmatically support, expose, and make possible building content that meets the WCAG." 
This would then require the following elements be clearly expressed: 1. device-independence (Checkpoint 2.1 defines character input, but does not specifically require non-character input as in other methods of navigation used by disabled persons - designers typically do not consider mouse inputs as character inputs because they are not associated with keyboards and speech navigation is clearly not understood as a character input), 2. include accessibility features (this would require that applets, PDF's, Flash, and any other technology that comes along to meet the requirements of this checkpoint), 3. have publicly documented interfaces for interoperability (this would require action on two parts - first the developer of the technology to provide documentation on how to develop with accessibility in mind, and then the part of the designer using the technology with the accessibility features in mind) 4. make use of operating system accessibility features (either directly or via the user agent) supported by assistive technologies in the natural language(s) of the content (this would require that the designer ensure the technology being used is supported in the natural language of the content, thereby ensuring that the disabled population related to that natural language can utilize the content), 5. are implemented in user agents and/or proxies in the natural language(s) of the content ***** this point can be deleted because it is clearly required by subpoint 4. Sincerely, Lee Roberts President/CEO 405-321-6372 Rose Rock Design, Inc. 
The term "device independence" keeps coming up. 
So I would like to write something here to spur a dialog that will let us clear this concept up as it relates to accessibility. 
The term device independence has always been a very confusing term. 
If device independence means anything other than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" then I do not think that we want or need it. 
In fact I do not see how it could even be possible. 
If the goal is to allow content to be accessed from PDAs, by Voice, by keyboard etc. then "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" will get you this. 
If you would like to ALSO add mouse control to make some tasks easier. 
That is fine. 
But we should not require it - and, as I said above, I don't even think it is possible. 
Since text input is sometimes required as a part of web content interaction, it would mean that text input would have to be possible using just a mouse. 
This in turn would require that every single page that required text input have a keyboard on the page and a script to drive it. 
If an external on-screen keyboard is used - then you are using keyboard input to the content - not mouse. 
And if a keyboard on the page is used then you are requiring that a script be used and the page would fail if the script did not run. 
Help me here. 
1) what does "device independence" mean? 
2) independence from what? 
3) does it require that all content be usable with a mouse only? 
(if so - how could this be done? 
Remember an on screen keyboard that is not part of the content is just a keyboard and the content would be receiving keyboard input.) 4) does it require that all content be usable with a keyboard only? 
5) does it require anything else? 
How does device independence make things any more accessible than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" (I am presuming that device independence does not mean "also support a mouse where that is a good interface practice". 
That would make the pages more accessible but does not sound like device independence because it doesn't make the content independent of any device or input method. 
It is just good user interface design practice that makes the page more usable). 
Help me if you can. 
Am I missing something? 
Thanks Gregg Gregg C Vanderheiden Ph.D. Professor - Ind. Engr. 
&amp; BioMed Engr. 
Director - Trace R &amp; D Center University of Wisconsin-Madison 
My goal with "device independence" is to get people to quit using _scrap code_ that requires a mouse to perform the functions. 
All these onmouseover, onmouseout, onclick, ondblclick, and such do not work for everyone. 
I've talked to more developers than I can count that didn't even know onselect, onfocus, onblur existed and then wanted to know what they were for when I explained they should be using them. 
I don't think we should limit accessibility to just keyboard or keyboard interfaces. 
Wireless devices will provide some interesting advancements what will likely move into the desktop arena. 
One device I've seen that could work well in computing is the same tool helicopter pilots use to aim their canons. 
With that tool, I see mouse usage going away. 
We don't know when the next evolution of the WCAG will be started or the technologies available. 
It should be our goal to open the door to other technologies, so those technologies will have some guidance on how to be used to provide accessible interfaces and content. 
Lee Behalf Of Gregg Vanderheiden The term "device independence" keeps coming up. 
So I would like to write something here to spur a dialog that will let us clear this concept up as it relates to accessibility. 
The term device independence has always been a very confusing term. 
If device independence means anything other than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" then I do not think that we want or need it. 
In fact I do not see how it could even be possible. 
If the goal is to allow content to be accessed from PDAs, by Voice, by keyboard etc. then "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" will get you this. 
If you would like to ALSO add mouse control to make some tasks easier. 
That is fine. 
But we should not require it - and, as I said above, I don't even think it is possible. 
Since text input is sometimes required as a part of web content interaction, it would mean that text input would have to be possible using just a mouse. 
This in turn would require that every single page that required text input have a keyboard on the page and a script to drive it. 
If an external on-screen keyboard is used - then you are using keyboard input to the content - not mouse. 
And if a keyboard on the page is used then you are requiring that a script be used and the page would fail if the script did not run. 
Help me here. 
1) what does "device independence" mean? 
2) independence from what? 
3) does it require that all content be usable with a mouse only? 
(if so - how could this be done? 
Remember an on screen keyboard that is not part of the content is just a keyboard and the content would be receiving keyboard input.) 4) does it require that all content be usable with a keyboard only? 
5) does it require anything else? 
How does device independence make things any more accessible than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" (I am presuming that device independence does not mean "also support a mouse where that is a good interface practice". 
That would make the pages more accessible but does not sound like device independence because it doesn't make the content independent of any device or input method. 
It is just good user interface design practice that makes the page more usable). 
Help me if you can. 
Am I missing something? 
Thanks Gregg Gregg C Vanderheiden Ph.D. Professor - Ind. Engr. 
&amp; BioMed Engr. 
Director - Trace R &amp; D Center University of Wisconsin-Madison 
Hi Lee. 
I understand the first part about not using Mouseover etc. and agree. 
And I believe that would be met by what was proposed. 
(e.g. must be operable from keyboard). 
I don't understand your second part about not wanting things to be keyboard only. 
The proposal just says it must be keyboard operable. 
Not that you can't have it do other things as well. 
I presume you don't want to lose keyboard operability in favor of other things (i.e. mouse only or pointer only"). 
So are you just asking that it be written so that it doesn't sound like Keyboard only? 
Does the following meet your requirement/concern? "All content functionality must be usable by (from?) a keyboard or keyboard interface if the function or its result can be concisely expressed in words. 
NOTE: Other interface methods such as pointing can and should be supported in parallel with keyboard operability as appropriate, but keyboard operation is always required for functionality whose name or result can be concisely expressed in words." 
Thanks Gregg Gregg C Vanderheiden Ph.D. Professor - Ind. Engr. 
&amp; BioMed Engr. 
Director - Trace R &amp; D Center University of Wisconsin-Madison Of Lee Roberts My goal with "device independence" is to get people to quit using _scrap code_ that requires a mouse to perform the functions. 
All these onmouseover, onmouseout, onclick, ondblclick, and such do not work for everyone. 
I've talked to more developers than I can count that didn't even know onselect, onfocus, onblur existed and then wanted to know what they were for when I explained they should be using them. 
I don't think we should limit accessibility to just keyboard or keyboard interfaces. 
Wireless devices will provide some interesting advancements what will likely move into the desktop arena. 
One device I've seen that could work well in computing is the same tool helicopter pilots use to aim their canons. 
With that tool, I see mouse usage going away. 
We don't know when the next evolution of the WCAG will be started or the technologies available. 
It should be our goal to open the door to other technologies, so those technologies will have some guidance on how to be used to provide accessible interfaces and content. 
Lee -----Original Message----- Of Gregg Vanderheiden The term "device independence" keeps coming up. 
So I would like to write something here to spur a dialog that will let us clear this concept up as it relates to accessibility. 
The term device independence has always been a very confusing term. 
If device independence means anything other than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" then I do not think that we want or need it. 
In fact I do not see how it could even be possible. 
If the goal is to allow content to be accessed from PDAs, by Voice, by keyboard etc. then "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" will get you this. 
If you would like to ALSO add mouse control to make some tasks easier. 
That is fine. 
But we should not require it - and, as I said above, I don't even think it is possible. 
Since text input is sometimes required as a part of web content interaction, it would mean that text input would have to be possible using just a mouse. 
This in turn would require that every single page that required text input have a keyboard on the page and a script to drive it. 
If an external on-screen keyboard is used - then you are using keyboard input to the content - not mouse. 
And if a keyboard on the page is used then you are requiring that a script be used and the page would fail if the script did not run. 
Help me here. 
1) what does "device independence" mean? 
2) independence from what? 
3) does it require that all content be usable with a mouse only? 
(if so - how could this be done? 
Remember an on screen keyboard that is not part of the content is just a keyboard and the content would be receiving keyboard input.) 4) does it require that all content be usable with a keyboard only? 
5) does it require anything else? 
How does device independence make things any more accessible than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" (I am presuming that device independence does not mean "also support a mouse where that is a good interface practice". 
That would make the pages more accessible but does not sound like device independence because it doesn't make the content independent of any device or input method. 
It is just good user interface design practice that makes the page more usable). 
Help me if you can. 
Am I missing something? 
Thanks Gregg Gregg C Vanderheiden Ph.D. Professor - Ind. Engr. 
&amp; BioMed Engr. 
Director - Trace R &amp; D Center University of Wisconsin-Madison 
Gregg, Yes, that promotes the use of other devices and does lay the base requirement to keyboard or keyboard-like inputs. 
The base should always be keyboard or keyboard-like devices and I do agree. 
My concern was people tend to ignore other devices if we declare only one type of device. 
A quadriplegic (sorry about the spelling) may not have the use of a blow-stick or other click device and only have access to a speech recognition program. 
The inputs from that program wouldn't be keyboard or keyboard-like. 
I hope this helps clarify my concerns. 
Thanks, Lee Hi Lee. 
I understand the first part about not using Mouseover etc. and agree. 
And I believe that would be met by what was proposed. 
(e.g. must be operable from keyboard). 
I don't understand your second part about not wanting things to be keyboard only. 
The proposal just says it must be keyboard operable. 
Not that you can't have it do other things as well. 
I presume you don't want to lose keyboard operability in favor of other things (i.e. mouse only or pointer only"). 
So are you just asking that it be written so that it doesn't sound like Keyboard only? 
Does the following meet your requirement/concern? "All content functionality must be usable by (from?) a keyboard or keyboard interface if the function or its result can be concisely expressed in words. 
NOTE: Other interface methods such as pointing can and should be supported in parallel with keyboard operability as appropriate, but keyboard operation is always required for functionality whose name or result can be concisely expressed in words." 
Thanks Gregg Gregg C Vanderheiden Ph.D. Professor - Ind. Engr. 
&amp; BioMed Engr. 
Director - Trace R &amp; D Center University of Wisconsin-Madison -----Original Message----- Behalf Of Lee Roberts My goal with "device independence" is to get people to quit using _scrap code_ that requires a mouse to perform the functions. 
All these onmouseover, onmouseout, onclick, ondblclick, and such do not work for everyone. 
I've talked to more developers than I can count that didn't even know onselect, onfocus, onblur existed and then wanted to know what they were for when I explained they should be using them. 
I don't think we should limit accessibility to just keyboard or keyboard interfaces. 
Wireless devices will provide some interesting advancements what will likely move into the desktop arena. 
One device I've seen that could work well in computing is the same tool helicopter pilots use to aim their canons. 
With that tool, I see mouse usage going away. 
We don't know when the next evolution of the WCAG will be started or the technologies available. 
It should be our goal to open the door to other technologies, so those technologies will have some guidance on how to be used to provide accessible interfaces and content. 
Lee -----Original Message----- Behalf Of Gregg Vanderheiden The term "device independence" keeps coming up. 
So I would like to write something here to spur a dialog that will let us clear this concept up as it relates to accessibility. 
The term device independence has always been a very confusing term. 
If device independence means anything other than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" then I do not think that we want or need it. 
In fact I do not see how it could even be possible. 
If the goal is to allow content to be accessed from PDAs, by Voice, by keyboard etc. then "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" will get you this. 
If you would like to ALSO add mouse control to make some tasks easier. 
That is fine. 
But we should not require it - and, as I said above, I don't even think it is possible. 
Since text input is sometimes required as a part of web content interaction, it would mean that text input would have to be possible using just a mouse. 
This in turn would require that every single page that required text input have a keyboard on the page and a script to drive it. 
If an external on-screen keyboard is used - then you are using keyboard input to the content - not mouse. 
And if a keyboard on the page is used then you are requiring that a script be used and the page would fail if the script did not run. 
Help me here. 
1) what does "device independence" mean? 
2) independence from what? 
3) does it require that all content be usable with a mouse only? 
(if so - how could this be done? 
Remember an on screen keyboard that is not part of the content is just a keyboard and the content would be receiving keyboard input.) 4) does it require that all content be usable with a keyboard only? 
5) does it require anything else? 
How does device independence make things any more accessible than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" (I am presuming that device independence does not mean "also support a mouse where that is a good interface practice". 
That would make the pages more accessible but does not sound like device independence because it doesn't make the content independent of any device or input method. 
It is just good user interface design practice that makes the page more usable). 
Help me if you can. 
Am I missing something? 
Thanks Gregg Gregg C Vanderheiden Ph.D. Professor - Ind. Engr. 
&amp; BioMed Engr. 
Director - Trace R &amp; D Center University of Wisconsin-Madison 
Hi Lee, Yes- That is exactly why the proposal says keyboard or keyboard interface. 
Speech recognition programs interface with standard programs by looking like a keyboard. 
I don't know of any voice products that interface with standard programs that can't appear to the program exactly like keystrokes. 
Some also have other interfaces to particular popular programs and mouse emulation too, but all are able to "type keystrokes" that look like the came from the keyboard. 
Gregg Gregg C Vanderheiden Ph.D. Professor - Ind. Engr. 
&amp; BioMed Engr. 
Director - Trace R &amp; D Center University of Wisconsin-Madison Gregg, Yes, that promotes the use of other devices and does lay the base requirement to keyboard or keyboard-like inputs. 
The base should always be keyboard or keyboard-like devices and I do agree. 
My concern was people tend to ignore other devices if we declare only one type of device. 
A quadriplegic (sorry about the spelling) may not have the use of a blow-stick or other click device and only have access to a speech recognition program. 
The inputs from that program wouldn't be keyboard or keyboard-like. 
I hope this helps clarify my concerns. 
Thanks, Lee -----Original Message----- Hi Lee. 
I understand the first part about not using Mouseover etc. and agree. 
And I believe that would be met by what was proposed. 
(e.g. must be operable from keyboard). 
I don't understand your second part about not wanting things to be keyboard only. 
The proposal just says it must be keyboard operable. 
Not that you can't have it do other things as well. 
I presume you don't want to lose keyboard operability in favor of other things (i.e. mouse only or pointer only"). 
So are you just asking that it be written so that it doesn't sound like Keyboard only? 
Does the following meet your requirement/concern? "All content functionality must be usable by (from?) a keyboard or keyboard interface if the function or its result can be concisely expressed in words. 
NOTE: Other interface methods such as pointing can and should be supported in parallel with keyboard operability as appropriate, but keyboard operation is always required for functionality whose name or result can be concisely expressed in words." 
Thanks Gregg Gregg C Vanderheiden Ph.D. Professor - Ind. Engr. 
&amp; BioMed Engr. 
Director - Trace R &amp; D Center University of Wisconsin-Madison -----Original Message----- Of Lee Roberts My goal with "device independence" is to get people to quit using _scrap code_ that requires a mouse to perform the functions. 
All these onmouseover, onmouseout, onclick, ondblclick, and such do not work for everyone. 
I've talked to more developers than I can count that didn't even know onselect, onfocus, onblur existed and then wanted to know what they were for when I explained they should be using them. 
I don't think we should limit accessibility to just keyboard or keyboard interfaces. 
Wireless devices will provide some interesting advancements what will likely move into the desktop arena. 
One device I've seen that could work well in computing is the same tool helicopter pilots use to aim their canons. 
With that tool, I see mouse usage going away. 
We don't know when the next evolution of the WCAG will be started or the technologies available. 
It should be our goal to open the door to other technologies, so those technologies will have some guidance on how to be used to provide accessible interfaces and content. 
Lee -----Original Message----- Of Gregg Vanderheiden The term "device independence" keeps coming up. 
So I would like to write something here to spur a dialog that will let us clear this concept up as it relates to accessibility. 
The term device independence has always been a very confusing term. 
If device independence means anything other than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" then I do not think that we want or need it. 
In fact I do not see how it could even be possible. 
If the goal is to allow content to be accessed from PDAs, by Voice, by keyboard etc. then "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" will get you this. 
If you would like to ALSO add mouse control to make some tasks easier. 
That is fine. 
But we should not require it - and, as I said above, I don't even think it is possible. 
Since text input is sometimes required as a part of web content interaction, it would mean that text input would have to be possible using just a mouse. 
This in turn would require that every single page that required text input have a keyboard on the page and a script to drive it. 
If an external on-screen keyboard is used - then you are using keyboard input to the content - not mouse. 
And if a keyboard on the page is used then you are requiring that a script be used and the page would fail if the script did not run. 
Help me here. 
1) what does "device independence" mean? 
2) independence from what? 
3) does it require that all content be usable with a mouse only? 
(if so - how could this be done? 
Remember an on screen keyboard that is not part of the content is just a keyboard and the content would be receiving keyboard input.) 4) does it require that all content be usable with a keyboard only? 
5) does it require anything else? 
How does device independence make things any more accessible than "usable by a keyboard or keyboard interface if the function or its result can be concisely expressed in words" (I am presuming that device independence does not mean "also support a mouse where that is a good interface practice". 
That would make the pages more accessible but does not sound like device independence because it doesn't make the content independent of any device or input method. 
It is just good user interface design practice that makes the page more usable). 
Help me if you can. 
Am I missing something? 
Thanks Gregg Gregg C Vanderheiden Ph.D. Professor - Ind. Engr. 
&amp; BioMed Engr. 
Director - Trace R &amp; D Center University of Wisconsin-Madison 
