I was hoping to polish this proposal a little more before floating it externally, but alas, with the meeting on Monday, time did not permit. 
I hope that I have at least stated my perspective well enough to stimulate discussion. 
Problem statement: The existing HTTP authentication model does not allow authentication realms to be distributed across servers. 
To protect user credentials. 
HTTP browsers associate each realm with a single IP address, and will not pass user credentials to multiple servers even if they claim to belong to the same realm. 
This security measure, built into the browser, has created the undesirable side effect of requiring users to re-type their user names and passwords for each protected server within a multiple server site. 
Abstract: A proposal is made to: Allow the distribution of protection realms across servers Protect user credentials from "imposter" servers which claim to belong to a realm but do no Pass user credentials securely to content servers which identify themselves as members of those realms To re-use user credentials throughout protection realms so that users are challenged for user name and password only once within the context of a single session. 
Create secure, trusted relationships between servers Centralize authentication, authorization, and directory services for one or multiple websites Centralize directory security Simplify or eliminate directory services on distributed content servers Make it scalable I propose that this new authentication scheme be named "remote authentication". 
Theory of operation: When access is first attempted to a content page which is protected by remote authentication, the browser is redirected to the "remote authentication" server for that realm. 
This redirection should be done via SSL for security. 
The user is then challenged for user name and password by basic authentication. 
The server then encrypts the user name and password with a secret (symmetric) key and returns the user name and password to the browser where they are cached for the session. 
The browser is then re-directed to the original content server and the browser passes the encrypted user name and password to the server. 
The content server, which shares the same secret key as the authentication server, is able to decrypt the user name and password. 
When the browser is challenged by another server which claims to be in the same realm, the user credentials are served. 
If the server is trusted, it will share the same secret key as the authentication server and the user name and password will be decrypted. 
If the server is an imposter, decryption will fail and the user credentials remain secure. 
The way I see it, the browser will associate each realm with an encrypted user name and password, which are simply opaque strings. 
In addition, I would like the browser to allow the server to cache an additional string of arbitrary length to pass state to the other servers in the realm. 
It could be used to store additional authentication and authorization semantics, such as an expiration time for the authentication, authorization information such as a list of groups to which the individual belongs, an index to identify the identity of the encryption key, etc. 
This information could be signed with an MD5 MAC or encrypted or just plain cleartext. 
I think that we could do the web a great big favor if we eliminated the need to replicate directories to content servers. 
The authentication piece is easy, but if we can solve the authorization part I believe that we could simplify the common registration puzzle at the same time. 
Thank you for your support, -e 
I think that the spec for "domain" is broken -- it specifies a list of URIs, but doesn't say that these can be _prefixes_ of URIs that may also use the same credentials. 
Without that, it is pretty uselss, IMHO. 
From: Scott Lawrence[SMTP:lawrence@agranat.com] Sent: Friday, December 05, 1997 10:53 AM Subject: Re: Proposal for new HTTP 1.1 authentication scheme Digest authentication already includes a mechanism (the 'domain' attribute; see section 3.2.1 of draft-ietf-http-authentication-00) to specify that credentials may be used on multiple servers, and through the 'digest' attribute allows for mutual authentication. 
There is also the model of Kerberos to consider - developing a ticket-based authentication scheme (with the advantages and problems of any third-party mechanism) would be another area to explore. 
Could the spec be fixed without interoperability trouble emerging? 
(Query to digest implementers???). - Jim 
Most of the suggestions by Paul and Dave seem to be clarifications of the original intent. 
They should not cause problems. 
The one significant change is Paul's suggested change of the algorithm for calculating the "entity-digest". 
If implementations exist they will be incompatible. 
I don't think I would describe this as fixing a "bug" in the entity-digest algorithm. 
It might be an improvement though. 
On the other hand, if I recall correctly it was Paul who wrote the entity-digest algorithm, so he may have a right to call it a bug. 
John Franks john@math.nwu.edu 
I still feel my one objection about proxy-added headers is substantive and unresolved. 
Briefly, an origin server might omit headers that get figured into the entity-digest calculation. 
A proxy might subsequently add those headers. 
The client sees a message *with* the headers, calculates an entity-digest that figures them in, and gets a different answer from what the origin server calculated. 
Dave Kristol 
I agree that there is an issue here. 
The current spec says the proxy MUST not add these headers. 
If I recall you suggested the MUST be changed to SHOULD. 
I am not sure how this helps beyond making the proxy technically "legal." 
It doesn't materially affect the problem. 
What should a proxy do in this situation? 
It seems it must either not add headers or break the entity-digest. 
John Franks john@math.nwu.edu 
Ummm... I think my "MUST - SHOULD" had to do with a proxy's changing the content of headers. 
I think I see the words to which you're referring (end of p.13), and they mention Content-Length explicitly but don't mention Date. 
And there's a potential problem with Content-Length: suppose a proxy eats chunked data and wants to create a complete entity *with* Content-Length. 
Is it hereby forced to forward the entity as "chunked" because it's forbidden to add Content-Length? 
I agree it's a dilemma. 
An option is to require that clients send Content-Length and (perhaps) not Date, and forbid proxies to add either within this context. 
Dave Kristol 
Alternatively, you exclude those headers from the digest? 
Cheers, Ben. 
A.L. Digital Ltd, |http://www.algroup.co.uk/Apache-SSL London, England. 
|"Apache: TDG" http://www.ora.com/catalog/apache 
