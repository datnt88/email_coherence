I took an action item on the 14 February call to find out how to determine tracks in SMIL. 
It's very straightforward. 
Consider the following example 
from the SMIL access note [1]: audio alt="Interview with Harvey, English audio" src="audio.rm"/ 
textstream alt="English captions for interview with Harvey" src="closed-caps.rt"/ 
This will play an audio track, a video track and a text track (captions). 
Therefore, it is fairly simple to determine if a text track is associated with the audio/video tracks. 
However, this text track *could* be language subtitles. 
Consider the following example: textstream alt="English captions for My Favorite Movie" system-captions="on" src="closed-caps.rt"/ 
It uses the "system-captions" attribute to indicate to a SMIL player that if the user wants captions this is the track to play. 
I don't know if we want to get into repairing SMIL, but if we find a SMIL presentation without 
the "system-captions" flag we could raise a warning. 
SMIL 1.0 does not have a similar flag for auditory descriptions, although it is being discussed for the next release. 
Multiple audio tracks can be included, but they could be used for language overdubbing. 
Therefore, checking for captions is currently more straightforward than checking for an auditory description, but there are clues that you can use to make a guess and ask the author for confirmation. 
--wendy 
[1] http://www.w3.org/TR/SMIL-access/ wendy a chisholm world wide web consortium web accessibility initiative madison, wi usa 
Also, because text is much more lightweight than video, any text that is intended to form part of the presentation may be shipped as such. 
In that case it will most likely not have a system-captions set. 
Charles McCN I took an action item on the 14 February call to find out how to determine tracks in SMIL. 
It's very straightforward. 
Consider the following example 
from the SMIL access note [1]: audio alt="Interview with Harvey, English audio" src="audio.rm"/ 
textstream alt="English captions for interview with Harvey" src="closed-caps.rt"/ 
This will play an audio track, a video track and a text track (captions). 
Therefore, it is fairly simple to determine if a text track is associated with the audio/video tracks. 
However, this text track *could* be language subtitles. 
Consider the following example: textstream alt="English captions for My Favorite Movie" system-captions="on" src="closed-caps.rt"/ 
It uses the "system-captions" attribute to indicate to a SMIL player that if the user wants captions this is the track to play. 
I don't know if we want to get into repairing SMIL, but if we find a SMIL presentation without 
the "system-captions" flag we could raise a warning. 
SMIL 1.0 does not have a similar flag for auditory descriptions, although it is being discussed for the next release. 
Multiple audio tracks can be included, but they could be used for language overdubbing. 
Therefore, checking for captions is currently more straightforward than checking for an auditory description, but there are clues that you can use to make a guess and ask the author for confirmation. 
--wendy 
[1] http://www.w3.org/TR/SMIL-access/ wendy a chisholm world wide web consortium web accessibility initiative madison, wi usa W3C Web Accessibility Initiative http://www.w3.org/WAI Location: I-cubed, 110 Victoria Street, Carlton VIC 3053 Postal: GPO Box 2476V, Melbourne 3001, Australia 
example 
without 
And even if the system-captions flag is found it may be used for other purposes than a caption element or it may just attach captions for a part of the audio elements. 
Marja 
