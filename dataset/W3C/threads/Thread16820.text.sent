is there a w3c service that crawls a site and reports errors, in planning perhaps? 
thanks jonathan That's best done with a local tool. 
A W3C service could easily be used as a denial of service attack aid. 
You can use Lynx to build a complete contents lists for a site (assuming that links aren't hidden behind Javascript, etc., meaning that many search engines will ignore them as well), then feed them into nsgmsls to validate the HTML, or the CSS2 validator. 
DO NOT do this without the site owner's permission, as Lynx doesn't obey the "robots" protocol, so will crawl where it is not allowed to go, and will not pause the required 30 seconds between pages for unsolicited crawlers. 
Abuse of Lynx may get it blacklisted by the site as a hostile crawler. 
You can also mirror the site using wget, which does respect the "robots" protocol, then validate the local copy. 
scripsit jonathan chetwynd: WDG's validator [1] has something like this. 
If you tell it to validate the "whole site", it will crawl links which point to files in the same directory or under, and validate those recursively. 
It's not W3C, but it is "real" DTD-based validation. 
References 1. Linked from http://www.htmlhelp.com 
Thanasis Kinias Web Developer, Information Technology Graduate Student, Department of History Arizona State University Tempe, Arizona, U.S.A. Ash nazg durbatul?k, 
ash nazg gimbatul, Ash nazg thrakatul?k 
agh burzum-ishi krimpatul The key point is that any crawler should operate slowly so as not to risk overloading a server. 
One page per minute is a common rule-of-thumb for well-behaved robots. 
This is obviously not compatible with an online service that spiders while you wait. 
wget runs on rapid-fire too. 
The Site Valet spider does exactly what you're asking for, spidering a site over time and compiling results which can be emailed to you, queried online with a browser, or both. 
Nick Kew Available for contract work - Programming, Unix, Networking, Markup, etc. wget has an option for a suitable delay; I can't remember if it is on by default, though. 
