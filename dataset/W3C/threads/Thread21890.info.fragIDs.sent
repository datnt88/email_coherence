[mb] Not sure what you mean here -- our less than perfect tests are and have been available for some time. 
The tests have been modified, but have not all been translated and compiled. 
I would expect that any contribution would not be accepted until it met this minimum requirement. 
I've used the tests that I scraped from the test matrix to test the transforms and build processes, however it is not worthwhile trying to analyze those tests and correct or improve them since there is no mechanism to get any changes incorporated and the files may be undergoing independent changes within NIST. 
Until the tests are put in the CVS, it isn't worthwhile for anyone else to spend any time on them. 
In an earlier message, I thought that you were hesitant to put the tests in the CVS until they were near perfect. 
I think that we have the freedom to accept contributions in any condition that we choose. 
Ideally, a contributor would have tests that would transform, compile and run before they submitted the tests and we would double check that before committing the tests to the CVS to avoid breaking the build process (in rare cases, we could have a whiteboard area for tests under construction). 
However, since we don't have a buildable product at this time and having the initial test load in any form is valuable, I'd be in favor of your committing the tests in their current condition and we as a team can make the necessary changes to the test cases or transforms. 
Some minor notes: I think the package attribute on the test and suite elements is extraneous and expect to remove it from the generated schemas and DTD's and ignore it in the transforms. 
If you are going to commit tests, you may go ahead and strip it out now. 
The package name will be based on the location of the test. 
DOM Level 1 tests definitions should be added to 2001/DOM-Test-Suite/tests/level1/core, corresponding test files should added to 2001/DOM-Test-Suite/files/level1/core. 
If we create a log element that is used like the following: 
$Log$ 
The CVS will insert the update log within the element. 
This could also be copied to the generated tests. 
This would require that you avoid using &amp;,  or 's in the update comments. 
Yes! 
This makes me think that the test files should ride along with the tests, possibly in a subdir: tests in .../tests/level1/core, files in .../tests/level1/core/files (or data). 
Maintaining two sets of directories seems pretty artificial. 
I think people will have very divergent opinions on this. 
My thought on it is that CVS is very good at keeping track of this stuff, and it's easy enough to get out of CVS using "cvs log", so adding it to the test seems extraneous. 
It may be that it makes more sense here 
than in "normal" application development. 
(I'd sure hate to get the 150+ entry logs for many of the files I work with!) If we do decide we want it, though, we should probably use: log ![CDATA[ ]] /log This gives us fewer restrictions in the checkin comments, at least. 
-Fred Fred L. Drake, Jr. fdrake at acm.org PythonLabs at Zope Corporation 
They could be in the same directory as long as we use a distinct extension for test definitions. 
If they are all .xml 
files, then ANT can't determine which files are test definitions and should be 
validated or transformed and which are test resources. 
How about .tst for test definitions? 
If we decide otherwise, we can add the log elements at any time. 
I'll put that one on hold. 
However, leveraging the CVS log is definitely a better approach than trying to put the equivalent log explicitly in the test. 
Or I could stop thinking 8.3, how about .domtest? 
I'm not sure I understand just what the limitation is. 
I'll have to dig into Ant a little more to figure it out. 
Ugh. 
Fine. Agreed that the log should be maintained in CVS rather than doing it manually. 
Could, but there's probably no specific reason to avoid 8.3, either. 
-Fred Fred L. Drake, Jr. fdrake at acm.org PythonLabs at Zope Corporation 
There needs to be some pattern so the build can determine which files are test definitions and should be transformed and which files are resource files used in the test and should be copied without transformation. 
Explicitly listing the tests (or excluding the resource files) in build.xml is undesirable. 
Running everthing through the transform is unacceptible since some files aren't XML (for example, the DTD's) and the extension is determined outside the transform, so resource files would all end up with .java, 
.js, 
.cs, 
et al extensions and cause problems in compilation. 
The options are to either use pattern to test definitions file names (such as *.domtest or test*.xml), or to keep the test definitions and resource files in different locations. 
Since all the scraped 
test files had .xml 
extensions and there were also resource files with .xml 
extensions, I chose to keep them in parallel hierarchies. 
Using a files subfolder is just a slightly different approach. 
It is basically the same problem as if you used a .java 
extension for non-Java files, the build process would become much more complicated since it would assume that those files were Java source code and try to compile them. 
I was hoping that Ant would give us something smarter, at least for XML. 
One of the advantages of using different DTDs/schema for different documents is that you can determine what sort of thing each represents. 
I'd like to see a way to match based on publicId/systemId and the root element, and dispatch on that. 
Perhaps I should refresh my Java skills by writing an xmldispatch "action" for Ant: 
Yes, that can a real problem for maintainability! 
Yes, but the advantage here is that the data remains "close" to the test itself, and the shape of the tree does not need to be duplicated (another maintenance task). 
Now just where do you think I'm going to keep those coffee grounds I was saving??? -Fred Fred L. Drake, Jr. fdrake at acm.org PythonLabs at Zope Corporation 
