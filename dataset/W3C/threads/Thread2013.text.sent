good first step. 
For some headers, (accept, for example), you need more than merely knowing what it depended upon, but also the WAY in which it depended upon the original data, so that the proxy itself can decide whether a cached item is appropriate. 
Absolutely. 
A Vary: 1#(http-header-name) header returned by the server would help solve this problem. 
I like this syntax. 
The URI header would work, but this is short and to the point. 
I think this syntax is insufficient. 
This is pretty much the information that was contained in the HTTP/1.0-01 draft (AKA HTTP/1.1 before there was a 1.1) and it was presumably changed because others felt likewise. 
Using that scheme would require that the caching proxy keep the exact header(s) stored for the specified vary quanity for comparison purposes. 
This is a huge burden on a proxy because it doesn't just have to save headers once, it has to save headers for each request that doesn't have the exact same paramters as previous requests. 
An example might be useful here, if not longwinded. 
This demonstrates the insufficent-ness of the old URI:, and a Vary: header scheme as well. 
---Request 1 GET /index HTTP/1.1 Accept: image/gif, image/jpeg, image/helper-app1, image/helper-app2 ---Response URI: /index.gif , /index; vary=language, type ---cache has to store 1./index | T | Accept: image/gif, image/jpeg, image/helper-app1, image/helper-app2 ---Request 2 GET /index HTTP/1.1 Accept: image/gif, image/jpeg, image/helper-app1 Accept-Language: fr ---Response URI: /index.gif , /index; vary=language, type ---cache has to store 1. 
/index | T | Accept: image/gif, image/jpeg, image/helper-app1, image/helper-app2 2. /index | T | Accept: image/gif, image/jpeg, image/helper-app1, image/helper-app2 | L | Accept-Language: fr ---Request 3 GET /index HTTP/1.1 Accept: image/gif, image/jpeg, image/helper-app1 ---Response URI: /index.gif , /index ; vary=language, type ---cache has to store 1. 
/index | T | Accept: image/gif, image/jpeg, image/helper-app1, image/helper-app2 2. /index | T | Accept: image/gif, image/jpeg, image/helper-app1, image/helper-app2 | L | Accept-Language: fr 3. /index | T | Accept: image/gif, image/jpeg, image/helper-app1 This is totally unworkable. 
It's not just going to be one header permutation combo of charsets/encodings/types/langs per browser either, as good browsers now let people set some of these parameters to their preference. 
This list will grow forever, and proxies just won't cache things that vary, or will forget about content negotiation altogether. 
The new scheme has the big advantage of including all variants, their metainformaiton, and the qs's of the variants in the URI header. 
This gives the proxy the information it needs to do the negotiation itself, and is the only way to assure a trip to the original server would yield the same result, and that serving from the cache is acceptable. 
(I completely ignore the vary by User-Agent here, but until we invent the psychic proxy, no proxy can solve for server's varying content outside of the content negotiation scheme without listing all 2000 user agents that come through its doors.) I've always been very hesitant about the server's content variant-picking algorithm being part of the protocol, because I saw that as a server-side implementation issue, but as time goes on, I become more and more convinced of the weight of this issue and its impact on the scalabilty of the web. 
The new URI header solves this caching problem perfectly, and single-handedly convinces me of the concept of opening the algorithm to the protocol. 
Now, if I can just 1) convince Roy to default charsets/encodings to .001 on absent headers, and 2) propose a different sytax than the URL: {} lispism, I might die happy. 
The current one can cause extremely big headers (you think Accept is bad?) and doesn't parse like existing headers. 
How about: Location: http://www.spyglass.com/index.html 
URI: "/index.html"; 
t=text/html; qs=.9, "/index.en.html"; t=text/html; l=en; qs=.9 URI: "/index.jp.txt"; t=text/plain; l=jp-JP; c=isp-2022-jp1; qs=.1 And maybe even uhg : URI "/index.nscp.html"; 
ua="Mozilla/1.2N (Windows; I; 32bit)" where the absence of an encoding, language, or charset mean they're indeterminate for that resource. 
I like saving a few bytes on the "language" &amp; "encoding" etc tags, and on the default to "variant=", and I like sticking with a format that parses like the Accept headers. 
Besides the current 9/22 draft looks too much like Logic Bags :) If anyone wishes, I will gladly write up a BNF. 
Dan DuBois, Software Animal http://www.spyglass.com/~ddubois/ 
I absolutely do not speak for Spyglass. 
I like this syntax. 
The URI header would work, but this is short and to the point. 
Firstly, I'm not convinced that it's a _huge_ burden; does anyone have any statistics on Accept: headers? 
Yes, there are cases where a Vary: header will not provide enough information for a cache. 
But are you arguing against the implementation of the Vary: header? 
I am suggesting that it is a useful feature for varying resources. 
You seem to be arguing that it may not be enough for caching of content-negotatiated resources. 
Does that matter? 
I'm not quite sure what you mean, but half of the point of the Vary: header was to inform about the server's varying content outside the content negotiation scheme. 
David Robinson. 
It's likely not much of a burden now, but as browsers become more willing to let uses set their own q's, or add type and encoding helper-apps to their Accept* headers, it will become hugely burdensome. 
Yes. 
Yes. 
Caching is integral. 
So, tell me again what functionailty the Vary: header would provide? 
How would I modify my behavior based on a Vary: header? 
Either variances are acceptable future responses (in the content provider's mind), and hence cachable, or their not, and then the server will send a Cache-Control. 
Dan DuBois, Software Animal http://www.spyglass.com/~ddubois/ 
I absolutely do not speak for Spyglass. 
Daniel DuBois: I still am very hesitant about moving variant-picking algorithms into proxies: if it is done in the wrong way, it will have a negative impact on the extensibility of the protocol. 
It is desirable however to put a sub-algorithm that often occurs in server variant-picking algorithms in the protocol. 
The sub-algorithm in question is the algorithm that can match MIME type, language, and content coding. 
I agree with your assessment of the old `vary' method not being a good solution, but I disagree with you that the new URI header `solves the caching problem perfectly'. 
The URI header in draft-ietf-http-v11-spec-00 is a step in the right direction, but it does not offer a perfect solution by itself, we need some additional mechanisms currently under discussion. 
(One example of such a mechanism is the request header I called `Send-no-body-for' in my notes on content negotiation (see We need something like `Send-no-body-for' because variant-picking algorithms can never be moved completely into proxies. 
(User-agent based negotiation is the most obvious reason why this cannot be done.) I expect to be working on these issues inside the content negotiation subgroup. 
By the way, I disagree with Larry Masinter on where to draw the line between content negotiation and caching. 
My assignment of header responsibility is: Content negotiation subgroup: Accept-*, URI, Location Caching subgroup: Expires, Cache-control, If-Modified-Since, .... URI and Location are both used by all types of clients, not just proxies, in reactive negotiation. 
This makes them primarily the responsibility of the negotiation subgroup. 
Koen. 
THe only problem with your position is that desigining negotiation while igoring proxy/caching issues can't be successful. 
Either negotiation won't work in the general cases or proxies will never be able to determine if a response can be delivered in response to another requrest. 
Furthermore, to some degree or another all clients provide caching as well so caching is not simply a proxy issue. 
I think Larry Masinter's split makes much sense, especially considering the broad participation in the proxy/caching sub-group. 
If the negotiation group can identify how to specify and what to negotiate then the join the caching/proxy discussion to make sure we end up with a cohesive mechanism which covers all issues. 
Dave Morris David W. Morris: I agree, doing it this way is the best solution. 
Of course, this implies that the caching/proxy group stops discussing the caching of negotiated responses for some time. 
While the content negotiation subgroup is working out the negotiation mechanism, the caching/proxy subgroup can work on the caching model for non-negotiated responses. 
There are still plenty of things to discuss even if negotiation is presumed absent. 
According to the current 1.1 draft (Section 12, second paragraph), a response is non-negotiated if it does not have an URI header listing the available variants. 
I doubt that the content negotiation subgroup will propose a change of this rule. 
Koen. 
I agree, doing it this way is the best solution. 
Of course, this implies that the caching/proxy group stops discussing the caching of negotiated responses for some time. 
While the content negotiation subgroup is working out the negotiation mechanism, the caching/proxy subgroup can work on the caching model for non-negotiated responses. 
There are still plenty of things to discuss even if negotiation is presumed absent. 
If the content-negotiation subgroup is aware of the need to provide a solution to the caching problem, I think the caching subgroup can go on our merry way for a while. 
Ultimately, the content-negotiation subgroup ought to provide a precise definition of how a cache can determine if a new request matches the cached response to a previous request. 
The current 1.1 draft contains this paragraph: Servers that make use of content negotiated resources must include URI response headers which accurately describe the available variants, and include the relevant parameters necessary for the client (user agent or proxy) to evaluate those variants. 
I think the key words here are "accurately describe", "relevant parameters", and "evaluate." 
We need precise specifications to replace these somewhat ambiguous phrases. 
-Jeff Jeffrey Mogul: I agree this is what the content-negotiation subgroup ought to provide. 
It is on our list of topics. 
We will also be discussing whether or not the negotiation mechanism should yield variant URIs in Location headers, and, if so, how to prevent spoofing. 
Koen. 
