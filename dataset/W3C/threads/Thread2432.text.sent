It currently says: In theory, the date SHOULD represent the moment just before the entity is generated. 
In practice, the date can be generated at any time during the message origination without affecting its semantic value. 
I don't think it makes sense for a normative keyword such as "SHOULD" to be preceded by "In theory", except if this is clearly marked as a "Note". 
This would be very confusing to someone trying to figure out if this is a real SHOULD, or just a theory. 
How about In theory, the date ought to represent the moment just before the entity is generated. 
In practice, the date can be generated at any time during the message origination without affecting its semantic value. 
In fact, if you read 14.19 carefully, it never has any actual normative requirement on what the Date value MUST or SHOULD be (except for this "in theory"). 
But perhaps what we really meant to say, before the paragraph quoted above, is: The HTTP-date sent in a Date header SHOULD NOT represent a date and time subsequent to the generation of the message. 
It SHOULD represent the best available approximation of the date and time of message generation, unless the implementation has no means of generating a reasonably accurate date and time. 
-Jeff I've been wading through filed mail since IETF; unless I hear complaints, the changes in this message Jeff proposes will be adopted. 
There has been no comment on this since Jeff's original posting. 
As it is a clarification involving normative wording, I wanted to flag it for people's attention. 
- Jim (http://www.ics.uci.edu/pub/ietf/http/hypermail/1997q4/0378.html) Jim Gettys Industry Standards and Consortia Digital Equipment Corporation Visting Scientist, World Wide Web Consortium, M.I.T. jg@w3.org, 
jg@pa.dec.com 
Has the Content-Length issue be resolved? 
I.e. is the Content-Length value the length before or after a Transfer-encoding is supplied? 
Whichever it is, it must be clearly stated in the specification and I don't see this on the issues list. 
John Franks john@math.nwu.edu 
I don't believe so, and I for one would be glad to get it decided. 
As I see it there are basically four solutions to this problem: 1) Content-Length is the length after t-e. 2) Add a new header Transfer-Length for t-e's other than chunked and identity. 
3) Require all t-e's to be self delimiting. 
3a) If a t-e is not self delimiting then either use a Transfer-length, Content-length or chunked t-e on top 4) require the "outermost" t-e to be the chunked t-e I think that 1) is bad and unnecessary. 
Content-length has never been the length after t-e is applied, as previously the only t-e's were identity and chunked (Content-length was ignored when the chunked t-e was used). 
Let's leave Content-* as applying to the entity before t-e. 
I also don't like 3) and 3a) for implementation reasons: in a client the partitioning of the input stream into responses is a very low level operation. 
If self delimiting t-e's are allowed then supporting a new t-e would require changes to the core code, making it harder to write extensible clients. 
I'd rather see the number of ways the body can be delimited frozen once and for all (the currently 4 ways are quite enough, IMHO). 
Also, this solution means clients can't just use existing decompression libraries (such zlib) to decode the body; instead they have to implement at least parts of the code themselves. 
And lastly, this solution would prevent the existence of clients which accept all t-e's, possibly storing the response for later processing by some other software (such as spiders and similar clients). 
This leaves 2) and 4). 
The disadvantage of 4) is that it might use a few bytes more than 2). 
Furthermore, some people have expressed concern that 4) would require extra copying of the data on the server side, but I'm not sure how true this is if implemented correctly. 
On the other hand I personally like 4) because it requires the least changes to client code, but I can live with either solution. 
Note that if t-e's are going to be computed on the fly then servers will have to resort to chunking anyway. 
Just my 2 Rp. Cheers, Ronald [nice summary of alternatives] RT 4) require the "outermost" t-e to be the chunked t-e RT I personally like 4) because it requires the least changes to client code, RT but I can live with either solution. 
Note that if t-e's are going to be RT computed on the fly then servers will have to resort to chunking anyway. 
Agreed - I thought that Jeffs note proposing this as the easy way out was a simple solution that is almost certainly a backward-compatible solution, and we've heard nothing to the contrary. 
Scott Lawrence EmWeb Embedded Server lawrence@agranat.com 
Agranat Systems, Inc. Engineering http://www.agranat.com/ 
