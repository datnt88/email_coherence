Jeremy, Brian: I guess this sort of test case does not fit the "here's the RDF/XML, this is what it means in n-triples" pattern very well In testing ARP I work through a zip file finding all pairs of RDF and NT and check they are the same. 
I noticed that this test case still supports that. 
I think it is important that someone wishing to run automated tests off the test cases should be able to, without having to code in lots of specific filenames. 
I note that the zip file version is more useful than the web version for automated testing, since it is fairly hard to automatically work through all the files in a web directory. 
Your noting is noted. 
Did you have a specific suggestion in mind? 
Brian Brian: Thank-you, ... The current test cases have a regular format that is easy to automate tests against: look for an rdf file, and an nt file and match them up. 
Or look for an error file and check you fail it. 
If we were to extend the test cases with different paradigms I would suggest: + the paradigm should be clear. 
+ there should be no need to read a readme to understand a particular test + the different paradigms should be different top-level directories. 
e.g. we copy all the current tests into a directory "syntax" leaving the internal structure unchanged, The paradigm syntax supports error*.rdf and test*.{rdf,nt} 
tests. 
We could then have a paradigm "entailment" each test could consist of a directory with two sub-directories "premises" and "conclusions". 
The "premises" sub-directory would then include the axioms file as well as others. 
Personally I think I would prefer that each test in the "entailment" paradigm used either RDF/XML or N-triples for its facts (not both). 
No point in confusing a test for one thing with a test for another. 
We can still have a readme explaining the paradigm, just we expect to have more than one test in the same paradigm, and the developer having chosen to run tests of this paradigm only needs to write one lot of code. 
Another paradigm I proposed earlier was "equality" where each test consisted of two or more RDF/XML files that contain the same model. 
I saw this as useful for testing xml:lang, which does not occur in N-triples. 
Jeremy Jeremy, this is also syntactic stuff and I had better used the symbol |- S |- R i.e. "from the set of formulae S we can obtain the formula R" (RDF graph seen as a formula) at the moment we do that also via entailment i.e. f1 |- f2 &amp; f2 |- f1 so that's why we keep the f(ormulae) in the same directory but I can see that we keep the test descriptions distinct Jos De Roo, AGFA http://www.agfa.com/w3c/jdroo/ 
Right, I see what you mean. 
You want an automatic way to determine what sort of test to run on the data. 
There is a rule that we don't create broken URI's so I'm relucant to move the existing test cases. 
But I'm sure we can work around that. 
Yet? 
Am I right in assuming that the current direction the literal discussion is taking will require a change to the representation of literals in n-triples? 
Brian Brian McBride said: Yes - but we should make it only *after* we have recorded the decision on what a literal is. 
Similarly if/when the model requires changes of the n-trriples, we can do them, as we have agreed to in previous meetings. 
Dave I've tried this morning to sketch another approach. 
Like the LFG approach of last week this is declarative. 
However it is XML based, presumably implementable in XSLT, and compatible with the Infoset grammar rather than an EBNF grammar. 
Again, this is intended as a discussion document, primarily for the syntax subgroup. 
Jeremy 
