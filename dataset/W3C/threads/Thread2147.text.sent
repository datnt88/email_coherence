I feel like the little kid whose questions are missed among the shouting of a huddle of bigger kids. 
So I'll try again, now that the exchanges among people on the U.S. Pacific Coast have died down. 
The issue is cache corruption and how to avoid it, and I'm obviously not following some of the dialog. 
Yesterday I asked whether Lou Montulli (or anyone else) could describe to me the circumstances under which a file's modification date might remain unchanged, even though the file content had changed. 
I can imagine the mechanics (e.g., Unix "touch"), but I don't understand why someone would go to the trouble to do so. 
Anyone care to respond? 
(Private is okay.) Lou argues that "HTTP servers reference a file system that can be changed at random". 
I presume he means by the Webmaster, and not by other users. 
If the Webmaster doesn't administer a site properly, then all bets are off anyway. 
Lou also says that "dates are not strong enough by themselves to do an adequate job of versioning". 
I'd like to know why, which gets back to my original question. 
I also don't understand the arguments about a Version header. 
Mike Meyer suggested that the origin server could generate one, and a client could reflect it back to ask whether something changed. 
Lou Montulli was unhappy, saying the client could not calculate the Version information independently. 
I don't understand that reasoning. 
Why is it so hard to store it? 
Why does the client need to calculate it? 
I infer that Lou wants to use size as a way to tell whether a client got an entire resource in the face of prematurely cut off connections. 
Wouldn't a requirement that there be either a Content-Length or packetized content (HTTP/1.2) be a better solution? 
The client would then know whether it got everything then. 
I support the idea of the client's knowing whether its cache is correct, but I oppose burdening the origin server with significant extra work to help it do so. 
So I oppose the need for an origin server always to calculate checksums or file sizes, since that might require running a script. 
Even asking the origin server to compare a checksum or file size supplied by the client against the server's idea of those values is a burden. 
For scripts, the server would have to do all the processing of a GET anyway, if only to decide the supplied value matches. 
Dave Kristol There has been a lot of somewhat repetitive debate on this mailing list over the last few days. 
I suspect that some of the confusion stems from a lack of a shared set of goals and principles. 
Maybe we should settle on those first, before trying to design or tweak mechanisms to implement caching? 
Hence this message. 
I'm going to pretend that we are designing a new protocol, not changing an existing one, to avoid confusing the issue with debates about broken implementations or minimal changes. 
Until we can agree on what we want the protocol to do, it's pointless to argue over how it does it. 
Let's assume that the HTTP 1.1 spec, and all subsequent ones, explicitly state the tautology that "an implementation not conforming to this specification does not conform to this specification." 
Any "broken" browsers, servers, or clients will simply not be able to claim conformance to HTTP 1.1, so it is not necessary to write that spec to allow non-conforming implementations. 
At the same time, the robustness principle applies: we should not write a spec that leads to a "fragile" system. 
Time for a Principle: Principle #1 of caching: Caches should never introduce undetectable incorrectness. 
Correctness always takes precedence over performance. 
If we can't agree on this one, then we will never reach consensus about a caching design. 
The main lesson I draw from this principle is "when in doubt, don't cache". 
This is also a version of the robustness principle. 
In practical terms: a client or proxy, when trying to decide whether or not to cache something, should do all feasible sanity checks and not cache the object if a check fails. 
The other lesson is that a server needs a foolproof mechanism to tell the client (or proxy) not to cache an object. 
This cannot be an "optional" feature of the protocol, and it should not be based on any client/proxy algorithm that could get a wrong answer. 
So how would I design HTTP 1.1, if I were in charge? 
(1) Servers may send a header field explictly controlling caching. 
The spec could either be simple, something like Dont-Cache-This-ever: or a little more complicated: Caching-allowed: [never | always | byClient | byProxy] to allow for unanticipated future developments. 
(2) Clients and proxies need a foolproof way to validate cache entries. 
"If-modified-since" seems to be of questionable reliability. 
I suggest we use an "opaque version ID" approach: o For any cachable object, the server must generate a unique version ID. 
This could be constructed from a timestamp, but only if the server is able to guarantee uniqueness of the timestamp. 
A server without a synchronized clock may use any other scheme it wants, including (for example) generation of a random number so large that the chances of collision are effectively zero. 
oClients and proxies caching an object must store this version string as part of the caching data. 
o To validate a cached object, a client or proxy presents its version string to the server, along with the URL. 
The server checks to see if the version string is still valid for the URL. 
o Clients and proxies must not do anything with a version string except store it and present it to the server for validity checking. 
A server must have a way of deciding if the version string is valid for a given object, but the protocol specification need not concern itself with how this is done. 
There are several ways to do this, including using file modification dates + "epoch numbers" (every time you do something major to the system clock, you increment the epoch number) or adjunct databases. 
If a server is unable to generate useful version strings, it can still conform to the spec but it must specify that the objects it returns are uncachable. 
I know that some people will object that this makes life hard for servers implemented on underpowered machines. 
Tough. 
It really does not take a lot of CPU cycles or storage to get this right. 
If you can't handle the load, buy a faster server. 
This approach decouples cache validity checking and expiration, and so removes any dependency on synchronized clocks from the cache validity protocol. 
What about expiration? 
The issue with expiration is how to deal with clock skew. 
We can probably learn something from the work done on clock synchronization protocols. 
Here's a first cut at a proposal: (3) Servers may send Expiration information for cachable objects. 
(Expiration is not meaningful for noncachable objects.) Prior to the expiration time, a client or proxy need not validate the cached object with the server, but MUST provide a means for the user to request validation. 
The Expiration header looks like this: Expiration-info: Expires-time server-current-time The values are: o Expires-time Time at which the object expires. 
oserver-current-time Server's current idea of what time it is Clients and proxies would set the expiration time for a cached object to the Expires-time value, after correcting for the worst-case error. 
There are a number of ways to compute this, but a simple technique would be something like this: Tc = client's clock Ts = server-current-time Tr = round-trip-time measured for this request Te = Expires-time then actual-expiration-time = Tc + (Te - Ts) - Tr/2 Clients and proxies MUST NOT cache any object whose computed actual-expiration-time is highly suspect (for example, Te  Ts or Te  Tc, or |Tc - Ts|   Tr.) A server may send an "Expires-time" of "infinity", indicating that the object will never change (although the user must still be able to request that client/proxy validate the object, just in case). 
The "infinity" value is not subject to bogosity checking. 
-Jeff Well done! 
You addressed my issues and then some. 
--Shel Kaphan Jeffrey made an excellent proposal. 
I think it's worth pursuing. 
For the transition phase I still think that we should add Lou's SIZE parameter to I-M-S. 
Most of the cache corruption is truncation due to the fact that HTTP uses closing of connection as EOF and far too many implementations leave truncation unnoticed (and it's not even possible to notice it if there is no C-L header). 
Cheers, Ari Luotonenari@netscape.com Netscape Communications Corp.http://home.netscape.com/people/ari/ 
501 East Middlefield Road Mountain View, CA 94043, USANetscape Server Development Team That is not within our guidelines for 1.x. 
I do not believe in creating large entry barriers between minor protocol revisions, and HTTP versioning was designed to prevent it. 
Yep. 
I claim that both are already true given the mechanisms we have already discussed and which are within the scope of 1.1. 
That includes: Date: (no change necessary) Expires: (no change necessary) Last-Modified: specify that LM  server time must not be given If-Modified-Since: specify that IMS  server time is invalid Pragma: add "no-cache", "private", and "max-age" Content-MD5: no problemo Content-CRC: no problemo Transfer-Encoding: chunked Pragma is already set up to do this, and more (the above does not include the functionality of max-age). 
Solved. 
IMS is only of questionable reliability when users are prevented from controlling their own cache, or when servers send out invalid data. 
Unnecessary. 
That is why Date is given in responses. 
....Roy T. Fielding Department of ICS, University of California, Irvine USA Visiting Scholar, MIT/LCS + World-Wide Web Consortium (fielding@w3.org) 
(fielding@ics.uci.edu) 
Is the discussion on changing pragma no-cache semantics and introducing pragma private for old no-cache semantics? 
I see Content-MD5, Content-CRC Transfer-Encoding: chunked first time. 
Maybe I should subscribe to www-talk to be enough informed? 
If the 1.1 spec defines response headers like Content-MD5, (Content-MD3 ? 
- see RFC1810 on MD5 performance) Content-CRC, (maybe Content-CRC16 and Content-CRC32 to have more options? 
about this I'm less sure, than MD3) then when somebody or some application is in doubt, can issue a HEAD request to get those headers, and re-check the cache content against them. 
I like this kind of extension! 
Only MD5 can be stated as CPU-intensive, CRC and MD3 can be computed rapidly in case, when the origin server is in doubt about cached values, and can be supplied to the server as meta-data, if they are stored separately from the document. 
(I mean the technical impossibility of in-lineing like META HTTP-EQUIV="Pragma" CONTENT="no-cache" in the HEAD element. 
Not fully true for CRCs.) Andrew. 
(Endre Balint Nagy) bne@bne.ind.eunet.hu 
Why is getting someone to pay attention to 'size' easier than getting them not to cache truncated data or data without C-L? 
If the data didn't have a C-L in the first place, how would the server be able to check the length against a I-M-S parameter? 
Jeffrey Mogul: As discussed earlier on www-talk, if a sufficient number of service authors keeps putting Expires: yesterday or Pragma: no-cache headers in responses for frivolous reasons, a web cache administrator may want to (selectivelty) `tune' the cache to ignore these headers (even if this means that the cache does not conform to http 1.x anymore). 
Such a `tuned' cache would introduce incorrectness, so a corollary of the above principle is: If a cache does not honor requests _not_ to cache as in http 1.x, there should be a way for _origin servers_ to detect it, so that they can refuse to serve dynamic documents through these caches (or embed big warning messages in these documents). 
So we could introduce yet another pragma: Pragma: min-age= delta-seconds `Tuned' caches, either in user agents or in proxies, should add this header to the _request_ headers. 
Semantics of the header: - if it is absent: the cache promises to always honor the http 1.x response headers related to cache control (Expires and Pragma in 1.0 and 1.1). 
- if it is present: the cache does only guarantee to honor the http 1.x response headers related to cache control (Expires and Pragma in 1.0 and 1.1) _after_ delta-seconds seconds after the end of the http connection. 
In the time before that, the cache may choose to serve the cached entiry without prior validation with the origin server. 
Maybe a special case, Pragma: min-age=session is also needed to allow user agents to express that an entity is cached (without ever sending IMS or head requests to the origin server) until the end of the session (where the exact meaning of `session' is left undefined). 
Adding Pragma: min-age to a http 1.x spec would make `tuning' legal under http 1.x. 
I think any http spec should strongly discourage tuning. 
Tuning is with us now: if it has disappeared in, say, 2 years, the http x.y spec written in 1997 could make Pragma: min-age an obsolete header. 
Koen. 
No, it *might* introduce incorrectness. 
I claim that over 99% of today's non-cacheable pages are still "correct" after being cached, where correctness is defined as containing the same substantive and qualitative information content as would be obtained directly from the origin. 
[Note: my claim is based on personal observation, not controlled experimentation] That is why a cache administrator is willing to "tune" the cache, and it is not something that can be fixed within the protocol. 
Caches will do what providers want them to do when providers stop marking cacheable pages as non-cacheable. 
I am opposed to this change. 
First, any sensible cache administrator would never send such a header, since it effectively changes the request profile and therby lowers the quality of the response. 
Second, the cache is tuned based on each individual response, not based on every request. 
If the response looks like it shouldn't be cached, a tuned cache will not cache it. 
If it says "no-cache" and is coming from a reputable provider, a tuned cache will not cache it. 
If it comes from a notoriously wasteful provider, the cache will cache it and there is no incentive whatsoever for the cache administrator to warn the wasteful provider ahead of time. 
BTW folks, lack of a Last-Modified date does not imply no-cache. 
That is only an optimization used by Ari's two proxies and Navigator; it does not hold true in general. 
....Roy T. Fielding Department of ICS, University of California, Irvine USA Visiting Scholar, MIT/LCS + World-Wide Web Consortium (fielding@w3.org) 
(fielding@ics.uci.edu) 
These comments, and some in Jeff Mogul's thought-experiment, made me realize that the "argument" about discarding "future" Last-Modified's and not caching the accompanying documents is somewhat of a red herring if the implementation is "good" (where I get to define "good" :)). 
PRINCIPLE: It is not possible to reliably compare times from two different, unsynchronized, clocks. 
So, don't do it. 
(Not naively, anyway). 
Regarding Last-Modifieds "in the future", Last-Modified should be ignored if the timestamp is later than the accompanying Date response header. 
Then it is certainly invalid. 
But it can't be reliably compared to the local clock without appropriate adjustment. 
So, subject to the following being adopted I'll agree with Larry Masinter's rules. 
The following is a proposal, so when I say "should" here, I mean in the context of this proposal, ok? 
If a server sends an expires header that is 30 seconds in the future, it means the future as it knows it. 
So, when a downstream server receives Expires, it should interpret that in local time using (some function of) the delta between the accompanying Date header and its own clock. 
A cache should keep track of the delta between a server's clock (as returned by Date) and its own clock, and include (some function of) that delta in any communication with that server involving timestamps. 
There is some complication with GET-IMS requests being passed along from downstream servers. 
An intermediate proxy cannot tell whether the date in an IMS request is given in the upstream server's coordinates (e.g. an upstream LM header being returned in an IMS request) or in the downstream server's coordinates (e.g. "get me something if it has changed in the past 15 minutes"). 
When proxies pass through requests or responses including timestamps such as GET if-modified-since, last-modified, and expires, I propose that they should normalize the times to their own clocks, using an unspecified algorithm they determine, which is a function of the delta between local time and the Date header passed by the server, and may include information on round-trip delays accumulated over time. 
This way, for instance, a downstream server's GET-IMS request or an upstream server's Expires header can be translated to be in local time system. 
So, here is a PROPOSAL: For this reason, I propose that whenever requests or responses containing these timestamps are generated, that a Date header should be REQUIRED, and should indicate the moment the request or response is transmitted. 
Example: Assume 0 delays everywhere for simplicity. 
In this example the RECEIVERs do all time adjustments in both directions. 
That is not the only way this could work. 
Client CProxy PServer S 12:0012:0111:59 GET -- -- GET -- Process GET, issue headers Date: 11:59 last-modified: 10:00 -- Receive Date 11:59 Delta for server S = 12:01 - 11:59 = +2 minutes rewrite headers: Date:12:01 Last-modified: 10:02 -- Receive Date 12:01 Delta for Proxy P = 12:00 - 12:01 = -1 minute interpret headers: date: 12:00 last-modified:10:01 12:0512:0612:04 GET IMS 10:01 -- Receive Date:12:05 Translate IMS header Using +1 minute delta, translate IMS header to 10:02, GET IMS 10:02-- Receive Date: 12:06. 
Use -2 minute delta to interpret IMS header as GET IMS 10:00. 
One problem with this is that due to inevitable inaccuracies in the delta computations, an IMS request might differ from the LM that it corresponds to. 
So, in the long term, some cookie other than a timestamp is a better way to go for such return-trip operations, as both Jeff Mogul and I previously suggested. 
--Shel Kaphan I just don't think this applies. 
The 'comparison' I was suggesting was not an equal, but a 'greater' comparison. 
For the most part, clock drift of seconds or even hours doesn't affect it. 
And, secondly, I believe it is reasonable at some point to expect HTTP clients and servers and the proxies in between to have correct clocks. 
We're talking about Internet applications now, for machines that are well connected on the net. 
Maybe it would simplify things if HTTP servers and proxies also offered a time service, and HTTP clients on impoverished platforms had an option for setting the time? 
I'd handle this using well-known URLs for 'get' rather than some special protocol, though. 
And, secondly, I believe it is reasonable at some point to expect HTTP clients and servers and the proxies in between to have correct clocks. 
We're talking about Internet applications now, for machines that are well connected on the net. 
and suggests that HTTP servers offer time service. 
Ugh. 
While it is perhaps reasonable to expect HTTP servers and clients to have correct clocks, for some definition of "correct" (talk to Professor Einstein about this), I do not think it is *necessary* to rely on this when designing the protocol. 
Moreover, I would not confuse "reasonable to expect" with "safe to expect". 
Shel Kaphan suggests that clients use the "Date" information to run a sort of NTP-like clock synchronization algorithm, keeping track of each server's relative clock performance. 
Double ugh. 
This is a lot of hard work, and it's already done by NTP. 
And it's not all that useful. 
We're still confused about two uses of timestamps: (1) cache validation and (2) expiration. 
I think Shel is close to the truth when he writes It is not possible to reliably compare times from two different, unsynchronized, clocks. 
So, don't do it. 
But let me try to clarify things a bit more. 
(1) For the purpose of cache validation ("is the cached copy I have valid or not"), it should not be necessary to do ANYTHING besides a strict equality comparison. 
The cached copy is either the same as the server's copy, or it isn't. 
If we are using last-modified times as the validation ID, then either they are equal or they aren't. 
I fail to see any value in allowing a server to return 304 (not modified) if it's idea of the modification time is prior (that is, not exactly equal to) the client's (or proxy's) stored modification time. 
[I'll note that all the allowed date formats have one-second resolution. 
This could be a problem in the future, if things are changing faster than once a second, and browsers can do something useful with this (but this is speculative, I admit).] (2) For expiration checking, it is obviously necessary to do inequality comparisons ("is expiration time  now?"). 
In this case, though, we don't need to be 100% accurate, since in almost all cases I can think of, when someone assigns an expiration date, it's at best a guess, anyway. 
Doing expiration checking does not require carefully synchronized clocks; it only requires sufficient sanity checking that badly out-of-whack clocks are not believed. 
I think the algorithm I suggested in my previous message should work fine, noting Roy's comment that the Date header provides the necessary sanity-checking info. 
(And so HTTP 1.1 should make Date mandatory if Expires is sent, I think.) For both cache-validation and expiration, I believe that the algorithms used by clients and proxies should be identical. 
That is, I see no reason why a client should cache something that a proxy isn't allowed to (except as explicitly instructed by the "Caching-allowed:" header or whatever we're calling that). 
And there can't be any reason to allow a proxy to cache something that a client is not allowed to. 
So far, what I've suggested in this message does not change the syntax of the protocol; I'm suggesting changes in what servers, clients, and proxies do with the headers we already have. 
This means that (so far) everything I've suggested in this message should interoperate with all reasonable implementations. 
(Clearly, a server sending entirely random values for last-modified, for example, isn't entirely reasonable.) People may suspect that I don't entirely like the use of last-modified dates as cache validators. 
It may be that a server implementor would prefer to use a separately managed and opaque unique-ID, such as a generation number (as done by NFS) or an MD5 checksum. 
This relieves the server of having to be cautious about file modification dates, and also solves the problem of insufficient precision in the HTTP timestamp formats. 
I do not believe that file length is useful as a cache validator. 
As many people have pointed out, it's hard to define "length" and it's not a safe validator, since the file contents may change without changing the length. 
On the other hand, if server implementors are naive enough to use file length as their opaque identifiers, I'm not going to stop them (but I won't run their servers!). 
So I would like to suggest, for HTTP 1.1, a FULLY COMPATIBLE protocol change that should solve this problem. 
Add a new header returned by a server (perhaps via a proxy): Cache-Validator = "Cache-Validator" ":" opaqueID opaqueID = *( unreserved | reserved ) And a new header sent by clients: If-Validator-Valid = "If-Validator-Valid" ":" opaqueID Clients and proxies are not allowed to do anything with the opaqueID except return it to the server that it came from by sending it in an "If-Validator-Valid" header. 
A server that receives both "If-Validator-Valid" and "If-Modified-Since" should ignore the latter. 
Otherwise, the spec for "If-Validator-Valid" should look pretty much like the spec for "If-Modified-Since", except of course for simpler rules about comparisons. 
This allows full interoperability with older implementations. 
Old servers won't send "Cache-Validator" headers; old clients won't send "If-Validator-Valid". New clients will send only "If-Modified-Since" to old servers, since they won't have a validator in this case. 
Old clients may receive "Cache-Validator" headers, but they are already required to ignore unknown headers. 
Proxies (old and new) will pass these new headers in either direction; new proxies may even use them. 
A server is free to use a timestamp as its opaqueID. 
It may even use timestamps for some files, checksums for others, etc. 
It might make sense to use one for files, and the other for CGI output. 
To summarize: I think HTTP 1.1 should aim for the simplest possible correct, interoperable cache-control protocol. 
I claim that what I've proposed fits the bill: (1) Servers can use explicit "Caching-allowed:" headers to force non-caching behavior when necessary. 
(2) Servers and clients/proxies exchange opaqueIDs as cache validators. 
This leaves no confusion about interpretation. 
Choice of how unique opaqueIDs are generated is left entirely up to the server implementor. 
(3) Cache expiration is done using a simple "Expires+Date" pair that allows the client/proxy to do a sanity-check, without requiring synchronized clocks. 
-Jeff No, it *might* introduce incorrectness. 
I claim that over 99% of today's non-cacheable pages are still "correct" after being cached, where correctness is defined as containing the same substantive and qualitative information content as would be obtained directly from the origin. 
[Note: my claim is based on personal observation, not controlled experimentation] I hate to be pedantic, but let's try to maintain a distinction between a "correct protocol" and "correct results". 
A correct protocol is one that never yields incorrect results. 
(Usually, this is respect to a given failure model; that is, you have to say what kinds of failures you are willing to defend against. 
But that's splitting hairs.) A correct result is one that would have resulted from a correct protocol. 
An incorrect protocol can generate correct results, but doesn't always do so. 
Roy's claim about "99% of today's non-cacheable pages" is one about correct results. 
Koen's statement is about an incorrect protocol (or rather, an incorrect implementation of the protocol). 
I agree with Koen that some proxy implementors (or managers) may want to violate the protocol spec, for reasons of their own. 
But this is outside the realm of the HTTP spec, and I agree with Roy that the spec should not be twisted to support it. 
On the other hand, there is some merit in in allowing a cache to return an object of questionable validity. 
For example, suppose the original server is down; should the cache return "sorry" or should it return a possibly invalid object? 
Or (to be more speculative about future versions of HTTP) if the server is really slow, perhaps the cache could return the possibly invalid version quickly, and then update it with the proper version when it arrives. 
Or perhaps the cache is "tuned" as Koen has described. 
(I might say "kludged" instead of "tuned" :-).) I suggest that these are potentially useful things for a cache to do, but we ought to think about protecting the ultimate user against the possible inconsistency. 
Koen suggested a Pragma sent as part of the request, implying that the user agent controls how the cache handles inconsistency, but this doesn't actually help the user decide if the response is questionable or not. 
How about doing things the other way? 
Any cache (including one inside the user agent) that returns a possibly invalid object must mark it with (of course) a new header: Possibly-invalid : reason-why-string The reason-why-string would be some sort of explanation of what is suspect. 
For example, "server is down, this is 1 hour old" or "we are ignoring Expiration dates from this server, but if you care, the file expired in 1991", or "server is slow, try again soon but meanwhile here's my 2-hour-old copy". 
Actually, the latter might better be handled by a different kind of response, to allow a browser to automatically update the page when it arrives from the server. 
Maybe: Possibly-invalid-try-again-soon : reason-why-string In HTTP 2.0, the cache could probably simply promise to send the response along as soon as it arrives. 
A browser could use some sort of status line, or pop-up window, or whatever, to display this warning to the user. 
Cascaded proxies would have to convey the warning, but of course they would naturally do that with an unexpected header. 
This approach allows the cache to do almost anything, but ensures that the user is never mislead about the validity of a page. 
A user who doesn't like the idea of looking at an invalid page can always hit "Reload". 
-Jeff I was just about to agree that if servers were synchronized to within a fraction of a second, and that was a required part of (some future version) of http, that would suffice, but then I remembered that clients have a part in all of this too. 
User agents have to do the right thing with Expires, and there is no way that anyone's ever going to make all user agent clocks correct. 
So at minimum, some of this normalization has to occur within user agents. 
It affects both handling of Expires and generation of GET-IMS, if you want things to be accurate in time. 
If accurate timekeeping were part of HTTP for servers &amp; proxies, that would remove any necessity for what I suggested for them though. 
The question you've gotta ask yourself is "which is a better engineering solution"? 
--Shel How about doing things the other way? 
Any cache (including one inside the user agent) that returns a possibly invalid object must mark it with (of course) a new header: Possibly-invalid : reason-why-string The reason-why-string would be some sort of explanation of what is suspect. 
For example, "server is down, this is 1 hour old" Oops. 
How small-minded of me. 
This can't just be a string, since that would only be useful if the proxy spoke the same language as the users. 
Which is likely to be true, but it's probably not guaranteed. 
So I guess we would need some sort of scheme of coded responses, allowing the browser to turn them into human language. 
It would be nice to include some parameters, though. 
-Jeff I tried to say this before but I think something bad happened when I tried to send the mail. 
I like Jeff's proposal better than what I suggested. 
My mistake was in presuming that nothing can be thrown away, in particular if-modified-since. 
Jeff's proposal obsoletes if-modified-since. 
Since I don't believe if-modified-since can work without some form of synchronization -- either NTP + browser hacks or something like what I said, which is indeed too complicated, maybe it would be best if it just went away in some future version of the protocol, and we just not worry about fine-grained synchronization. 
In any case the date+expires rule should go in sooner rather than later. 
--Shel Roy Fielding: [Koen Holtman:] Still "correct" after being cached for how long? 30 seconds? 
5 minutes? 
For the duration of the user agent session? 1 day? 
30 days? 1 year? 
If you say 30 seconds, I would agree with your 99% estimate (but only if your `pages' do not include responses to POST requests). 
For 30 days, my guess is about 50%. 
But anyway, saying that 99% of the pages will remain correct even if caches are `tuned' is besides the point: it is the possibility of getting incorrect pages that counts: if the web is an unreliable communications medium, this rather restricts the kind of content it can carry. 
Be fixed, no. 
Be taken into consideration, yes. 
Providers are not one group. 
There are at least two groups: - Static content providers, serving pages that can always be cached. 
- Dynamic content providers, serving pages that cannot be cached (or cannot be cached for more than N minutes/hours/days). 
Static providers can afford to mark their cacheable pages as non-cacheable for frivolous reasons: if this drives some proxy administrators to `tuning', they only feel a slight dip in hitcounts, nothing more. 
What have they got to loose? 
The web currently has almost no _dynamic_ providers, because they need reliable caches (or at least a way to detect unreliable caches), and they cannot get reliable caches. 
A dynamic content provider cannot put a `tornado warning, updated every 10 minutes' page on the web if it cannot be guaranteed that this page will never be cached for longer than 10 minutes. 
Bad things will happen to unsuspecting users otherwise. 
A web-shop cannot put a `shopping cart' application on the web if the (dynamic) shopping cart contents may be inappropriately cached. 
A customer pressing `buy' on an outdated shopping basket page may sue the web-shop after receiving the wrong products. 
A `war' between proxy administrators and static content providers will prevent dynamic content providers from using the web (unless they have huge legal departments). 
Thus, such a war prevents the web from growing beyond the static, read-only medium it is now. 
Sending the header would allow dynamic content providers to start using the web. 
This will greatly increase the quality (or at least the diversity) of web content. 
A `tornado warning, updated every 100 minutes' response, put out by a tornado warning server after getting a `Pragma: min-age=6000' header in the request, has a much higher quality than a 90-minutes old `tornado warning, updated every 10 minutes' response from a `tuned' proxy cache. 
You call it `sensible' for a cache administrator managing a `tuned' cache not to tellthe world it being tuned. 
I strongly disagree with this. 
Not all actions by cache administrators can be morally justified by the existence of selfish server administrators. 
Undetectable `tuning' is a very selfish thing to do. 
If 10% of cache administrators do undetectable tuning, they will keep dynamic service providers off the web, and spoil the fun for all people behind the 90% of working caches as well. 
This is why I propose pragma: min-age. 
If 10% of cache administrators insist on fighting a spec non-conformance war with static service providers, at least they should ensure that the other 90%, who put up with more IP traffic in the hope of getting dynamic web services someday, do not become victims. 
A protocol extension cannot make the 10% of tuned caches go away, but it can reduce their harmful effects. 
I think that a Pragma: min-age request header is an adequate solution to tuned cache detection, because I don't expect tuned caches to become that common. 
A much more refined mechanism is not needed in my opinion. 
A Pragma: pragma-no-cache-coming-from-selfish-provider-ignored response header, generated by proxies, looks more refined, but has a big disadvantage: it may cause the `warning: this page may be outdated' messages by browsers to become so common that users simply always ignore them, even if they are accessing a page that really is autdated. 
This will leave dynamic service providers with the same problem they have now. 
Technology to distinguish between `reputable' and `notoriously wasteful' providers is not available now, and I don't have very high hopes of it being feasible, available, and used anytime soon. 
If proxy administrators go through the trouble at all of making any distinction between reputable and wasteful providers, I fear that the default will be to assume that a provider is wasteful. 
If (new) dynamic service providers cannot count on getting a warning from tuned caches, they will simply stay off the web. 
Also, if a known wasteful provider is not warned, how is the provider to know cache administrators disapprove of him? 
If anything, wasteful providers need to get as many warnings (=complaints) as possible. 
A wasteful provider responding to these warnings by generating pages with `one-time-urls' or other cache busters would immediately show up on the `wastefulness detector' you assume present: a proxy administrator could then decide to stop talking to the provider altogether. 
Jeffrey Mogul: Just for the record, Roy seems to be much move forgiving of such violations than I am. 
This problem is outside the realm of the current draft HTTP spec (in that a spec can never contain a mechanism to support spec violations), but not outside the realm of HTTP spec _development_. 
If the goal of HTTP spec development is to allow for the growth of the web, the next spec should support the needs of dynamic service providers. 
Dynamic service providers need Pragma: min-age, or some equivalent warning mechanism, so it should be in the next spec. 
Putting Pragma: min-age in the next spec will, if it is done right, not make the spec self-contradictory. 
Like the Accept-Encoding header, Pragma min-age would just be a mechanism for a client to express that it only supports a subset of the defined potential http functionality. 
Koen. 
