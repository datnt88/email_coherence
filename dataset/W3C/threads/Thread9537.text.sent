As I noted in: I created three test cases that test different permutations of mis-spellings of the parseType attribute (e.g. ParseType): Although there is no associated issue for this in the Issue Tracking doc, they cover a common error for both new and experienced RDF/XML authors. 
Consequently, I offer these TCs as candidates for inclusion in the WG's test case repo and thus request comments. 
Art Are we banning use of rdf:* except where we say so? 
My thought is that a parser may choose to treat rdf:ParseType as a propAttr. 
Your test cases are still errors but with a different sort of error message. 
e.g. ERROR: Unknown rdf attribute: 'ParseType' or ERROR: Unexpected text, propertyElt with propAttrs must be empty. 
which one do we go for? 
(I prefer the first) Jeremy Hi Art, Right, I see where you are coming from. 
I was expecting that we were doing test cases for the issues that have been raised, or that we uncover during our deliberations. 
Such test cases need formal approval by the WG on a case by case basis as this part of the process by which the WG is resolving issues. 
Can I suggest that test cases which do not involve WG issues are something you can just collect, don't need reviewing on a case by case basis and can be reviewed as part of the process of publishing WD's. 
Less work, all round, yes? 
You have brought up another issue about the scope of the test cases document. 
The charter states as deliverables: * publish a set of machine-processable test cases corresponding to technical issues addressed by the WG If you'd like to extend the scope of the test cases document beyond that, covering common errors and the like, that will be more work for the WG and something we need to discuss. 
I think this would be a great thing to do, but I guess I have to act as charter policeman a bit here. 
Are you envisaging just a few extra test cases here and there, or something requiring more significant effort? 
Brian It had occurred to me that scoping test cases was likely to be tricky; clearly, test cases that address issues are desirable, but where to stop? 
I had formed a view that if someone cared enough to actually create some test cases for a non-issue, then they were probably worth including. 
On reflection, I'd say: if someone cares enough to produce the test cases, and at least 2 (?) others feel they're important enough to review, then they're probably worth including. 
I think that could be done without incurring lots of WG effort. 
I would request, however, that the test cases themselves include (brief) text that makes it clear what they are actually testing. 
(Many already do, but some don't.) #g Graham Klyne MIMEsweeper Group Strategic Research http://www.mimesweeper.com 
Seems like reviewing the non-issue related test cases in pieces or in one batch would take the same amount of time. 
Well, if you're going to start playing charter cop, then I don't believe the charter explictly lists as deliverables test automation or automatic triple generation :-). 
You may also want to consider a threshold for the number of WG members that need to approve a test case before it gets labeled as Approved in the TC doc. 
I currently have no plans for creating new tests. 
I do, however, agree with the sentiments Graham expresed in: and wouldn't categorically deny a test case just because it doesn't represent an issue in the issue tracking doc. 
Art Yup. 
That looks like a reasonable policy. 
Brian 
