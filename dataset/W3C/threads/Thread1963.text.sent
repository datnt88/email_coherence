1.Much has been mentioned about the cumulative terror of the round trip time (RTT) penalty paid for many small HTTP requests, each of which requires its own TCP connection (and resultant RTTs) required to fetch and render an HTML document and its component objects. 
Compounding the problem, some anti-social network clients initiate multiple concurrent TCP connections in an attempt to create the illusion of a speed up by distracting from boredom by rendering all objects as they arrive simultaneously. 
Should the user choose to abort a document load conducted in this way, it aborts all in-progress TCP connections as well. 
The network is then then saddled with what others have observed as the substantial overhead of all the silent screams of those aborted connections. 
2. Packing all or part of an HTML document and its components into a multipart MIME message in response to an HTTP GET would increase the number of bytes sent along a single TCP socket connection. 
This will avoid some of the network congestion observed with the multiple and/or simultaneous low content-length TCP sessions when clients build the document. 
While valuable work is underway to provide binary-encoded and multiplexed transport-level solutions to the multiple connect problem [ Spero, Raggett, HTTP-ng ], We need to look concurrently at exploiting the transport encoding scheme upon which HTTP theoretically rests to address this problem--MIME. 
I do not believe that this approach conflicts with any of the work on HTTP-ng, and could envision a case where they could be used together transfer multiple HTML documents and their components quite rapidly. 
Most of all, we need to provide many options allowing for maximum tuning and customization on all sides. 
3.Operating under the assumption that at this time in the life cycle of the web, most HTML documents contain components that reside on the same server as the document itself, why not trade the multiple network connections from the client to the same server for some up-front packaging by the server. 
Instead of a server having to clone itself into as many instances as sub-objects it serves, it could perform a rudimentary (cached) parsing of the document to determine the appropriate sub-objects that it served as well, package them up into MIME body parts sent along with the HTML document. 
Accesses by the server on which the components reside usually requires merely a simple secondary storage access measured in terms of milliseconds which in the vast majority of cases is significantly less than that of a TCP RTT which can run into perceptable fractions of whole seconds. 
As an option, the server could resolve any object references resident on other servers (caching the results in shared memory), and include them in the multipart data stream. 
What follows is a draft protocol for encoding an HTML document and its components in multupart MIME. 
4.The client would need to include multipart/mixed* in its Accept: headers if it chose to accept this encoding. 
A terminal-based browser such as lynx or LineMode would not send this in its Accept: headers and could thus opt out. 
If a browser had the flushed the HTML document from its cache but had not flushed some of its inline images you would not want to include this header unless you wanted the larger, complete data stream. 
The server builds a multipart/mixed* message consisting of the HTML document and whatever components were resolved. 
The server could be configured either to resolve and cache or leave to the client any components that resided elsewhere. 
* multipart/mixed might be better as application/http or multipart/http. 
I defer to the MIME dieties for a ruling. 
6. Interoperating efficiently with client cache management brings up some interesting issues. 
The ability to check the HTML document's requirements against the client-side cache before issuing a precisely tailored HTTP MGET request (which would be returned as multipart/mixed*). 
6. 
The HTML document is included as a body part of Content-Type: text/html. 
The outermost MIME headers (or the header associated with multipart/mixed*) contain a Message-ID: field in the form: Message-ID: URI Each component object is identified by a Content-ID: field that is in the form: Content-ID: URI In this manner, each body part can be unpacked by the client, inserted into its cache data structure, any missing body parts could be acquired, and the multipart images would be pulled out of the cache struture to render. 
The master HTML document can be recognized as main body part by the URI common to both the Message-ID: field and that of the Content-ID: field in one of the Content-Type: text/html body parts. 
7.An instance of the proposed MIME encoding scheme for HTTP follows. 
This is currently in the process of a feasibility study in METHADONE (Mime Encoding THreAded Daemon Optimized for Network Efficiency), a caching, lightweight threaded, MIME multipart encoding HTTP server for solaris 2.x (exploiting the rich base functionality of NCSA's httpd) currently under beta development at the UCSF Library and Center for Knowedge Management. 
Client makes HTTP connection to host.domain: GET /http_mime.html 
HTTP/1.0 Language: en Accept: multipart/mixed, application/http Server responds: HTTP/1.0 200 OK Title: A Proposed MIME Encoding of an HTML Document and its Components Date: Thursday, 15-Dec-94 03:19:05 GMT Server: METHADONE 0.1 Cost: free! 
Content-Language: en Allowed: GET HEAD PUT Allowed: GET HEAD Date: Thu Dec 15 19:48:54 PST 1994 Last-Modified: Wed Dec 7 14:54:48 1994 MIME-version: 1.0 Message-ID: http://host.domain/http_mime.html 
Version: beta Content-Type: multipart/mixed; boundary=__http__boundary__ --__http__boundary__ Content-type: text/html Content-Language: en Content-ID: http://host.domain/path/http_mime.html Content-Length: 193 --__http__boundary__ Content-Type: image/gif Content-ID: http://host.domain/image.gif Content-Transfer-Encoding: 8bit Content-Length: 1234 --__http__boundary__ Content-Type: text/html Content-ID: http://host.domain/path/frag.html 
Content-Transfer-Encoding: 7bit Content-Length: 799 LI Client issues GET on HTML document. 
LI Server scans HTML document for any component objects (SRC=%URI;) upon reciept of GET. 
LI In most cases, the components are resident on the same server, so any GET's are to secondary storage instead of the network. 
LI The server can perform GET on components resident elsewhere and cache or defer that to the client. 
LI The server packs up the document with its components into a multipart MIME message. 
LI The data can be sent over an 8-bit HTTP socket, no content-transfer-encoding required. 
LI Content-ID: MIME Header contains URL of component. 
LI Client parses multipart MIME message. 
LI Client adds components to image cache. 
LI Client performs GET on remaining images if not resolved by server. 
LI Client renders HTML. 
--__http__boundary__ Content-Type: image/xbm Content-ID: http://host.domain/path/image.xbm Content-Transfer-Encoding: 8bit Content-Length: 2345 --__http__boundary__ --__http__boundary__ Two consecutive boundary strings indicate an EOF. 8. I plan to bring this up on the sgml-internet list as well, for a broader, more general perspective. 
-marc // Marc Salomon Software Engineer e-mail: marc@ckm.ucsf.edu 
// \\ Innovative Software Systems Group \\ // Center for Knowledge Management phone : 415.476.9541 // \\ The University of California, San Fransisco \\ Deploying MGET/multipart looks to me like: [a list of steps for clients, servers, including...] * A few information providers maybe start using it (It's 3 months into the future by now) Meanwhile, commercial folks are implementing HTTP-NG at lightning speed. 
Six months from now, all the major vendors are doing interoperable compression and encryption over something like SCP or SSL (not to mention strong authentication). 
Sorry, I'm skeptical about this statement. 
At least some of the proposals for MGET/multipart and keep-alive are compatible with what exists now. 
For example, a client could attempt to send an MGET to a server. 
If the server chokes, the client can revert to a series of regular GETs. 
My contrast, deploying HTTP-NG would require significant changes to clients and servers both, and, despite the transition plan described by Raggett and Spero, I see HTTP 1.0 and HTTP-NG as fundamentally unable to interoperate. 
(They propose using a proxy to translate.) So, I think vendors are less likely to switch to HTTP-NG in three months, a protocol still being experimented with and IMO not quite ready for prime time, than they are to adopt the MGET stuff. 
It may well be that *some* vendors will have compression, encryption, and session control in six months (some do now, in limited ways), but I'm equally skeptical that "all the major vendors" will be doing so "interoperabl[y]" if there's as yet no agreed-to standard upon which to interoperate. 
My tastes (obviously) run to a more evolutionary approach for HTTP. 
I'm unconvinced that the performance problems require a flash cut to a binary protocol. 
Spero has shown that doing multiple transactions over one connection achieves signficant performance improvements. 
His response is to change HTTP drastically. 
Mine is to do so within the current overall design. 
Dave Kristol Dave My tastes (obviously) run to a more evolutionary approach Dave for HTTP. 
I'm unconvinced that the performance problems Dave require a flash cut to a binary protocol. 
Spero has shown Dave that doing multiple transactions over one connection Dave achieves signficant performance improvements. 
His response Dave is to change HTTP drastically. 
Mine is to do so within the Dave current overall design. 
Well, there's always my other response :-) One of the things I talked about with Alex at the IETF was making a slight change to the SESSION proposal. 
The idea is to use the SESSION method to switch the connection over to running SCP, and then use SCP to manage multiple sequential HTTP 1.0 transactions. 
It turns out that this technique allows even more code to be reused than using MIME multipart, and provides a very obvious transition path to full HTTP-NG. 
One other thing that was discussed was the relative advantages of using a session method vs. an ignorable header. 
It turns out that there is a problem with using ignorable headers when proxies are used - if a proxy which doesn't interpret the header is used to talk to a server which does handle the header, the connection can become deadlocked (the end server things that the proxy doesn't want it to drop the connection, whilst the proxy is sitting there waiting for the connection to drop). 
Simon I knew I should have replied to these messages yesterday, but the need for sleep got the better of me. 
Enabling multiple requests on a single connection will be the primary goal for HTTP/1.1. 
However, before that happens, we needed a solid basis for HTTP/1.0 -- one which is compatible with correct current practice and yet does not prevent future extensibility. 
Thus, in the process of writing HTTP/1.0, Henrik and I have been figuring out what needs to be done for HTTP/1.1. 
In this way, we have identified several aspects of "current practice" which must be fixed before standardizing 1.0. 
Most of these we have already talked about (i.e. being able to parse media types correctly so that parameters can be used, enabling something other than a closed connection to mean end-of-body, etc.). 
Simon briefly mentioned another problem that we have yet to discuss on the mailing list: As always, all the real work at the IETF was done in the hallways, so many of you at the BOF may not have heard about this either. 
The essential problem is that HTTP intermediaries (proxies) treat everything they don't understand as being something they should pass on to the destination host. 
Unfortunately, that means they would pass on stuff that was only intended for them (like connection setup information), thus fooling the end-server into thinking that the proxy wants that connection setup applied. 
Worse, I believe this applies equally for both ignorable headers and unknown methods! 
Thus, we need a way for all proxies/servers, both HTTP/1.0 and 1.1, to be able to identify information which must not be passed downstream. 
Henrik and I (with help from many others, some of whom have asked to remain anonymous ;-) worked out a possible solution in two parts: 1) a SESSION method Like what was discussed at the BOF, except current proxies would be changed such that no SESSION requests were passed-on -- in effect, this would be the same as a NOP command, but allow connection info to be passed in the headers. 
2) a Connection header The Connection header is used to specify the parameters (desired or actual) of the current connection. 
Clients can use this header to indicate their desire to use a set of connection options. 
Servers can use this header to indicate what options are actually being applied. 
This field applies only to the current connection -- receivers should not cache or otherwise save the connection information after the connection is closed. 
Proxies must not forward this header, though they may generate a separate Connection header for their own connections. 
Connection = "Connection" ":" 1#connect-option connect-option = token [ "=" word ] Although HTTP/1.0 clients and servers do not make use of the Connection header outside of experiments, this field will be necessary to enable future extensibility of connection-specific behavior. 
Most importantly, HTTP/1.0 proxies need to know that they must not forward this header even when they do not understand or make use of its contents. 
For example, an experimental client may send: Connection: keep-alive to indicate that it desires to keep the connection open for multiple requests. 
The server may then respond with a message containing: Connection: keep-alive, timeout=10, maxreq=5 to indicate that the connection will be kept open for a maximum of 5 requests, but will timeout if the next request is not received within 10 seconds. 
Note that the semantics of these options are not defined for HTTP/1.0, though similar options may be defined by future versions of HTTP. 
Note that the above two are independent -- a Connection header could be applied to a GET, HEAD, PUT, POST, etc. 
It does require a change to current practice, but only for proxies. 
Personally, I can't think of any other way of doing it without disallowing proxies altogether. 
The above is what I plan on putting in the next draft of the HTTP/1.0 spec. 
Now would be a good time to hack it to pieces, if you are so inclined. 
One idea that has been mentioned is that the Connection header should be a list of other header-names, thus allowing complete flexibility. 
I do not favor that approach, however, because a) it adds more overhead to the request b) it would require more work on the part of proxies, and c) it would require that Connection be the first header received (of those named). 
Comments, please? 
......Roy Fielding ICS Grad Student, University of California, Irvine USA Here's another wrinkle to consider for a SESSION method. 
Some transactions have a model that resembles the Basic authentication scheme: 1) The client innocently asks for something. 
2) The server rejects the request and asks for something extra. 
3) The client reissues the original request, plus the something extra. 
4) The server honors the request. 
This model applies for some payment schemes and some security schemes. 
It would be nice if the client had a way to tell the server it's willing to keep a connect open (create a session), even though it didn't request to do so at first (with a SESSION method). 
Perhaps the client can send the same Connection: headers that it would have sent with a SESSION method. 
If I understand the SESSION proposal correctly, the client must wait until the server responds before it can send its first "real" request. 
Wouldn't it make more sense to be able to send the first "real" request along with the SESSION request? 
If so, we're starting to look like my extensions proposal (http://www.research.att.com/~dmk/extend.txt, which needs some polishing per Larry Masinter's suggestion at IETF), in which you can "wrap" requests in layers. 
In this instance, SESSION resembles my WRAPPED request, and the contained request(s) is(are) the "real" request. 
Dave Kristol It is possible to send the first request with the session establishment packet, so you don't have to wait for the round trip. 
If the session method is rejected, the wrapped request will just be discarded. 
Simon 
